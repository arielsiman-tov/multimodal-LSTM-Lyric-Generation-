{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arielsiman-tov/multimodal-LSTM-Lyric-Generation-/blob/main/DL3_lyric_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0g86ce0Auhz"
      },
      "source": [
        "#**Deep Learning- lyric_RNN_model**\n",
        "#### **Tal Klein - 209234103 | Ariel Siman Tov - 209499821**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9M7ul7OMm_dk"
      },
      "source": [
        "# **Imports**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7sUJHR75trNP"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install pretty_midi\n",
        "!pip install torch\n",
        "!pip install TextBlob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UeCzIPn9v88o"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import re\n",
        "import string\n",
        "import csv\n",
        "import pickle\n",
        "import warnings\n",
        "from collections import Counter\n",
        "from itertools import product\n",
        "from gensim.downloader import load as gensim_load\n",
        "from gensim.models import KeyedVectors\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.distributions.one_hot_categorical import OneHotCategorical\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import gensim.downloader as api\n",
        "from gensim.models import Word2Vec\n",
        "from tqdm import tqdm\n",
        "import pretty_midi\n",
        "import glob\n",
        "from textblob import TextBlob\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yG0_4c7qtvGw"
      },
      "source": [
        "# **Connect to Drive**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRh1rC9N0zO_",
        "outputId": "f2bf998a-03f7-41d5-cc1a-277d3254db82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-PV3AoXwBAk",
        "outputId": "aa2d0add-d8c2-4052-8a74-f7f6d92a6eeb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZIaRxWr_wCoQ"
      },
      "outputs": [],
      "source": [
        "# change to your path.\n",
        "path_midi_files = '/home/tak/justice-tal/content/drive/MyDrive/DL3/midi_files'\n",
        "train_file = '/home/tak/justice-tal/content/drive/MyDrive/DL3/lyrics_train_set.csv'\n",
        "test_file = '/home/tak/justice-tal/content/drive/MyDrive/DL3/lyrics_test_set.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "atSEVGnIwElN",
        "outputId": "b22dc0a5-c6a7-4ee8-bfe6-6cd66192ca21"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Artist</th>\n",
              "      <th>Song Name</th>\n",
              "      <th>Lyrics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>elton john</td>\n",
              "      <td>candle in the wind</td>\n",
              "      <td>goodbye norma jean newline though i never knew...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>gerry rafferty</td>\n",
              "      <td>baker street</td>\n",
              "      <td>winding your way down on baker street newline ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gerry rafferty</td>\n",
              "      <td>right down the line</td>\n",
              "      <td>you know i need your love newline got that hol...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2 unlimited</td>\n",
              "      <td>tribal dance</td>\n",
              "      <td>come on check it out newline come on come on n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2 unlimited</td>\n",
              "      <td>let the beat control your body</td>\n",
              "      <td>let the beat control your body newline let the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>595</th>\n",
              "      <td>don henley</td>\n",
              "      <td>dirty laundry</td>\n",
              "      <td>i make my living off the evening news newline ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>596</th>\n",
              "      <td>don henley</td>\n",
              "      <td>new york minute</td>\n",
              "      <td>harry got up newline dressed all in black newl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>597</th>\n",
              "      <td>bob dylan</td>\n",
              "      <td>subterranean homesick blues</td>\n",
              "      <td>in the basement newline mixing up the medicine...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>598</th>\n",
              "      <td>goldfinger</td>\n",
              "      <td>mable</td>\n",
              "      <td>i met her sunday that was yesterday newline th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>599</th>\n",
              "      <td>dr dre</td>\n",
              "      <td>forgot about dre</td>\n",
              "      <td>know me still the same og but i been newline h...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>600 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             Artist                       Song Name  \\\n",
              "0        elton john              candle in the wind   \n",
              "1    gerry rafferty                    baker street   \n",
              "2    gerry rafferty             right down the line   \n",
              "3       2 unlimited                    tribal dance   \n",
              "4       2 unlimited  let the beat control your body   \n",
              "..              ...                             ...   \n",
              "595      don henley                   dirty laundry   \n",
              "596      don henley                 new york minute   \n",
              "597       bob dylan     subterranean homesick blues   \n",
              "598      goldfinger                           mable   \n",
              "599          dr dre                forgot about dre   \n",
              "\n",
              "                                                Lyrics  \n",
              "0    goodbye norma jean newline though i never knew...  \n",
              "1    winding your way down on baker street newline ...  \n",
              "2    you know i need your love newline got that hol...  \n",
              "3    come on check it out newline come on come on n...  \n",
              "4    let the beat control your body newline let the...  \n",
              "..                                                 ...  \n",
              "595  i make my living off the evening news newline ...  \n",
              "596  harry got up newline dressed all in black newl...  \n",
              "597  in the basement newline mixing up the medicine...  \n",
              "598  i met her sunday that was yesterday newline th...  \n",
              "599  know me still the same og but i been newline h...  \n",
              "\n",
              "[600 rows x 3 columns]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train = pd.read_csv(train_file, header=None)\n",
        "train = train[[0,1,2]]\n",
        "train.columns = ['Artist', 'Song Name', 'Lyrics']\n",
        "train['Lyrics'] = train['Lyrics'].apply(clean_text)\n",
        "train['Lyrics'] = train['Lyrics'].apply(lambda x: ' '.join(re.sub(r'[^\\w\\s]', '', x).split()))\n",
        "train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "qf84cWhO3lI-",
        "outputId": "e98b5bd9-7cf3-4f8a-ce37-d1d83653c829"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Artist</th>\n",
              "      <th>Song Name</th>\n",
              "      <th>Lyrics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>the bangles</td>\n",
              "      <td>eternal flame</td>\n",
              "      <td>close your eyes give me your hand darling newl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>billy joel</td>\n",
              "      <td>honesty</td>\n",
              "      <td>if you search for tenderness newline it isnt h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cardigans</td>\n",
              "      <td>lovefool</td>\n",
              "      <td>dear i fear were facing a problem newline you ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>aqua</td>\n",
              "      <td>barbie girl</td>\n",
              "      <td>hiya barbie newline hi ken newline do you want...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>blink 182</td>\n",
              "      <td>all the small things</td>\n",
              "      <td>all the small things newline true care truth b...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Artist              Song Name  \\\n",
              "0  the bangles          eternal flame   \n",
              "1   billy joel                honesty   \n",
              "2    cardigans               lovefool   \n",
              "3         aqua            barbie girl   \n",
              "4    blink 182   all the small things   \n",
              "\n",
              "                                              Lyrics  \n",
              "0  close your eyes give me your hand darling newl...  \n",
              "1  if you search for tenderness newline it isnt h...  \n",
              "2  dear i fear were facing a problem newline you ...  \n",
              "3  hiya barbie newline hi ken newline do you want...  \n",
              "4  all the small things newline true care truth b...  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test = pd.read_csv(test_file, header=None )\n",
        "test = test[[0,1,2]]\n",
        "test.columns = ['Artist', 'Song Name', 'Lyrics']\n",
        "test['Lyrics'] = test['Lyrics'].str.replace('&', 'newline')\n",
        "test['Lyrics'] = test['Lyrics'].apply(lambda x: ' '.join(re.sub(r'[^\\w\\s]', '', x).split()))\n",
        "test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1YcoxBdyqhT"
      },
      "source": [
        "# **Word2vec**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnZdcbwF1eN_"
      },
      "source": [
        "## Save the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lL-e1m89AgEU",
        "outputId": "865f5a6a-3d5f-447b-b8c2-8ac72071c6e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ],
      "source": [
        "word2vec = gensim_load('word2vec-google-news-300')\n",
        "word2vec.save('/home/tak/justice-tal/content/drive/MyDrive/DL3/word2vec-google-news-300.gensim')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21ZIFxciyzIg",
        "outputId": "63de8df3-091a-4cc0-a1c0-9546ec1fb202"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 31.6/31.6MB downloaded\n"
          ]
        }
      ],
      "source": [
        "# Download the text8 corpus\n",
        "corpus = api.load('text8')\n",
        "\n",
        "# Convert the corpus to the format required by Word2Vec\n",
        "sentences = [list(doc) for doc in corpus]\n",
        "\n",
        "# Train the Word2Vec model with a vector size of 300\n",
        "word_model = Word2Vec(sentences=sentences, vector_size=300, window=5, min_count=1, workers=8)\n",
        "\n",
        "# Save the trained model\n",
        "word_model.save(\"w2v_text8\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xErnUNXD1OGL"
      },
      "outputs": [],
      "source": [
        "# Save the trained model to Google Drive\n",
        "save_path = \"/home/tak/justice-tal/content/drive/MyDrive/DL3/w2v_text8.model\"\n",
        "word_model.save(save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPQaQgwH1h7W"
      },
      "source": [
        "## Load the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TE4hzpnL2Odh"
      },
      "source": [
        "### text8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDYqEPYX1Zzt"
      },
      "outputs": [],
      "source": [
        "model_path = \"/home/tak/justice-tal/content/drive/MyDrive/DL3/w2v_text8.model\"\n",
        "word_model = Word2Vec.load(model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_3-QRlM2Odh"
      },
      "source": [
        "### google news"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bvH4KwwdAgEX"
      },
      "outputs": [],
      "source": [
        "model_path = \"/home/tak/justice-tal/content/drive/MyDrive/DL3/word2vec-google-news-300.gensim\"\n",
        "word_model = KeyedVectors.load(model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOVsRHeA2Odi"
      },
      "source": [
        "### glove"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPyZOg6M2Odi"
      },
      "outputs": [],
      "source": [
        "# word_model = {}\n",
        "# embedding = []\n",
        "# idx2word = []\n",
        "\n",
        "# with open('/home/tak/justice-tal/content/drive/MyDrive/DL3/glove.6B.300d.txt', encoding='utf-8') as f:\n",
        "#     # is just a space-separated text file in the format:\n",
        "#     # word vec[0] vec[1] vec[2] ...\n",
        "#     for line in f:\n",
        "#         values = line.split()\n",
        "#         word = values[0]\n",
        "#         vec = np.asarray(values[1:], dtype='float32')\n",
        "#         word_model[word] = vec\n",
        "#         embedding.append(vec)\n",
        "#         idx2word.append(word)\n",
        "\n",
        "# # save the word_model\n",
        "# with open('/home/tak/justice-tal/content/drive/MyDrive/DL3/glove.6B.300d.pkl', 'wb') as f:\n",
        "#     pickle.dump(word_model, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4NIRKwQLMwD"
      },
      "source": [
        "# **Function for create data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QI6M5UG_RW6a"
      },
      "outputs": [],
      "source": [
        "def rename_files_to_lowercase(directory_path):\n",
        "    for filename in os.listdir(directory_path):\n",
        "        if filename != filename.lower():\n",
        "            if filename=='depeche_mode_-_enjoy_the_silence.mid':\n",
        "              filename = 'depeche_mode_-_enjoy_the_silence-2.mid'\n",
        "\n",
        "            elif filename=='eric_clapton_-_wonderful_tonight.mid':\n",
        "              filename = 'eric_clapton_-_wonderful_tonight_-_live_extnd_version_@jiji@.mid'\n",
        "\n",
        "            elif filename=='ed_sheeran_-_thinking_out_loud.mid':\n",
        "              filename = 'ed_sheeran_-_thinking_out_loud_-_violin.mid'\n",
        "            # Create new file name with all lowercase letters\n",
        "            new_filename = filename.lower()\n",
        "            # Construct full file paths\n",
        "            old_file_path = os.path.join(directory_path, filename)\n",
        "            new_file_path = os.path.join(directory_path, new_filename)\n",
        "            # Rename the file\n",
        "            os.rename(old_file_path, new_file_path)\n",
        "rename_files_to_lowercase('/home/tak/justice-tal/content/drive/MyDrive/DL3/midi_files')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzVxohw32Odi"
      },
      "outputs": [],
      "source": [
        "def clean_text(song_lyrics):\n",
        "    # Replace unwanted characters and patterns\n",
        "    replacements = {\n",
        "        '&': 'newline',\n",
        "        '  ': ' ',\n",
        "        '\\'': '',\n",
        "        '--': ' ',\n",
        "    }\n",
        "    for old, new in replacements.items():\n",
        "        song_lyrics = song_lyrics.replace(old, new)\n",
        "\n",
        "    # Tokenize and clean tokens\n",
        "    tokens = song_lyrics.split()\n",
        "    tokens = [word.translate(str.maketrans('', '', string.punctuation)) for word in tokens]  # Remove punctuation\n",
        "    tokens = [word for word in tokens if word.isalpha()]  # Keep only alphabetic tokens\n",
        "    tokens = [word.lower() for word in tokens if word.lower() in word_model.wv]  # Convert to lowercase and check in vocabulary\n",
        "\n",
        "    # Join cleaned tokens back into a single string\n",
        "    return ' '.join(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJ7NGSHHZbA8"
      },
      "outputs": [],
      "source": [
        "def csv2df(df_path, is_test=False):\n",
        "    df1 = pd.read_csv(df_path, header=None)\n",
        "    df = df1.iloc[:, :3]\n",
        "    df.columns = ['Artist', 'Name', 'Lyrics']\n",
        "    #replace with the function that cleans the text\n",
        "    df['Lyrics'] = df['Lyrics'].apply(clean_text)\n",
        "    df['Lyrics'] = df['Lyrics'].apply(lambda x: ' '.join(re.sub(r'[^\\w\\s]', '', x).split()))\n",
        "    # Create the 'path' column by combining 'Artist' and 'Name' with \"_-_\"\n",
        "    if is_test == False:\n",
        "      df['Path'] = df.apply(lambda row: f\"/home/tak/justice-tal/content/drive/MyDrive/DL3/midi_files/{row['Artist'].replace(' ', '_')}_-_{row['Name'].replace(' ', '_')}.mid\", axis=1)\n",
        "      return df\n",
        "    else:\n",
        "      df['Path'] = df.apply(lambda row: f\"/home/tak/justice-tal/content/drive/MyDrive/DL3/midi_files/{row['Artist'].replace(' ', '_')}_-{row['Name'].replace(' ', '_')}.mid\", axis=1)\n",
        "      return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYQsrlei2Odi",
        "outputId": "d5397f61-bb1a-4f1a-ec97-b5f3b65bd16c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_1783929/1791170600.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['Lyrics'] = df['Lyrics'].apply(clean_text)\n",
            "/tmp/ipykernel_1783929/1791170600.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['Lyrics'] = df['Lyrics'].apply(lambda x: ' '.join(re.sub(r'[^\\w\\s]', '', x).split()))\n",
            "/tmp/ipykernel_1783929/1791170600.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['Path'] = df.apply(lambda row: f\"/home/tak/justice-tal/content/drive/MyDrive/DL3/midi_files/{row['Artist'].replace(' ', '_')}_-_{row['Name'].replace(' ', '_')}.mid\", axis=1)\n",
            "Processing Rows: 100%|██████████| 600/600 [00:00<00:00, 25646.44it/s]\n"
          ]
        }
      ],
      "source": [
        "df = csv2df('/home/tak/justice-tal/content/drive/MyDrive/DL3/lyrics_train_set.csv',is_test=False)\n",
        "X_input = []\n",
        "Y_target = []\n",
        "words_not_in_w2v = set()\n",
        "# save all the token in the lyrics\n",
        "all_tokens = []\n",
        "for i, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Processing Rows\"):\n",
        "    # Extract lyrics and MIDI path\n",
        "    lyrics = row['Lyrics'].split(\" \")\n",
        "    all_tokens.extend(lyrics)\n",
        "token_counts = {token: all_tokens.count(token) for token in set(all_tokens)}\n",
        "tokens_to_keep = [\n",
        "    token for token, count in token_counts.items()\n",
        "    if count >= 10 or token in word_model.wv\n",
        "]\n",
        "tokens_to_keep = list(set(tokens_to_keep))  # Ensure uniqueness\n",
        "reduced_vectors = np.zeros((len(tokens_to_keep), 300))  # +1 for <UNK> token\n",
        "reduced_vocab = {}  # Map <UNK> token to index 0\n",
        "voc_idx = {}\n",
        "for idx, token in enumerate(tokens_to_keep, start=0):  # Start indexing at 1\n",
        "    if token in word_model.wv:\n",
        "        reduced_vectors[idx] = word_model.wv[token]\n",
        "    else:\n",
        "        reduced_vectors[idx] = np.random.uniform(-0.1, 0.1, 300)\n",
        "    reduced_vocab[token] = idx\n",
        "    voc_idx[idx] = token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uLe2ugPN2Odj"
      },
      "outputs": [],
      "source": [
        "def extract_features_from_melody(index_word, ticks_per_beat, midi_file):\n",
        "    \"\"\"\n",
        "    Extracts musical features for a specific time window from a MIDI file.\n",
        "\n",
        "    Parameters:\n",
        "        index_word (int): The index representing the word position in the MIDI timeline.\n",
        "        ticks_per_beat (int): The duration of one word in ticks (time per division).\n",
        "        midi_file (pretty_midi.PrettyMIDI): The MIDI file to analyze.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: A feature vector containing various musical attributes for the time window.\n",
        "    \"\"\"\n",
        "    # Define the time window\n",
        "    start_time = index_word * ticks_per_beat\n",
        "    end_time = start_time + ticks_per_beat\n",
        "\n",
        "    # Initialize feature variables\n",
        "    average_velocity = 0\n",
        "    average_pitch = 0\n",
        "    average_programs = 0\n",
        "    num_instruments = 0\n",
        "    num_notes = 0\n",
        "    has_drums = 0\n",
        "    onset_density = 0\n",
        "    note_durations = []\n",
        "    programs = []\n",
        "    pitch_class_histogram = np.zeros(12)  # 12 pitch classes in an octave\n",
        "    key_changes = midi_file.key_signature_changes\n",
        "    key = key_changes[0].key_number if key_changes else 0\n",
        "\n",
        "    _, temp = midi_file.get_tempo_changes()\n",
        "    tempo = temp[0] if len(temp) > 0 else 120\n",
        "    tempo_normalized = tempo / 300\n",
        "\n",
        "    # Iterate through instruments and their notes\n",
        "    for instrument in midi_file.instruments:\n",
        "        instrument_in_range = False\n",
        "        for note in instrument.notes:\n",
        "            if start_time <= note.start < end_time and note.end <= end_time:\n",
        "                if instrument.is_drum:\n",
        "                    has_drums = 1\n",
        "                instrument_in_range = True\n",
        "                num_notes += 1\n",
        "                average_pitch += note.pitch\n",
        "                average_velocity += note.velocity\n",
        "                note_durations.append(note.end - note.start)\n",
        "                pitch_class_histogram[note.pitch % 12] += 1\n",
        "                programs.append(instrument.program)\n",
        "\n",
        "            elif note.start >= end_time:\n",
        "                break  # Stop processing notes outside the time window\n",
        "\n",
        "        if instrument_in_range:\n",
        "            num_instruments += 1\n",
        "\n",
        "    # Calculate aggregate features\n",
        "    if num_notes > 0:\n",
        "        average_velocity /= num_notes\n",
        "        average_pitch /= num_notes\n",
        "        onset_density = num_notes / (end_time - start_time)\n",
        "        average_programs /= num_notes\n",
        "\n",
        "    if note_durations:\n",
        "        note_durations = np.array(note_durations)\n",
        "        mean_duration = np.mean(note_durations)\n",
        "        variance_duration = np.var(note_durations)\n",
        "    else:\n",
        "        mean_duration = 0\n",
        "        variance_duration = 0\n",
        "\n",
        "    # Combine features into a final feature vector\n",
        "    final_features = np.concatenate((\n",
        "        np.array([\n",
        "            tempo_normalized,\n",
        "            key,\n",
        "            average_programs,\n",
        "            average_velocity,\n",
        "            average_pitch,\n",
        "            num_instruments,\n",
        "            has_drums,\n",
        "            onset_density,\n",
        "            mean_duration,\n",
        "            variance_duration,\n",
        "            0,  # Placeholder for unused chroma features\n",
        "            0,  # Placeholder for unused chroma features\n",
        "            0   # Placeholder for unused chroma features\n",
        "        ]),\n",
        "        pitch_class_histogram\n",
        "    ), axis=0)\n",
        "\n",
        "    return final_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VX0HfbOy3q0w"
      },
      "outputs": [],
      "source": [
        "def extract_piano_roll_features(num_of_notes_per_word, piano_roll, word_idx):\n",
        "    start_idx = word_idx * num_of_notes_per_word\n",
        "    end_idx = start_idx + num_of_notes_per_word\n",
        "    piano_roll_for_lyric = piano_roll[:, start_idx:end_idx].transpose()\n",
        "    piano_roll_slice_sum = np.sum(piano_roll_for_lyric, axis=0)  # Sum each column into a single cell\n",
        "    return piano_roll_slice_sum\n",
        "\n",
        "def prepare_train(df_path):\n",
        "    \"\"\"\n",
        "    Prepares the training dataset by extracting features from MIDI files and corresponding lyrics.\n",
        "\n",
        "    Parameters:\n",
        "        df_path (str): Path to the CSV file containing lyrics and MIDI file paths.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing:\n",
        "            - X_input (list): Combined tensors of word embeddings and MIDI features.\n",
        "            - Y_target (list): Target word embeddings.\n",
        "    \"\"\"\n",
        "    # Load the dataframe\n",
        "    df = csv2df(df_path,is_test=False)\n",
        "    X_input = []\n",
        "    Y_target = []\n",
        "    words_not_in_w2v = set()\n",
        "    # save all the token in the lyrics\n",
        "    all_tokens = []\n",
        "    for i, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Processing Rows\"):\n",
        "        # Extract lyrics and MIDI path\n",
        "        lyrics = row['Lyrics'].split(\" \")\n",
        "        all_tokens.extend(lyrics)\n",
        "    token_counts = {token: all_tokens.count(token) for token in set(all_tokens)}\n",
        "    tokens_to_keep = [\n",
        "        token for token, count in token_counts.items()\n",
        "        if count >= 10 or token in word_model.wv\n",
        "    ]\n",
        "    tokens_to_keep = list(set(tokens_to_keep))  # Ensure uniqueness\n",
        "    reduced_vectors = np.zeros((len(tokens_to_keep), 300))  # +1 for <UNK> token\n",
        "    reduced_vocab = {}  # Map <UNK> token to index 0\n",
        "    voc_idx = {}\n",
        "    for idx, token in enumerate(tokens_to_keep, start=0):  # Start indexing at 1\n",
        "        if token in word_model.wv:\n",
        "            reduced_vectors[idx] = word_model.wv[token]\n",
        "        else:\n",
        "            reduced_vectors[idx] = np.random.uniform(-0.1, 0.1, 300)\n",
        "        reduced_vocab[token] = idx\n",
        "        voc_idx[idx] = token\n",
        "    reduced_vectors = torch.tensor(reduced_vectors, dtype=torch.float32)\n",
        "\n",
        "    for i, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Processing Rows\"):\n",
        "        # Extract lyrics and MIDI path\n",
        "        lyrics = row['Lyrics'].split(\" \")\n",
        "        midi_path = row['Path']\n",
        "\n",
        "        # Attempt to load MIDI data\n",
        "        try:\n",
        "            midi_pretty_data = pretty_midi.PrettyMIDI(midi_path)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {midi_path}: {e}\")\n",
        "            continue\n",
        "\n",
        "        # Calculate MIDI-related features\n",
        "        avg_time = midi_pretty_data.get_end_time() / len(lyrics)\n",
        "        beat_intervals = [\n",
        "            x - midi_pretty_data.get_beats()[i - 1]\n",
        "            for i, x in enumerate(midi_pretty_data.get_beats())\n",
        "        ][1:]\n",
        "        beat_freq = np.mean(beat_intervals) if beat_intervals else 0\n",
        "        num_instruments = len(midi_pretty_data.instruments)\n",
        "        chroma = midi_pretty_data.get_chroma().mean(axis=1) if midi_pretty_data.get_chroma().size > 0 else np.zeros(12)\n",
        "        midi_pretty_data.remove_invalid_notes()\n",
        "        num_of_words_in_song = len(lyrics)\n",
        "        piano_roll = midi_pretty_data.get_piano_roll(fs=50)\n",
        "        num_of_notes_per_word = int(piano_roll.shape[1] / num_of_words_in_song)  # Num of piano roll columns per word\n",
        "        # Process each word in the lyrics (excluding the last one)\n",
        "        for i in range(len(lyrics) - 1):\n",
        "            current_word = lyrics[i]\n",
        "            next_word = lyrics[i + 1]\n",
        "            # Extract MIDI features for the current word\n",
        "            try:\n",
        "                word_melody = extract_features_from_melody(i, avg_time, midi_pretty_data)\n",
        "            except Exception as e:\n",
        "                print(f\"Error extracting features for word {i} in {midi_path}: {e}\")\n",
        "                continue\n",
        "            notes_features = extract_piano_roll_features(num_of_notes_per_word, piano_roll, i)\n",
        "            # Update extracted MIDI features with additional data\n",
        "            word_melody[5] = num_instruments  # Update the number of instruments\n",
        "            word_melody[10] = beat_freq       # Update the beat frequency\n",
        "            word_melody[11:11 + 12] = chroma   # Update the chroma features\n",
        "            word_melody = np.concatenate((word_melody, notes_features), axis=0)\n",
        "            # normalize word_melody\n",
        "            scaler = MinMaxScaler()\n",
        "            word_melody = scaler.fit_transform(word_melody.reshape(-1, 1)).flatten()\n",
        "            # Check if both words are in the Word2Vec model's vocabulary\n",
        "            if current_word in word_model.wv and next_word in word_model.wv:\n",
        "                # Convert current word embedding to a tensor\n",
        "                current_word_tensor = torch.tensor(word_model.wv[current_word])\n",
        "                # Convert MIDI features to a tensor\n",
        "                word_melody_tensor = torch.from_numpy(word_melody).float()\n",
        "                # Concatenate word embedding and MIDI features\n",
        "                combined_tensor = torch.cat((current_word_tensor, word_melody_tensor), dim=0)\n",
        "                # Append tensors to the training data\n",
        "                X_input.append(combined_tensor)\n",
        "\n",
        "                # Prepare one-hot target vector\n",
        "                next_word_index = reduced_vocab[next_word]  # Get the index of the next word\n",
        "                one_hot_target = torch.zeros(len(reduced_vocab)).to(device)  # Create a zero vector of vocab size\n",
        "                one_hot_target[next_word_index] = 1.0  # Set the target index to 1\n",
        "                Y_target.append(one_hot_target)\n",
        "\n",
        "\n",
        "            else:\n",
        "                # Add words not in Word2Vec vocabulary to a tracking set\n",
        "                words_not_in_w2v.update({current_word, next_word})\n",
        "\n",
        "    return X_input, Y_target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oAowKQTHR5gb"
      },
      "outputs": [],
      "source": [
        "def prepare_test(df_path):\n",
        "    \"\"\"\n",
        "    Prepares the test dataset by extracting features from MIDI files and corresponding lyrics.\n",
        "\n",
        "    Parameters:\n",
        "        df_path (str): Path to the CSV file containing lyrics and MIDI file paths.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of lists, where each inner list contains tensors of MIDI features for a song's lyrics.\n",
        "    \"\"\"\n",
        "    # Load the test dataframe\n",
        "    df = csv2df(df_path, is_test=True)\n",
        "    X_input = []\n",
        "    words_not_in_w2v = set()\n",
        "\n",
        "    for i, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Processing Rows\"):\n",
        "        # Extract lyrics and MIDI path\n",
        "        lyrics = row['Lyrics'].split(\" \")\n",
        "        midi_path = row['Path']\n",
        "        print(f\"Processing MIDI file: {midi_path}\")\n",
        "\n",
        "        # Attempt to load MIDI data\n",
        "        try:\n",
        "            midi_pretty_data = pretty_midi.PrettyMIDI(midi_path)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {midi_path}: {e}\")\n",
        "            continue\n",
        "\n",
        "        # Calculate MIDI-related features\n",
        "        avg_time = midi_pretty_data.get_end_time() / len(lyrics)\n",
        "        beat_intervals = [\n",
        "            x - midi_pretty_data.get_beats()[i - 1]\n",
        "            for i, x in enumerate(midi_pretty_data.get_beats())\n",
        "        ][1:]\n",
        "        beat_freq = np.mean(beat_intervals) if beat_intervals else 0\n",
        "        chroma = midi_pretty_data.get_chroma().mean(axis=1) if midi_pretty_data.get_chroma().size > 0 else np.zeros(12)\n",
        "        num_instruments = len(midi_pretty_data.instruments)\n",
        "        midi_pretty_data.remove_invalid_notes()\n",
        "\n",
        "        num_of_words_in_song = len(lyrics)\n",
        "\n",
        "        piano_roll = midi_pretty_data.get_piano_roll(fs=50)\n",
        "        num_of_notes_per_word = int(piano_roll.shape[1] / num_of_words_in_song)  # Num of piano roll columns per word\n",
        "\n",
        "        # Process each word in the lyrics (excluding the last one)\n",
        "        curr_song = []\n",
        "        for j in range(len(lyrics) - 1):\n",
        "            try:\n",
        "                # Extract MIDI features for the current word\n",
        "                word_melody = extract_features_from_melody(j, avg_time, midi_pretty_data)\n",
        "                notes_features = extract_piano_roll_features(num_of_notes_per_word, piano_roll, i)\n",
        "\n",
        "                # Update MIDI features with additional data\n",
        "                word_melody[5] = num_instruments  # Update the number of instruments\n",
        "                word_melody[10] = beat_freq        # Update the beat frequency\n",
        "                word_melody[11:11 + 12] = chroma    # Update the chroma features\n",
        "                word_melody = np.concatenate((word_melody, notes_features), axis=0)\n",
        "\n",
        "\n",
        "                # normalize word_melody\n",
        "                scaler = MinMaxScaler()\n",
        "                word_melody = scaler.fit_transform(word_melody.reshape(-1, 1)).flatten()\n",
        "                # Convert the features to a tensor and append to the current song list\n",
        "                curr_song.append(torch.from_numpy(word_melody).float())\n",
        "            except Exception as e:\n",
        "                print(f\"Error extracting features for word {j} in {midi_path}: {e}\")\n",
        "                continue\n",
        "\n",
        "        # Append the song's features to the input list\n",
        "        X_input.append(curr_song)\n",
        "\n",
        "    return X_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xS94In712Odj"
      },
      "outputs": [],
      "source": [
        "def prepare_train_2(df_path):\n",
        "    \"\"\"\n",
        "    Prepares the training dataset by extracting features from MIDI files and corresponding lyrics.\n",
        "\n",
        "    Parameters:\n",
        "        df_path (str): Path to the CSV file containing lyrics and MIDI file paths.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing:\n",
        "            - X_input (list): Combined tensors of word embeddings and MIDI features.\n",
        "            - Y_target (list): Target word embeddings.\n",
        "    \"\"\"\n",
        "    # Load the dataframe\n",
        "    df = csv2df(df_path,is_test=False)\n",
        "    X_input = []\n",
        "    Y_target = []\n",
        "    words_not_in_w2v = set()\n",
        "    # save all the token in the lyrics\n",
        "    all_tokens = []\n",
        "    for i, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Processing Rows\"):\n",
        "        # Extract lyrics and MIDI path\n",
        "        lyrics = row['Lyrics'].split(\" \")\n",
        "        all_tokens.extend(lyrics)\n",
        "    token_counts = {token: all_tokens.count(token) for token in set(all_tokens)}\n",
        "    tokens_to_keep = [\n",
        "        token for token, count in token_counts.items()\n",
        "        if count >= 10 or token in word_model.wv\n",
        "    ]\n",
        "    tokens_to_keep = list(set(tokens_to_keep))  # Ensure uniqueness\n",
        "    reduced_vectors = np.zeros((len(tokens_to_keep), 300))  # +1 for <UNK> token\n",
        "    reduced_vocab = {}  # Map <UNK> token to index 0\n",
        "    voc_idx = {}\n",
        "    for idx, token in enumerate(tokens_to_keep, start=0):  # Start indexing at 1\n",
        "        if token in word_model.wv:\n",
        "            reduced_vectors[idx] = word_model.wv[token]\n",
        "        else:\n",
        "            reduced_vectors[idx] = np.random.uniform(-0.1, 0.1, 300)\n",
        "        reduced_vocab[token] = idx\n",
        "        voc_idx[idx] = token\n",
        "    reduced_vectors = torch.tensor(reduced_vectors, dtype=torch.float32)\n",
        "\n",
        "    for i, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Processing Rows\"):\n",
        "        # Extract lyrics and MIDI path\n",
        "        lyrics = row['Lyrics'].split(\" \")\n",
        "        midi_path = row['Path']\n",
        "\n",
        "        # Attempt to load MIDI data\n",
        "        try:\n",
        "            midi_pretty_data = pretty_midi.PrettyMIDI(midi_path)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {midi_path}: {e}\")\n",
        "            continue\n",
        "\n",
        "        # Calculate MIDI-related features\n",
        "        avg_time = midi_pretty_data.get_end_time() / len(lyrics)\n",
        "        beat_intervals = [\n",
        "            x - midi_pretty_data.get_beats()[i - 1]\n",
        "            for i, x in enumerate(midi_pretty_data.get_beats())\n",
        "        ][1:]\n",
        "        beat_freq = np.mean(beat_intervals) if beat_intervals else 0\n",
        "        num_instruments = len(midi_pretty_data.instruments)\n",
        "        chroma = midi_pretty_data.get_chroma().mean(axis=1) if midi_pretty_data.get_chroma().size > 0 else np.zeros(12)\n",
        "        midi_pretty_data.remove_invalid_notes()\n",
        "        # Process each word in the lyrics (excluding the last one)\n",
        "        for i in range(len(lyrics) - 1):\n",
        "            current_word = lyrics[i]\n",
        "            next_word = lyrics[i + 1]\n",
        "            # Extract MIDI features for the current word\n",
        "            try:\n",
        "                word_melody = extract_features_from_melody(i, avg_time, midi_pretty_data)\n",
        "            except Exception as e:\n",
        "                print(f\"Error extracting features for word {i} in {midi_path}: {e}\")\n",
        "                continue\n",
        "            # Update extracted MIDI features with additional data\n",
        "            word_melody[5] = num_instruments  # Update the number of instruments\n",
        "            word_melody[10] = beat_freq       # Update the beat frequency\n",
        "            word_melody[11:11 + 12] = chroma   # Update the chroma features\n",
        "            # normalize word_melody\n",
        "            scaler = MinMaxScaler()\n",
        "            word_melody = scaler.fit_transform(word_melody.reshape(-1, 1)).flatten()\n",
        "            # Check if both words are in the Word2Vec model's vocabulary\n",
        "            if current_word in word_model.wv and next_word in word_model.wv:\n",
        "                # Convert current word embedding to a tensor\n",
        "                current_word_tensor = torch.tensor(word_model.wv[current_word])\n",
        "                # Convert MIDI features to a tensor\n",
        "                word_melody_tensor = torch.from_numpy(word_melody).float()\n",
        "                # Concatenate word embedding and MIDI features\n",
        "                combined_tensor = torch.cat((current_word_tensor, word_melody_tensor), dim=0)\n",
        "                # Append tensors to the training data\n",
        "                X_input.append(combined_tensor)\n",
        "\n",
        "                # Prepare one-hot target vector\n",
        "                next_word_index = reduced_vocab[next_word]  # Get the index of the next word\n",
        "                one_hot_target = torch.zeros(len(reduced_vocab)).to(device)  # Create a zero vector of vocab size\n",
        "                one_hot_target[next_word_index] = 1.0  # Set the target index to 1\n",
        "                Y_target.append(one_hot_target)\n",
        "\n",
        "\n",
        "            else:\n",
        "                # Add words not in Word2Vec vocabulary to a tracking set\n",
        "                words_not_in_w2v.update({current_word, next_word})\n",
        "\n",
        "    return X_input, Y_target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0NEhFPie2Odk"
      },
      "outputs": [],
      "source": [
        "def prepare_test_2(df_path):\n",
        "    \"\"\"\n",
        "    Prepares the test dataset by extracting features from MIDI files and corresponding lyrics.\n",
        "\n",
        "    Parameters:\n",
        "        df_path (str): Path to the CSV file containing lyrics and MIDI file paths.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of lists, where each inner list contains tensors of MIDI features for a song's lyrics.\n",
        "    \"\"\"\n",
        "    # Load the test dataframe\n",
        "    df = csv2df(df_path, is_test=True)\n",
        "    X_input = []\n",
        "    words_not_in_w2v = set()\n",
        "\n",
        "    for i, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Processing Rows\"):\n",
        "        # Extract lyrics and MIDI path\n",
        "        lyrics = row['Lyrics'].split(\" \")\n",
        "        midi_path = row['Path']\n",
        "        print(f\"Processing MIDI file: {midi_path}\")\n",
        "\n",
        "        # Attempt to load MIDI data\n",
        "        try:\n",
        "            midi_pretty_data = pretty_midi.PrettyMIDI(midi_path)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {midi_path}: {e}\")\n",
        "            continue\n",
        "\n",
        "        # Calculate MIDI-related features\n",
        "        avg_time = midi_pretty_data.get_end_time() / len(lyrics)\n",
        "        beat_intervals = [\n",
        "            x - midi_pretty_data.get_beats()[i - 1]\n",
        "            for i, x in enumerate(midi_pretty_data.get_beats())\n",
        "        ][1:]\n",
        "        beat_freq = np.mean(beat_intervals) if beat_intervals else 0\n",
        "        chroma = midi_pretty_data.get_chroma().mean(axis=1) if midi_pretty_data.get_chroma().size > 0 else np.zeros(12)\n",
        "        num_instruments = len(midi_pretty_data.instruments)\n",
        "        midi_pretty_data.remove_invalid_notes()\n",
        "\n",
        "        # Process each word in the lyrics (excluding the last one)\n",
        "        curr_song = []\n",
        "        for j in range(len(lyrics) - 1):\n",
        "            try:\n",
        "                # Extract MIDI features for the current word\n",
        "                word_melody = extract_features_from_melody(j, avg_time, midi_pretty_data)\n",
        "\n",
        "                # Update MIDI features with additional data\n",
        "                word_melody[5] = num_instruments  # Update the number of instruments\n",
        "                word_melody[10] = beat_freq        # Update the beat frequency\n",
        "                word_melody[11:11 + 12] = chroma    # Update the chroma features\n",
        "\n",
        "\n",
        "                # normalize word_melody\n",
        "                scaler = MinMaxScaler()\n",
        "                word_melody = scaler.fit_transform(word_melody.reshape(-1, 1)).flatten()\n",
        "                # Convert the features to a tensor and append to the current song list\n",
        "                curr_song.append(torch.from_numpy(word_melody).float())\n",
        "            except Exception as e:\n",
        "                print(f\"Error extracting features for word {j} in {midi_path}: {e}\")\n",
        "                continue\n",
        "\n",
        "        # Append the song's features to the input list\n",
        "        X_input.append(curr_song)\n",
        "\n",
        "    return X_input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTliULIwSrE2"
      },
      "source": [
        "# **Create and save data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awaR6IAj2Odk"
      },
      "source": [
        "## First Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "collapsed": true,
        "id": "uVnT-0xFHv3T",
        "outputId": "7e233fce-0911-4065-8769-e80b57cbc11d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_716480/1791170600.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['Lyrics'] = df['Lyrics'].apply(clean_text)\n",
            "/tmp/ipykernel_716480/1791170600.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['Lyrics'] = df['Lyrics'].apply(lambda x: ' '.join(re.sub(r'[^\\w\\s]', '', x).split()))\n",
            "/tmp/ipykernel_716480/1791170600.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['Path'] = df.apply(lambda row: f\"/home/tak/justice-tal/content/drive/MyDrive/DL3/midi_files/{row['Artist'].replace(' ', '_')}_-_{row['Name'].replace(' ', '_')}.mid\", axis=1)\n",
            "Processing Rows: 100%|██████████| 600/600 [00:00<00:00, 27142.33it/s]\n",
            "Processing Rows:   0%|          | 1/600 [00:00<07:19,  1.36it/s]/home/tak/.conda/envs/tal_env/lib/python3.12/site-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
            "  warnings.warn(\n",
            "Processing Rows:   1%|          | 7/600 [00:06<09:33,  1.03it/s]/home/tak/.conda/envs/tal_env/lib/python3.12/site-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
            "  warnings.warn(\n",
            "Processing Rows:   2%|▎         | 15/600 [00:12<12:10,  1.25s/it]/home/tak/.conda/envs/tal_env/lib/python3.12/site-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
            "  warnings.warn(\n",
            "Processing Rows:   3%|▎         | 20/600 [00:15<06:22,  1.51it/s]/home/tak/.conda/envs/tal_env/lib/python3.12/site-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
            "  warnings.warn(\n",
            "Processing Rows:   5%|▍         | 28/600 [00:21<07:45,  1.23it/s]/home/tak/.conda/envs/tal_env/lib/python3.12/site-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
            "  warnings.warn(\n",
            "Processing Rows:  10%|█         | 63/600 [00:47<06:45,  1.33it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X,Y \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_train_2\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/tak/justice-tal/content/drive/MyDrive/DL3/lyrics_train_set.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[14], line 80\u001b[0m, in \u001b[0;36mprepare_train_2\u001b[0;34m(df_path)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# normalize word_melody\u001b[39;00m\n\u001b[1;32m     79\u001b[0m scaler \u001b[38;5;241m=\u001b[39m MinMaxScaler()\n\u001b[0;32m---> 80\u001b[0m word_melody \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword_melody\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# Check if both words are in the Word2Vec model's vocabulary\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m current_word \u001b[38;5;129;01min\u001b[39;00m word_model\u001b[38;5;241m.\u001b[39mwv \u001b[38;5;129;01mand\u001b[39;00m next_word \u001b[38;5;129;01min\u001b[39;00m word_model\u001b[38;5;241m.\u001b[39mwv:\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;66;03m# Convert current word embedding to a tensor\u001b[39;00m\n",
            "File \u001b[0;32m~/.conda/envs/tal_env/lib/python3.12/site-packages/sklearn/utils/_set_output.py:295\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 295\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    298\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    299\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    300\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    301\u001b[0m         )\n",
            "File \u001b[0;32m~/.conda/envs/tal_env/lib/python3.12/site-packages/sklearn/base.py:1098\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m   1083\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1084\u001b[0m             (\n\u001b[1;32m   1085\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) has a `transform`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1093\u001b[0m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[1;32m   1094\u001b[0m         )\n\u001b[1;32m   1096\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1097\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[0;32m-> 1098\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m   1101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
            "File \u001b[0;32m~/.conda/envs/tal_env/lib/python3.12/site-packages/sklearn/utils/_set_output.py:295\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 295\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    298\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    299\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    300\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    301\u001b[0m         )\n",
            "File \u001b[0;32m~/.conda/envs/tal_env/lib/python3.12/site-packages/sklearn/preprocessing/_data.py:534\u001b[0m, in \u001b[0;36mMinMaxScaler.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    530\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    532\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m--> 534\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    536\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_array_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msupported_float_dtypes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    542\u001b[0m X \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_\n\u001b[1;32m    543\u001b[0m X \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_\n",
            "File \u001b[0;32m~/.conda/envs/tal_env/lib/python3.12/site-packages/sklearn/base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
            "File \u001b[0;32m~/.conda/envs/tal_env/lib/python3.12/site-packages/sklearn/utils/validation.py:1049\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1043\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1044\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1045\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m   1046\u001b[0m     )\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m-> 1049\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1051\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1053\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1054\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[1;32m   1057\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[1;32m   1058\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
            "File \u001b[0;32m~/.conda/envs/tal_env/lib/python3.12/site-packages/sklearn/utils/validation.py:122\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# First try an O(n) time, O(1) space solution for the common case that\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;66;03m# everything is finite; fall back to O(n) space `np.isinf/isnan` or custom\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m# Cython implementation to prevent false positives and provide a detailed\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m# error message.\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(over\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 122\u001b[0m     first_pass_isfinite \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39misfinite(\u001b[43mxp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
            "File \u001b[0;32m~/.conda/envs/tal_env/lib/python3.12/site-packages/numpy/core/fromnumeric.py:2313\u001b[0m, in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2310\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[1;32m   2311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[0;32m-> 2313\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2314\u001b[0m \u001b[43m                      \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.conda/envs/tal_env/lib/python3.12/site-packages/numpy/core/fromnumeric.py:72\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrapreduction\u001b[39m(obj, ufunc, method, axis, dtype, out, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 72\u001b[0m     passkwargs \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m     73\u001b[0m                   \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue}\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(obj) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mu\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "X,Y = prepare_train_2('/home/tak/justice-tal/content/drive/MyDrive/DL3/lyrics_train_set.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgZNrTt6WRlZ",
        "outputId": "fadfd429-591f-4094-d805-90a0840b952d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Rows:  20%|██        | 1/5 [00:00<00:00,  6.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing MIDI file: /home/tak/justice-tal/content/drive/MyDrive/DL3/midi_files/the_bangles_-_eternal_flame.mid\n",
            "Processing MIDI file: /home/tak/justice-tal/content/drive/MyDrive/DL3/midi_files/billy_joel_-_honesty.mid\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Rows:  40%|████      | 2/5 [00:00<00:00,  5.08it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing MIDI file: /home/tak/justice-tal/content/drive/MyDrive/DL3/midi_files/cardigans_-_lovefool.mid\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Rows:  60%|██████    | 3/5 [00:00<00:00,  3.55it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing MIDI file: /home/tak/justice-tal/content/drive/MyDrive/DL3/midi_files/aqua_-_barbie_girl.mid\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Rows:  80%|████████  | 4/5 [00:01<00:00,  2.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing MIDI file: /home/tak/justice-tal/content/drive/MyDrive/DL3/midi_files/blink_182_-_all_the_small_things.mid\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Rows: 100%|██████████| 5/5 [00:01<00:00,  2.66it/s]\n"
          ]
        }
      ],
      "source": [
        "X_test = prepare_test_2('/home/tak/justice-tal/content/drive/MyDrive/DL3/lyrics_test_set.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xztbljjwRnpT"
      },
      "outputs": [],
      "source": [
        "def save_to_pickle(data, filename):\n",
        "    with open(filename, 'wb') as f:\n",
        "        pickle.dump(data, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ev9-ZBTdRqxx"
      },
      "outputs": [],
      "source": [
        "save_to_pickle((X, Y), '/home/tak/justice-tal/content/drive/MyDrive/DL3/train_data_last_new_2.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERLLXvk3Zpf5"
      },
      "outputs": [],
      "source": [
        "save_to_pickle((X_test), '/home/tak/justice-tal/content/drive/MyDrive/DL3/test_data_last_new_2.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ng8cth32Odq"
      },
      "source": [
        "## Second Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jBiNxGGe2Odq",
        "outputId": "6fe14f99-4c6d-4983-ab43-c9da2ece98c7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_1783929/1791170600.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['Lyrics'] = df['Lyrics'].apply(clean_text)\n",
            "/tmp/ipykernel_1783929/1791170600.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['Lyrics'] = df['Lyrics'].apply(lambda x: ' '.join(re.sub(r'[^\\w\\s]', '', x).split()))\n",
            "/tmp/ipykernel_1783929/1791170600.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['Path'] = df.apply(lambda row: f\"/home/tak/justice-tal/content/drive/MyDrive/DL3/midi_files/{row['Artist'].replace(' ', '_')}_-_{row['Name'].replace(' ', '_')}.mid\", axis=1)\n",
            "Processing Rows: 100%|██████████| 600/600 [00:00<00:00, 24147.06it/s]\n",
            "Processing Rows:   0%|          | 1/600 [00:01<11:25,  1.14s/it]/home/tak/.conda/envs/tal_env/lib/python3.12/site-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
            "  warnings.warn(\n",
            "Processing Rows:   1%|          | 7/600 [00:06<10:17,  1.04s/it]/home/tak/.conda/envs/tal_env/lib/python3.12/site-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
            "  warnings.warn(\n",
            "Processing Rows:   2%|▎         | 15/600 [00:14<14:05,  1.44s/it]/home/tak/.conda/envs/tal_env/lib/python3.12/site-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
            "  warnings.warn(\n",
            "Processing Rows:   3%|▎         | 20/600 [00:17<06:45,  1.43it/s]/home/tak/.conda/envs/tal_env/lib/python3.12/site-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
            "  warnings.warn(\n",
            "Processing Rows:   5%|▍         | 28/600 [00:23<08:11,  1.16it/s]/home/tak/.conda/envs/tal_env/lib/python3.12/site-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
            "  warnings.warn(\n",
            "Processing Rows:  17%|█▋        | 101/600 [01:16<05:09,  1.61it/s]/home/tak/.conda/envs/tal_env/lib/python3.12/site-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
            "  warnings.warn(\n",
            "Processing Rows:  18%|█▊        | 108/600 [01:24<06:24,  1.28it/s]/home/tak/.conda/envs/tal_env/lib/python3.12/site-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
            "  warnings.warn(\n",
            "Processing Rows:  18%|█▊        | 109/600 [01:24<05:13,  1.57it/s]/home/tak/.conda/envs/tal_env/lib/python3.12/site-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
            "  warnings.warn(\n",
            "Processing Rows:  18%|█▊        | 110/600 [01:25<04:55,  1.66it/s]/home/tak/.conda/envs/tal_env/lib/python3.12/site-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
            "  warnings.warn(\n",
            "Processing Rows:  18%|█▊        | 111/600 [01:25<05:48,  1.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error processing /home/tak/justice-tal/content/drive/MyDrive/DL3/midi_files/beastie_boys_-_girls.mid: Could not decode key with 1 flats and mode 255\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Rows:  19%|█▉        | 116/600 [01:30<09:04,  1.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error processing /home/tak/justice-tal/content/drive/MyDrive/DL3/midi_files/eric_clapton_-_wonderful_tonight.mid: [Errno 2] No such file or directory: '/home/tak/justice-tal/content/drive/MyDrive/DL3/midi_files/eric_clapton_-_wonderful_tonight.mid'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Rows:  20%|██        | 121/600 [01:36<08:59,  1.13s/it]/home/tak/.conda/envs/tal_env/lib/python3.12/site-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
            "  warnings.warn(\n",
            "Processing Rows:  21%|██        | 125/600 [01:38<05:43,  1.38it/s]/home/tak/.conda/envs/tal_env/lib/python3.12/site-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
            "  warnings.warn(\n",
            "Processing Rows:  22%|██▏       | 132/600 [01:46<08:33,  1.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error processing /home/tak/justice-tal/content/drive/MyDrive/DL3/midi_files/billy_joel_-_movin'_out.mid: data byte must be in range 0..127\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Rows:  23%|██▎       | 139/600 [01:48<03:06,  2.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error processing /home/tak/justice-tal/content/drive/MyDrive/DL3/midi_files/billy_joel_-_pressure.mid: data byte must be in range 0..127\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Rows:  26%|██▌       | 157/600 [02:01<04:21,  1.70it/s]/home/tak/.conda/envs/tal_env/lib/python3.12/site-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
            "  warnings.warn(\n",
            "Processing Rows:  28%|██▊       | 165/600 [02:07<04:53,  1.48it/s]/home/tak/.conda/envs/tal_env/lib/python3.12/site-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
            "  warnings.warn(\n",
            "Processing Rows:  28%|██▊       | 171/600 [02:11<06:37,  1.08it/s]/home/tak/.conda/envs/tal_env/lib/python3.12/site-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
            "  warnings.warn(\n",
            "Processing Rows:  29%|██▉       | 174/600 [02:14<07:34,  1.07s/it]/home/tak/.conda/envs/tal_env/lib/python3.12/site-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
            "  warnings.warn(\n",
            "Processing Rows:  30%|███       | 181/600 [02:20<04:52,  1.43it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error processing /home/tak/justice-tal/content/drive/MyDrive/DL3/midi_files/dan_fogelberg_-_leader_of_the_band.mid: Could not decode key with 4 flats and mode 255\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Rows:  38%|███▊      | 228/600 [02:53<03:41,  1.68it/s]/home/tak/.conda/envs/tal_env/lib/python3.12/site-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
            "  warnings.warn(\n",
            "Processing Rows:  45%|████▍     | 268/600 [03:26<06:14,  1.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error processing /home/tak/justice-tal/content/drive/MyDrive/DL3/midi_files/depeche_mode_-_enjoy_the_silence.mid: [Errno 2] No such file or directory: '/home/tak/justice-tal/content/drive/MyDrive/DL3/midi_files/depeche_mode_-_enjoy_the_silence.mid'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Rows:  45%|████▌     | 270/600 [03:27<03:54,  1.40it/s]/home/tak/.conda/envs/tal_env/lib/python3.12/site-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
            "  warnings.warn(\n",
            "Processing Rows:  45%|████▌     | 271/600 [03:27<03:29,  1.57it/s]/home/tak/.conda/envs/tal_env/lib/python3.12/site-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error processing /home/tak/justice-tal/content/drive/MyDrive/DL3/midi_files/depeche_mode_-_enjoy_the_silence.mid: [Errno 2] No such file or directory: '/home/tak/justice-tal/content/drive/MyDrive/DL3/midi_files/depeche_mode_-_enjoy_the_silence.mid'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Rows:  46%|████▌     | 273/600 [03:28<02:29,  2.19it/s]/home/tak/.conda/envs/tal_env/lib/python3.12/site-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
            "  warnings.warn(\n",
            "Processing Rows:  48%|████▊     | 286/600 [03:40<05:42,  1.09s/it]/home/tak/.conda/envs/tal_env/lib/python3.12/site-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
            "  warnings.warn(\n",
            "Processing Rows:  49%|████▉     | 293/600 [03:48<05:05,  1.01it/s]/home/tak/.conda/envs/tal_env/lib/python3.12/site-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
            "  warnings.warn(\n",
            "Processing Rows:  50%|█████     | 303/600 [03:54<02:43,  1.81it/s]/home/tak/.conda/envs/tal_env/lib/python3.12/site-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
            "  warnings.warn(\n",
            "Processing Rows:  51%|█████     | 307/600 [03:56<03:10,  1.53it/s]/home/tak/.conda/envs/tal_env/lib/python3.12/site-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
            "  warnings.warn(\n",
            "Processing Rows:  52%|█████▏    | 309/600 [03:56<02:20,  2.07it/s]/home/tak/.conda/envs/tal_env/lib/python3.12/site-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
            "  warnings.warn(\n",
            "Processing Rows:  55%|█████▌    | 331/600 [04:15<03:27,  1.29it/s]/home/tak/.conda/envs/tal_env/lib/python3.12/site-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
            "  warnings.warn(\n",
            "Processing Rows:  63%|██████▎   | 376/600 [04:36<01:39,  2.24it/s]/home/tak/.conda/envs/tal_env/lib/python3.12/site-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
            "  warnings.warn(\n",
            "Processing Rows:  67%|██████▋   | 400/600 [04:57<02:14,  1.48it/s]/home/tak/.conda/envs/tal_env/lib/python3.12/site-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
            "  warnings.warn(\n",
            "Processing Rows:  70%|███████   | 422/600 [05:07<01:56,  1.53it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error processing /home/tak/justice-tal/content/drive/MyDrive/DL3/midi_files/ed_sheeran_-_thinking_out_loud.mid: [Errno 2] No such file or directory: '/home/tak/justice-tal/content/drive/MyDrive/DL3/midi_files/ed_sheeran_-_thinking_out_loud.mid'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Rows:  72%|███████▏  | 432/600 [05:11<01:33,  1.80it/s]/home/tak/.conda/envs/tal_env/lib/python3.12/site-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
            "  warnings.warn(\n",
            "Processing Rows:  78%|███████▊  | 467/600 [06:17<01:52,  1.18it/s]/home/tak/.conda/envs/tal_env/lib/python3.12/site-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
            "  warnings.warn(\n",
            "Processing Rows:  80%|███████▉  | 478/600 [06:26<01:43,  1.18it/s]/home/tak/.conda/envs/tal_env/lib/python3.12/site-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
            "  warnings.warn(\n",
            "Processing Rows:  80%|████████  | 482/600 [06:28<01:20,  1.46it/s]/home/tak/.conda/envs/tal_env/lib/python3.12/site-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
            "  warnings.warn(\n",
            "Processing Rows:  83%|████████▎ | 496/600 [06:36<00:47,  2.20it/s]/home/tak/.conda/envs/tal_env/lib/python3.12/site-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
            "  warnings.warn(\n",
            "Processing Rows:  83%|████████▎ | 499/600 [06:38<00:42,  2.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error processing /home/tak/justice-tal/content/drive/MyDrive/DL3/midi_files/brian_mcknight_-_on_the_down_low.mid: \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Rows:  85%|████████▌ | 512/600 [06:48<01:41,  1.16s/it]/home/tak/.conda/envs/tal_env/lib/python3.12/site-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
            "  warnings.warn(\n",
            "Processing Rows:  89%|████████▉ | 535/600 [07:09<00:57,  1.14it/s]/home/tak/.conda/envs/tal_env/lib/python3.12/site-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
            "  warnings.warn(\n",
            "Processing Rows:  90%|████████▉ | 537/600 [07:11<00:54,  1.16it/s]/home/tak/.conda/envs/tal_env/lib/python3.12/site-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
            "  warnings.warn(\n",
            "Processing Rows:  92%|█████████▏| 554/600 [07:25<01:16,  1.66s/it]/home/tak/.conda/envs/tal_env/lib/python3.12/site-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
            "  warnings.warn(\n",
            "Processing Rows:  93%|█████████▎| 557/600 [07:27<00:47,  1.10s/it]/home/tak/.conda/envs/tal_env/lib/python3.12/site-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
            "  warnings.warn(\n",
            "Processing Rows:  94%|█████████▎| 561/600 [07:28<00:18,  2.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error processing /home/tak/justice-tal/content/drive/MyDrive/DL3/midi_files/aaron_neville_-_tell_it_like_it_is.mid: data byte must be in range 0..127\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Rows:  98%|█████████▊| 589/600 [07:51<00:09,  1.16it/s]/home/tak/.conda/envs/tal_env/lib/python3.12/site-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
            "  warnings.warn(\n",
            "Processing Rows: 100%|█████████▉| 599/600 [07:58<00:00,  1.41it/s]/home/tak/.conda/envs/tal_env/lib/python3.12/site-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
            "  warnings.warn(\n",
            "Processing Rows: 100%|██████████| 600/600 [07:59<00:00,  1.25it/s]\n"
          ]
        }
      ],
      "source": [
        "X,Y = prepare_train('/home/tak/justice-tal/content/drive/MyDrive/DL3/lyrics_train_set.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zlYXUCOs2Odq",
        "outputId": "7ee8d807-3180-4312-cfec-566cd29b0475"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Rows:   0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing MIDI file: /home/tak/justice-tal/content/drive/MyDrive/DL3/midi_files/the_bangles_-_eternal_flame.mid\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Rows:  20%|██        | 1/5 [00:00<00:00,  4.96it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing MIDI file: /home/tak/justice-tal/content/drive/MyDrive/DL3/midi_files/billy_joel_-_honesty.mid\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Rows:  40%|████      | 2/5 [00:00<00:00,  4.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing MIDI file: /home/tak/justice-tal/content/drive/MyDrive/DL3/midi_files/cardigans_-_lovefool.mid\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Rows:  60%|██████    | 3/5 [00:00<00:00,  3.13it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing MIDI file: /home/tak/justice-tal/content/drive/MyDrive/DL3/midi_files/aqua_-_barbie_girl.mid\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Rows:  80%|████████  | 4/5 [00:01<00:00,  2.05it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing MIDI file: /home/tak/justice-tal/content/drive/MyDrive/DL3/midi_files/blink_182_-_all_the_small_things.mid\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Rows: 100%|██████████| 5/5 [00:02<00:00,  2.21it/s]\n"
          ]
        }
      ],
      "source": [
        "X_test = prepare_test('/home/tak/justice-tal/content/drive/MyDrive/DL3/lyrics_test_set.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Df_hEn3N2Odq"
      },
      "outputs": [],
      "source": [
        "save_to_pickle((X, Y), '/home/tak/justice-tal/content/drive/MyDrive/DL3/train_data_last_new.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZlYEOpmV2Odq"
      },
      "outputs": [],
      "source": [
        "save_to_pickle((X_test), '/home/tak/justice-tal/content/drive/MyDrive/DL3/test_data_last_new.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "li-XjGqh2COJ"
      },
      "source": [
        "# **Load dfs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77TWit8FZrU6"
      },
      "outputs": [],
      "source": [
        "def load_from_pickle(filename):\n",
        "    with open(filename, 'rb') as f:\n",
        "        data = pickle.load(f)\n",
        "    return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d4AcXoj2Odr"
      },
      "source": [
        "## First Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCierW7lSM4j"
      },
      "outputs": [],
      "source": [
        "X_loaded, Y_loaded = load_from_pickle('/home/tak/justice-tal/content/drive/MyDrive/DL3/train_data_last_new_2.pkl')\n",
        "X_test_load = load_from_pickle('/home/tak/justice-tal/content/drive/MyDrive/DL3/test_data_last_new_2.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TT2Xb6V-2Odr"
      },
      "source": [
        "## Second Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpvMTTzFSOBM"
      },
      "outputs": [],
      "source": [
        "X_loaded, Y_loaded = load_from_pickle('/home/tak/justice-tal/content/drive/MyDrive/DL3/train_data_last_new.pkl')\n",
        "X_test_load = load_from_pickle('/home/tak/justice-tal/content/drive/MyDrive/DL3/test_data_last_new.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6TTQn28J2Odr"
      },
      "outputs": [],
      "source": [
        "X_test_load = X_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66TqZo-XSnNa"
      },
      "source": [
        "# **Split to train and test**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ho9bbpsILUXY",
        "outputId": "4acd7d21-2e1a-4a11-95b7-4d4a21273c69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train shape: 138533, torch.Size([453])\n"
          ]
        }
      ],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "print(f\"X_train shape: {len(X_train)}, {X_train[1].shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7E19_BP_10k7"
      },
      "outputs": [],
      "source": [
        "train_data = [[X_train[i][0:300],X_train[i][300:453], y_train[i]] for i in range(len(X_train))]\n",
        "val_data = [[X_val[i][0:300],X_val[i][300:453], y_val[i]] for i in range(len(X_val))]\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(train_data, shuffle=False, batch_size=64)\n",
        "valloader = torch.utils.data.DataLoader(val_data, shuffle=False, batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4arwZWPL15vJ",
        "outputId": "34ee7872-95dd-4f7d-e52d-33d6b8b5232b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train data size: 138533\n",
            "Train data example shape: X_train[0] torch.Size([453]), y_train[0] torch.Size([6618])\n",
            "Train loader length: 2165\n",
            "Validation data size: 34634\n",
            "Validation data example shape: X_val[0] torch.Size([453]), y_val[0] torch.Size([6618])\n",
            "Validation loader length: 542\n"
          ]
        }
      ],
      "source": [
        "# Check train_data and trainloader\n",
        "print(f\"Train data size: {len(train_data)}\")\n",
        "print(f\"Train data example shape: X_train[0] {X_train[0].shape}, y_train[0] {y_train[0].shape}\")\n",
        "print(f\"Train loader length: {len(trainloader)}\")\n",
        "\n",
        "# Check val_data and valloader\n",
        "print(f\"Validation data size: {len(val_data)}\")\n",
        "print(f\"Validation data example shape: X_val[0] {X_val[0].shape}, y_val[0] {y_val[0].shape}\")\n",
        "print(f\"Validation loader length: {len(valloader)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6s6iZiHD2GHR"
      },
      "source": [
        "# **Models Setup**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hP0x9F8_Jig1"
      },
      "outputs": [],
      "source": [
        "class LyricsRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers=1, dropout=0.0):\n",
        "        super(LyricsRNN, self).__init__()\n",
        "        self.rnn = nn.LSTM(\n",
        "            input_size=input_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            dropout=dropout,\n",
        "            bidirectional=False  # Always unidirectional\n",
        "        )\n",
        "\n",
        "    def forward(self, x, hidden=None):\n",
        "        out, hidden = self.rnn(x, hidden)\n",
        "        return out, hidden\n",
        "\n",
        "class MelodyRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers=1, dropout=0.0, bidirectional=False):\n",
        "        super(MelodyRNN, self).__init__()\n",
        "        self.bidirectional = bidirectional\n",
        "        self.rnn = nn.LSTM(\n",
        "            input_size=input_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            dropout=dropout,\n",
        "            bidirectional=bidirectional\n",
        "        )\n",
        "        self.output_size = hidden_size * 2 if bidirectional else hidden_size\n",
        "\n",
        "    def forward(self, x, hidden=None):\n",
        "        out, hidden = self.rnn(x, hidden)\n",
        "        return out, hidden\n",
        "\n",
        "class CombinedModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Combines the unidirectional LyricsRNN with the MelodyRNN\n",
        "    (either bidirectional or unidirectional based on `bidirectional_melody`).\n",
        "\n",
        "    Args:\n",
        "        lyrics_rnn: An instance of LyricsRNN.\n",
        "        melody_rnn: An instance of MelodyRNN.\n",
        "        hidden_size: The hidden size of the lyrics RNN.\n",
        "        melody_hsize: The output hidden size of the melody RNN (adjusted for bidirectionality).\n",
        "        vocab_size: Size of the vocabulary for next-word predictions.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_sizes, hidden_sizes, num_layers, dropout, bidirectional_melody=False):\n",
        "        super(CombinedModel, self).__init__()\n",
        "        lyrics_input_size, melody_input_size = input_sizes\n",
        "        lyrics_hidden_size, melody_hidden_size = hidden_sizes\n",
        "\n",
        "        # Initialize RNNs\n",
        "        self.lyrics_rnn = LyricsRNN(\n",
        "            input_size=lyrics_input_size,\n",
        "            hidden_size=lyrics_hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            dropout=dropout\n",
        "        )\n",
        "        self.melody_rnn = MelodyRNN(\n",
        "            input_size=melody_input_size,\n",
        "            hidden_size=melody_hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            dropout=dropout,\n",
        "            bidirectional=bidirectional_melody\n",
        "        )\n",
        "\n",
        "        # Compute combined dimension and initialize FC layer\n",
        "        melody_output_size = self.melody_rnn.output_size\n",
        "        self.fc = nn.Linear(lyrics_hidden_size + melody_output_size, 6618)\n",
        "\n",
        "    def forward(self, lyrics_input, melody_input):\n",
        "        # Process lyrics and melody inputs through their respective RNNs\n",
        "        lyrics_out, _ = self.lyrics_rnn(lyrics_input)\n",
        "        melody_out, _ = self.melody_rnn(melody_input)\n",
        "\n",
        "        # Combine the outputs and map to logits\n",
        "        combined = torch.cat((lyrics_out, melody_out), dim=-1)\n",
        "        logits = self.fc(combined)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GcX7voC2Ods"
      },
      "source": [
        "## First Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0v_1WQ4BJkKS"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "lyrics_input_size = 300      # Word embedding size\n",
        "melody_input_size = 23      # MIDI feature size\n",
        "hidden_size = 256            # RNN hidden size for lyrics\n",
        "melody_hidden_size = 256     # RNN hidden size for melody\n",
        "num_layers = 2\n",
        "dropout = 0.1\n",
        "\n",
        "# Instantiate the CombinedModel with bidirectionality\n",
        "model_op1 = CombinedModel(\n",
        "    input_sizes=(lyrics_input_size, melody_input_size),\n",
        "    hidden_sizes=(hidden_size, melody_hidden_size),\n",
        "    num_layers=num_layers,\n",
        "    dropout=dropout,\n",
        "    bidirectional_melody=True\n",
        ")\n",
        "\n",
        "# Instantiate the CombinedModel with no bidirectionality\n",
        "model_op2 = CombinedModel(\n",
        "    input_sizes=(lyrics_input_size, melody_input_size),\n",
        "    hidden_sizes=(hidden_size, melody_hidden_size),\n",
        "    num_layers=num_layers,\n",
        "    dropout=dropout,\n",
        "    bidirectional_melody=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNWPlAPb2Ods"
      },
      "source": [
        "## Second Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_s6-vlaL2Ods"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "lyrics_input_size = 300      # Word embedding size\n",
        "melody_input_size = 153      # MIDI feature size\n",
        "hidden_size = 256            # RNN hidden size for lyrics\n",
        "melody_hidden_size = 256     # RNN hidden size for melody\n",
        "num_layers = 2\n",
        "dropout = 0.1\n",
        "\n",
        "# Instantiate the CombinedModel with bidirectionality\n",
        "model_op1 = CombinedModel(\n",
        "    input_sizes=(lyrics_input_size, melody_input_size),\n",
        "    hidden_sizes=(hidden_size, melody_hidden_size),\n",
        "    num_layers=num_layers,\n",
        "    dropout=dropout,\n",
        "    bidirectional_melody=True\n",
        ")\n",
        "\n",
        "# Instantiate the CombinedModel with no bidirectionality\n",
        "model_op2 = CombinedModel(\n",
        "    input_sizes=(lyrics_input_size, melody_input_size),\n",
        "    hidden_sizes=(hidden_size, melody_hidden_size),\n",
        "    num_layers=num_layers,\n",
        "    dropout=dropout,\n",
        "    bidirectional_melody=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MV1YFQ5j4pqY"
      },
      "outputs": [],
      "source": [
        "writer = SummaryWriter()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KAqeJzhr2Ods",
        "outputId": "5e2c3353-3474-48a4-b2d0-2f7fe1ca024b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean line length: 39.89833333333333\n",
            "Mean song length: 253.54\n",
            "Standard deviation of song length: 141.54949251546486\n"
          ]
        }
      ],
      "source": [
        "train = pd.read_csv(train_file, header=None)\n",
        "train = train[[0,1,2]]\n",
        "train.columns = ['Artist', 'Song Name', 'Lyrics']\n",
        "train['Lyrics'] = train['Lyrics'].apply(clean_text)\n",
        "train['Lyrics'] = train['Lyrics'].apply(lambda x: ' '.join(re.sub(r'[^\\w\\s]', '', x).split()))\n",
        "\n",
        "# for each row sum the number of time & is present in the lyrics\n",
        "train['newline'] = train['Lyrics'].apply(lambda x: x.count('newline'))\n",
        "#calculate the average number of newline in the lyrics\n",
        "mean_line_length = train['newline'].mean()\n",
        "#calculate the sum of words in the lyrics(ecxluding newline)\n",
        "train['sum_words'] = train['Lyrics'].apply(lambda x: len(x.split()) - x.count('newline'))\n",
        "#calculate the average number of words in the lyrics\n",
        "mean_song_length = train['sum_words'].mean()\n",
        "#std deviation of the number of words in the lyrics\n",
        "std_song_length = train['sum_words'].std()\n",
        "\n",
        "print(f\"Mean line length: {mean_line_length}\")\n",
        "print(f\"Mean song length: {mean_song_length}\")\n",
        "print(f\"Standard deviation of song length: {std_song_length}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iIFaI6fyxcTI"
      },
      "outputs": [],
      "source": [
        "def train(trainloader, model, loss_fn, optimizer, name, writer, epoch):\n",
        "    \"\"\"\n",
        "    Train the model on the training set and log the metrics.\n",
        "    \"\"\"\n",
        "    running_loss = []\n",
        "    model.train()\n",
        "    for batch_idx, (x_lyrics,x_melody, y) in enumerate(trainloader):\n",
        "        x_lyrics = x_lyrics.to(device).float()\n",
        "        x_melody = x_melody.to(device).float()\n",
        "        y = y.to(device).float()\n",
        "        optimizer.zero_grad()\n",
        "        # Forward pass with splitted inputs\n",
        "        pred = model(x_lyrics, x_melody)\n",
        "        pred_indices = torch.argmax(pred, dim=-1)  # Assuming pred shape is [batch_size, seq_length, vocab_size]\n",
        "\n",
        "        penalties = 0.0\n",
        "        newline_token_idx = reduced_vocab['newline']\n",
        "        if newline_token_idx is not None:\n",
        "            newline_counts = (pred == newline_token_idx).sum(dim=1)  # Count NEWLINE_TOKEN per batch\n",
        "            long_line_penalty = (newline_counts.float().mean() - 6).clamp(min=0)  # Penalize lines longer than 5\n",
        "            penalties += long_line_penalty\n",
        "        penalty = penalties * 0.3\n",
        "\n",
        "        # Penalize overly long lyrics sequences\n",
        "        total_tokens = pred_indices.size(0)  # Sequence length\n",
        "        long_lyrics_penalty = torch.tensor(total_tokens - 253, device=device).clamp(min=0).float()\n",
        "        penalties += long_lyrics_penalty\n",
        "        penalties = penalties * 0.3\n",
        "\n",
        "        loss = loss_fn(pred, y) + penalty\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss.append(loss.item())\n",
        "        if batch_idx % 100 == 99:  # Log every 100 batches\n",
        "            print(f'Epoch [{epoch + 1}], Batch [{batch_idx + 1}], Loss: {np.mean(running_loss) :.4f}')\n",
        "            writer.add_scalar(f'training/loss_{name}', np.mean(running_loss), epoch * len(trainloader) + batch_idx)\n",
        "            running_loss = []\n",
        "\n",
        "def test(dataloader, model, loss_fn, name, writer, epoch):\n",
        "    \"\"\"\n",
        "    Evaluate the model on the validation set and log the metrics.\n",
        "    \"\"\"\n",
        "    running_loss = []\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss = []\n",
        "    correct = 0\n",
        "    q = 10\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (x_lyrics, x_melody, y) in enumerate(dataloader):\n",
        "            x_lyrics = x_lyrics.to(device).float()\n",
        "            x_melody = x_melody.to(device).float()\n",
        "            y = y.to(device).float()  # Assuming y contains probabilities\n",
        "\n",
        "            # Forward pass\n",
        "            pred = model(x_lyrics, x_melody)\n",
        "\n",
        "            # Calculate loss\n",
        "            loss = loss_fn(pred, y)\n",
        "            test_loss.append(loss.item())\n",
        "\n",
        "            # Accuracy calculation\n",
        "            pred_indices = torch.argmax(pred, dim=1)  # Predicted classes\n",
        "            target_indices = torch.argmax(y, dim=1)   # True classes\n",
        "            correct += (pred_indices == target_indices).sum().item()\n",
        "\n",
        "            if q == 0:\n",
        "                running_loss.append(loss.item())\n",
        "                writer.add_scalar(f'validation/loss_{name}', np.mean(running_loss), epoch * len(dataloader) + batch_idx)\n",
        "                running_loss = []\n",
        "                q = 10\n",
        "            q -= 1\n",
        "\n",
        "    test_loss = sum(test_loss) / len(test_loss)\n",
        "    correct /= size\n",
        "    print(f\"Accuracy: {(correct * 100):>0.1f}%, Avg loss: {test_loss:>7f} \\n\")\n",
        "    writer.add_scalar(f'validation/accuracy_{name}', correct, epoch)\n",
        "    writer.add_scalar(f'validation/loss_{name}', test_loss, epoch)\n",
        "    return correct, test_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xqf8LXlw2Odt"
      },
      "source": [
        "# **Hyperparameters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "lRTTHVYpb6gQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import numpy as np\n",
        "# Hyperparameter search setup\n",
        "def hyperparameter_search(trainloader, valloader, model_class, dataset_train, dataset_val, device, search_space):\n",
        "    best_params = None\n",
        "    best_accuracy = 0\n",
        "    best_model = None\n",
        "\n",
        "    for params in search_space:\n",
        "        print(f\"Testing parameters: {params}\")\n",
        "\n",
        "        # Reinitialize DataLoaders with new batch size\n",
        "        batch_size = params.get('batch_size', 32)  # Default to 32 if not specified\n",
        "        trainloader = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
        "        valloader = torch.utils.data.DataLoader(dataset_val, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "        # Initialize model, optimizer, loss function, and writer\n",
        "        model = model_class.to(device)\n",
        "\n",
        "        # Handle optimizer initialization (support lambdas and direct calls)\n",
        "        if callable(params['optimizer']):\n",
        "            optimizer = params['optimizer'](model.parameters())\n",
        "        else:\n",
        "            optimizer = params['optimizer'](model.parameters(), lr=params['learning_rate'])\n",
        "\n",
        "        loss_fn = params['loss_fn']\n",
        "        writer = SummaryWriter()\n",
        "\n",
        "        validation_loss = float('inf')\n",
        "        for epoch in range(params['num_epochs']):\n",
        "            print(f'Starting epoch {epoch + 1} ...')\n",
        "            train(trainloader, model, loss_fn, optimizer, params['name'], writer, epoch)\n",
        "            acc, val_loss = test(valloader, model, loss_fn, params['name'], writer, epoch)\n",
        "\n",
        "            if acc > best_accuracy:\n",
        "                best_accuracy = acc\n",
        "                best_params = params\n",
        "                best_model = model\n",
        "\n",
        "            if (validation_loss - val_loss) < 1e-6:  # Early stopping condition\n",
        "                print(\"Early stopping\")\n",
        "                break\n",
        "\n",
        "            validation_loss = val_loss\n",
        "\n",
        "        writer.close()\n",
        "\n",
        "    print(f\"Best parameters: {best_params}\")\n",
        "    print(f\"Best accuracy: {best_accuracy:.4f}\")\n",
        "    return best_params, best_accuracy, best_model\n",
        "\n",
        "\n",
        "# Expanded search space with additional hyperparameters\n",
        "search_space = [\n",
        "    # Adam optimizer with varying learning rates and batch sizes\n",
        "    {\n",
        "        'name': 'adam_lr_0.001_batch_32',\n",
        "        'optimizer': optim.Adam,\n",
        "        'learning_rate': 0.001,\n",
        "        'loss_fn': torch.nn.CrossEntropyLoss(),\n",
        "        'num_epochs': 10,\n",
        "        'batch_size': 32\n",
        "    },\n",
        "    {\n",
        "        'name': 'adam_lr_0.0005_batch_64',\n",
        "        'optimizer': optim.Adam,\n",
        "        'learning_rate': 0.0005,\n",
        "        'loss_fn': torch.nn.CrossEntropyLoss(),\n",
        "        'num_epochs': 10,\n",
        "        'batch_size': 64\n",
        "    },\n",
        "    # RMSprop with dropout\n",
        "    {\n",
        "        'name': 'rmsprop_lr_0.001_batch_size_32',\n",
        "        'optimizer': optim.RMSprop,\n",
        "        'learning_rate': 0.005,\n",
        "        'loss_fn': torch.nn.CrossEntropyLoss(),\n",
        "        'num_epochs': 10,\n",
        "        'batch_size': 32\n",
        "    },\n",
        "    # Model architecture variations\n",
        "    {\n",
        "        'name': 'adam_lr_0.0001_batch_size_64',\n",
        "        'optimizer': optim.SGD,\n",
        "        'learning_rate': 0.0001,\n",
        "        'loss_fn': torch.nn.CrossEntropyLoss(),\n",
        "        'num_epochs': 10,\n",
        "        'batch_size': 64\n",
        "\n",
        "    },\n",
        "    {\n",
        "        'name': 'adam_lr_0.0001_batch_size_64',\n",
        "        'optimizer': optim.Adam,\n",
        "        'learning_rate': 0.001,\n",
        "        'loss_fn': torch.nn.L1Loss(),\n",
        "        'num_epochs': 10,\n",
        "        'batch_size': 64\n",
        "    }\n",
        "]\n",
        "\n",
        "# Perform hyperparameter search\n",
        "best_params_model_op1, best_accuracy_model_op1, best_model_model_op1 = hyperparameter_search(\n",
        "    trainloader,\n",
        "    valloader,\n",
        "    model_op1,\n",
        "    train_data,\n",
        "    val_data,\n",
        "    device,\n",
        "    search_space\n",
        ")\n",
        "\n",
        "best_params_model_op2, best_accuracy_model_op2, best_model_model_op2 = hyperparameter_search(\n",
        "    trainloader,\n",
        "    valloader,\n",
        "    model_op2,\n",
        "    train_data,\n",
        "    val_data,\n",
        "    device,\n",
        "    search_space\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ask9pJb4KN2j"
      },
      "source": [
        "# **Model #_1 - bidirectional_melody**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tOSVIwnYxmKk",
        "outputId": "89589764-a59e-41d6-d724-b18a5075a354"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting epoch 1 ...\n",
            "Epoch [1], Batch [100], Loss: 6.4499\n",
            "Epoch [1], Batch [200], Loss: 5.8660\n",
            "Epoch [1], Batch [300], Loss: 5.8963\n",
            "Epoch [1], Batch [400], Loss: 5.7595\n",
            "Epoch [1], Batch [500], Loss: 5.7333\n",
            "Epoch [1], Batch [600], Loss: 5.7242\n",
            "Epoch [1], Batch [700], Loss: 5.6849\n",
            "Epoch [1], Batch [800], Loss: 5.5510\n",
            "Epoch [1], Batch [900], Loss: 5.5855\n",
            "Epoch [1], Batch [1000], Loss: 5.5774\n",
            "Epoch [1], Batch [1100], Loss: 5.6135\n",
            "Epoch [1], Batch [1200], Loss: 5.6419\n",
            "Epoch [1], Batch [1300], Loss: 5.5403\n",
            "Epoch [1], Batch [1400], Loss: 5.5360\n",
            "Epoch [1], Batch [1500], Loss: 5.4824\n",
            "Epoch [1], Batch [1600], Loss: 5.5664\n",
            "Epoch [1], Batch [1700], Loss: 5.5100\n",
            "Epoch [1], Batch [1800], Loss: 5.5593\n",
            "Epoch [1], Batch [1900], Loss: 5.5364\n",
            "Epoch [1], Batch [2000], Loss: 5.5178\n",
            "Epoch [1], Batch [2100], Loss: 5.5142\n",
            "Accuracy: 17.8%, Avg loss: 5.540282 \n",
            "\n",
            "Starting epoch 2 ...\n",
            "Epoch [2], Batch [100], Loss: 5.5238\n",
            "Epoch [2], Batch [200], Loss: 5.4682\n",
            "Epoch [2], Batch [300], Loss: 5.7461\n",
            "Epoch [2], Batch [400], Loss: 5.7816\n",
            "Epoch [2], Batch [500], Loss: 5.6891\n",
            "Epoch [2], Batch [600], Loss: 5.9385\n",
            "Epoch [2], Batch [700], Loss: 5.8316\n",
            "Epoch [2], Batch [800], Loss: 5.8838\n",
            "Epoch [2], Batch [900], Loss: 5.8456\n",
            "Epoch [2], Batch [1000], Loss: 5.8311\n",
            "Epoch [2], Batch [1100], Loss: 5.9929\n",
            "Epoch [2], Batch [1200], Loss: 6.0242\n",
            "Epoch [2], Batch [1300], Loss: 6.0159\n",
            "Epoch [2], Batch [1400], Loss: 6.0911\n",
            "Epoch [2], Batch [1500], Loss: 6.0681\n",
            "Epoch [2], Batch [1600], Loss: 6.0181\n",
            "Epoch [2], Batch [1700], Loss: 5.9092\n",
            "Epoch [2], Batch [1800], Loss: 6.0202\n",
            "Epoch [2], Batch [1900], Loss: 6.0348\n",
            "Epoch [2], Batch [2000], Loss: 6.0849\n",
            "Epoch [2], Batch [2100], Loss: 6.0752\n",
            "Accuracy: 16.9%, Avg loss: 6.069422 \n",
            "\n",
            "Early stopping\n"
          ]
        }
      ],
      "source": [
        "#Training Setup model_op1\n",
        "model1 = model_op1.to(device)\n",
        "writer = SummaryWriter()\n",
        "# cross_entropy = nn.CrossEntropyLoss()\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "# loss_fn = torch.nn.L1Loss()\n",
        "optimizer = optim.Adam(model1.parameters(), lr=0.01)\n",
        "num_epochs = 8\n",
        "validation_loss = float('inf')\n",
        "for epoch in range(num_epochs):\n",
        "    print(f'Starting epoch {epoch + 1} ...')\n",
        "    train(trainloader, model1, loss_fn, optimizer, \"model1\", writer, epoch)\n",
        "    acc, val_loss = test(valloader, model1, loss_fn, \"model1\", writer, epoch)\n",
        "    if (validation_loss - val_loss) < 1e-6:     # Early stopping condition\n",
        "        print(\"Early stopping\")\n",
        "        break\n",
        "\n",
        "    validation_loss = val_loss\n",
        "writer.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnzrSCbWLPzc"
      },
      "source": [
        "# **Model #_2 - undirectional_melody**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7rbKugr7LMwI",
        "outputId": "aa7a240e-838e-41cd-f1ef-94083af95466"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting epoch 1 ...\n",
            "Epoch [1], Batch [100], Loss: 6.3806\n",
            "Epoch [1], Batch [200], Loss: 5.8175\n",
            "Epoch [1], Batch [300], Loss: 5.7913\n",
            "Epoch [1], Batch [400], Loss: 5.6233\n",
            "Epoch [1], Batch [500], Loss: 5.5141\n",
            "Epoch [1], Batch [600], Loss: 5.4901\n",
            "Epoch [1], Batch [700], Loss: 5.4239\n",
            "Epoch [1], Batch [800], Loss: 5.3412\n",
            "Epoch [1], Batch [900], Loss: 5.3521\n",
            "Epoch [1], Batch [1000], Loss: 5.2608\n",
            "Epoch [1], Batch [1100], Loss: 5.2887\n",
            "Epoch [1], Batch [1200], Loss: 5.2549\n",
            "Epoch [1], Batch [1300], Loss: 5.2302\n",
            "Epoch [1], Batch [1400], Loss: 5.2273\n",
            "Epoch [1], Batch [1500], Loss: 5.1828\n",
            "Epoch [1], Batch [1600], Loss: 5.1518\n",
            "Epoch [1], Batch [1700], Loss: 5.1114\n",
            "Epoch [1], Batch [1800], Loss: 5.1737\n",
            "Epoch [1], Batch [1900], Loss: 5.1667\n",
            "Epoch [1], Batch [2000], Loss: 5.0992\n",
            "Epoch [1], Batch [2100], Loss: 5.1129\n",
            "Accuracy: 18.3%, Avg loss: 5.052948 \n",
            "\n",
            "Starting epoch 2 ...\n",
            "Epoch [2], Batch [100], Loss: 4.9453\n",
            "Epoch [2], Batch [200], Loss: 4.9434\n",
            "Epoch [2], Batch [300], Loss: 5.0383\n",
            "Epoch [2], Batch [400], Loss: 4.9718\n",
            "Epoch [2], Batch [500], Loss: 4.8881\n",
            "Epoch [2], Batch [600], Loss: 4.9152\n",
            "Epoch [2], Batch [700], Loss: 4.8833\n",
            "Epoch [2], Batch [800], Loss: 4.8430\n",
            "Epoch [2], Batch [900], Loss: 4.8585\n",
            "Epoch [2], Batch [1000], Loss: 4.8043\n",
            "Epoch [2], Batch [1100], Loss: 4.8398\n",
            "Epoch [2], Batch [1200], Loss: 4.8296\n",
            "Epoch [2], Batch [1300], Loss: 4.8176\n",
            "Epoch [2], Batch [1400], Loss: 4.8250\n",
            "Epoch [2], Batch [1500], Loss: 4.7789\n",
            "Epoch [2], Batch [1600], Loss: 4.7879\n",
            "Epoch [2], Batch [1700], Loss: 4.7521\n",
            "Epoch [2], Batch [1800], Loss: 4.8006\n",
            "Epoch [2], Batch [1900], Loss: 4.8052\n",
            "Epoch [2], Batch [2000], Loss: 4.7411\n",
            "Epoch [2], Batch [2100], Loss: 4.7492\n",
            "Accuracy: 18.9%, Avg loss: 4.946702 \n",
            "\n",
            "Starting epoch 3 ...\n",
            "Epoch [3], Batch [100], Loss: 4.5553\n",
            "Epoch [3], Batch [200], Loss: 4.5502\n",
            "Epoch [3], Batch [300], Loss: 4.6491\n",
            "Epoch [3], Batch [400], Loss: 4.6024\n",
            "Epoch [3], Batch [500], Loss: 4.5799\n",
            "Epoch [3], Batch [600], Loss: 4.6250\n",
            "Epoch [3], Batch [700], Loss: 4.6018\n",
            "Epoch [3], Batch [800], Loss: 4.5572\n",
            "Epoch [3], Batch [900], Loss: 4.5760\n",
            "Epoch [3], Batch [1000], Loss: 4.5046\n",
            "Epoch [3], Batch [1100], Loss: 4.5446\n",
            "Epoch [3], Batch [1200], Loss: 4.5333\n",
            "Epoch [3], Batch [1300], Loss: 4.5113\n",
            "Epoch [3], Batch [1400], Loss: 4.5635\n",
            "Epoch [3], Batch [1500], Loss: 4.4771\n",
            "Epoch [3], Batch [1600], Loss: 4.4855\n",
            "Epoch [3], Batch [1700], Loss: 4.4692\n",
            "Epoch [3], Batch [1800], Loss: 4.4805\n",
            "Epoch [3], Batch [1900], Loss: 4.5128\n",
            "Epoch [3], Batch [2000], Loss: 4.4310\n",
            "Epoch [3], Batch [2100], Loss: 4.4319\n",
            "Accuracy: 19.0%, Avg loss: 4.968545 \n",
            "\n",
            "Early stopping\n"
          ]
        }
      ],
      "source": [
        "#Training Setup model_op2\n",
        "model2 = model_op2.to(device)\n",
        "writer = SummaryWriter()\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model2.parameters(), lr=0.001)\n",
        "num_epochs = 4\n",
        "validation_loss = float('inf')\n",
        "for epoch in range(num_epochs):\n",
        "    print(f'Starting epoch {epoch + 1} ...')\n",
        "    train(trainloader, model2, loss_fn, optimizer, \"model2\", writer, epoch)\n",
        "    acc, val_loss = test(valloader, model2, loss_fn, \"model2\", writer, epoch)\n",
        "    if (validation_loss - val_loss) < 1e-6:     # Early stopping condition\n",
        "        print(\"Early stopping\")\n",
        "        break\n",
        "    validation_loss = val_loss\n",
        "writer.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFiQfaRSTUbF"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-e_a91M4TXMY",
        "outputId": "634538ef-0a9b-4147-90cb-4928b40d2ff2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Reusing TensorBoard on port 6006 (pid 1788364), started 1:24:52 ago. (Use '!kill 1788364' to kill it.)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "      <iframe id=\"tensorboard-frame-a2ee146f613ae775\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
              "      </iframe>\n",
              "      <script>\n",
              "        (function() {\n",
              "          const frame = document.getElementById(\"tensorboard-frame-a2ee146f613ae775\");\n",
              "          const url = new URL(\"http://localhost\");\n",
              "          const port = 6006;\n",
              "          if (port) {\n",
              "            url.port = port;\n",
              "          }\n",
              "          frame.src = url;\n",
              "        })();\n",
              "      </script>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%tensorboard --logdir runs/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Hitie9AAgFP"
      },
      "outputs": [],
      "source": [
        "def softmax(x):\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / e_x.sum(axis=0)\n",
        "\n",
        "def sample_word(probs):\n",
        "    \"\"\"\n",
        "    Sample a word from the Word2Vec model using the given vector.\n",
        "    A softmax distribution is applied to ensure probabilistic selection.\n",
        "    \"\"\"\n",
        "\n",
        "    probs = F.softmax(probs, dim=1).squeeze()\n",
        "    next_token = torch.multinomial(probs, num_samples=1).item()\n",
        "    chosen_word = voc_idx.get(next_token)\n",
        "\n",
        "    return chosen_word"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdgZYaZ1K0Eo"
      },
      "source": [
        "# **Generate text functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5WS-qEF5oyp"
      },
      "outputs": [],
      "source": [
        "def generate_text(model, song_features, word2vec_model, initial_word, song_index, max_length=100):\n",
        "    \"\"\"\n",
        "    Generate song lyrics based on a trained model and melody features.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The trained model for lyric generation.\n",
        "        song_features (list): List of melody features for the song.\n",
        "        word2vec_model (Word2Vec): Pre-trained Word2Vec model for word embeddings.\n",
        "        initial_word (str): Starting word for the song.\n",
        "        song_index (int): Index of the song being generated.\n",
        "        max_length (int): Maximum number of lines in the song.\n",
        "        verse_lines_range (tuple): Range for the number of lines in a verse.\n",
        "        chorus_lines_range (tuple): Range for the number of lines in the chorus.\n",
        "        verse_words_range (tuple): Range for words per line in a verse.\n",
        "        chorus_words_range (tuple): Range for words per line in the chorus.\n",
        "\n",
        "    Returns:\n",
        "        str: Generated lyrics as a formatted string.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    # generated_lyrics = ''\n",
        "    # Initialize generation parameters\n",
        "    try:\n",
        "        vec = reduced_vectors[reduced_vocab[initial_word]]\n",
        "    except:\n",
        "        #randomly select a word from the word2vec model\n",
        "        vec = reduced_vectors[reduced_vocab[random.choice(list(reduced_vocab.keys()))]]\n",
        "    input_word_vec = torch.tensor(vec).float().to(device)\n",
        "    generated_lyrics = initial_word + \" \"\n",
        "    i = 0\n",
        "    with torch.no_grad():\n",
        "        for melody_feature in song_features:\n",
        "            # Prepare input tensors\n",
        "            melody_feature_tensor = torch.tensor(melody_feature).float().to(device)\n",
        "\n",
        "            # Pass through separate RNNs\n",
        "            lyrics_output, _ = model.lyrics_rnn(input_word_vec.unsqueeze(0).unsqueeze(0))\n",
        "            melody_output, _ = model.melody_rnn(melody_feature_tensor.unsqueeze(0).unsqueeze(0))\n",
        "\n",
        "            # Combine outputs\n",
        "            combined_output = torch.cat((lyrics_output[:, -1, :], melody_output[:, -1, :]), dim=-1)\n",
        "            output = model.fc(combined_output)  # Project to vocabulary logits\n",
        "            # Sample a word using Word2Vec\n",
        "            chosen_word = sample_word(output)\n",
        "            if i == len(song_features)-2:\n",
        "              generated_lyrics += chosen_word\n",
        "              break\n",
        "            generated_lyrics += chosen_word + \" \"\n",
        "            try:\n",
        "                vec = reduced_vectors[reduced_vocab[chosen_word]]\n",
        "            except:\n",
        "                #randomly select a word from the word2vec model\n",
        "                vec = reduced_vectors[reduced_vocab[random.choice(list(reduced_vocab.keys()))]]\n",
        "            # Update input word vector for the next iteration\n",
        "            input_word_vec = torch.tensor(vec).float().to(device)\n",
        "            i+=1\n",
        "    #remove last word\n",
        "    # generated_lyrics = generated_lyrics[:-8]\n",
        "    return generated_lyrics\n",
        "    # ly = \"close feelin dreams baby that cause like friends im have day cool let be their would your wit ignorance such forgiven oh may doll nothing down i now around suddenly ball have empty that beautiful how you lonely no goes gone you are called of for wanted me life of stress apart say i all way\"\n",
        "\n",
        "    # ly = \"\"\"close never tropic you you deny and you to is he newline Da low walked gears dub a alone newline City profile on kinda make away drinks attraction male jubilee there bop hands form all newline Balloon loves share for things it am newline On begins not wintry twenty baby eos obvious both for so layer fears will where growth cest newline Searching hop leads will the slowly night ivory cada they guaranteed se lack passing deceased britney did eos mofo france boys windows yay plans newline Fine quiero that it they river george at newline Would weekend geht more done flip two my your hin given kommissar suffered and but makes never nationality for napoleon just hiring effect newline Glass newline Solitary stale farmers we silence petro worse since tragic united more arrow become sing wrinkled oz zone beautiful newline Into misled the gimme going not size ye choke newline Splendor newline That scene count in king dial newline Alone tragedy lebn smoke waste hush socks duke said shall newline House clearly knock not gold a southward tho finally said oceans is newline Radio confidence right a war move world feeling baby out they dim drink please color weiãt taking what call each massachusetts disappointments newlineMess apart aingt gimme shake you recently graceful years spirit sunlight newline Power a range me\"\"\"\n",
        "    # return ly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oNS3ytpGbOre"
      },
      "outputs": [],
      "source": [
        "def generate_ngram_embeddings(words, word_model, n):\n",
        "    \"\"\"\n",
        "    Generate a tensor representation for n-grams based on word embeddings.\n",
        "\n",
        "    Args:\n",
        "        words (list of str): List of tokenized words.\n",
        "        word_model: Pretrained word embedding model.\n",
        "        n (int): Size of the n-grams (e.g., 1 for unigrams, 2 for bigrams, 3 for trigrams).\n",
        "\n",
        "    Returns:\n",
        "        Tensor: A [num_ngrams, embedding_dim] tensor for all valid n-grams.\n",
        "    \"\"\"\n",
        "    if n <= 0:\n",
        "        raise ValueError(\"n must be a positive integer.\")\n",
        "\n",
        "    embeddings = []\n",
        "    for i in range(len(words) - n + 1):\n",
        "        ngram_words = words[i:i + n]\n",
        "        try:\n",
        "            original_vector = [reduced_vectors[reduced_vocab[word]] for word in ngram_words]\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "\n",
        "    # if len(embeddings) == 0:\n",
        "    #     return torch.zeros(300)\n",
        "    return torch.tensor(original_vector, dtype=torch.float)\n",
        "\n",
        "\n",
        "def cosine_similarity(lyrics1, lyrics2):\n",
        "    \"\"\"\n",
        "    Calculate the cosine similarity between two sets of embeddings.\n",
        "    \"\"\"\n",
        "    if not isinstance(lyrics1, torch.Tensor):\n",
        "        lyrics1 = torch.tensor(lyrics1).float()\n",
        "    if not isinstance(lyrics2, torch.Tensor):\n",
        "        lyrics2 = torch.tensor(lyrics2).float()\n",
        "\n",
        "    if lyrics1.ndim == 2 and lyrics1.size(1) == 300:\n",
        "        lyrics1 = lyrics1.mean(dim=0)  # Mean-pool to [300]-dim\n",
        "    if lyrics2.ndim == 2 and lyrics2.size(1) == 300:\n",
        "        lyrics2 = lyrics2.mean(dim=0)\n",
        "\n",
        "    similarity = F.cosine_similarity(lyrics1, lyrics2, dim=0)\n",
        "    return similarity.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhDBdrSA1tFm"
      },
      "outputs": [],
      "source": [
        "def evaluate_lyrics(generated_lyrics, song_index):\n",
        "  # Prepare generated_lyrics_tensor (1-grams)\n",
        "  raw_generated_words = generated_lyrics.split(\" \")\n",
        "  # raw_generated_words = [word.lower() for word in raw_generated_words][2:]  # Skip first 2 words\n",
        "  # Load CSV, find song_index, get its lyrics\n",
        "  df = csv2df('/home/tak/justice-tal/content/drive/MyDrive/DL3/lyrics_test_set.csv', is_test=False)\n",
        "  for i, row in df.iterrows():\n",
        "      if i == song_index:\n",
        "          true_lyrics = row['Lyrics']\n",
        "          break\n",
        "\n",
        "  # Prepare 1-gram tensor\n",
        "  generated_1gram_tensor = generate_ngram_embeddings(raw_generated_words, word_model, 1)\n",
        "  # Prepare true_lyrics_tensor (1-grams)\n",
        "  true_words = true_lyrics.split(\" \")\n",
        "  true_words = [clean_text(w.lower()) for w in true_words]\n",
        "  true_1gram_tensor = generate_ngram_embeddings(true_words, word_model, 1 )\n",
        "  # Compute 1-gram Cosine Similarity\n",
        "  similarity_1gram = cosine_similarity(true_1gram_tensor, generated_1gram_tensor)\n",
        "\n",
        "  # Prepare 2-gram tensors\n",
        "  generated_2gram_tensor = generate_ngram_embeddings(raw_generated_words, word_model, 2)\n",
        "  true_2gram_tensor = generate_ngram_embeddings(true_words, word_model, 2)\n",
        "\n",
        "  # Compute 2-gram Cosine Similarity\n",
        "  similarity_2gram = cosine_similarity(true_2gram_tensor, generated_2gram_tensor)\n",
        "\n",
        "  # # Prepare 3-gram tensors\n",
        "  generated_3gram_tensor = generate_ngram_embeddings(raw_generated_words, word_model, 3)\n",
        "  true_3gram_tensor = generate_ngram_embeddings(true_words, word_model, 3)\n",
        "\n",
        "  # Compute 3-gram Cosine Similarity\n",
        "  similarity_3gram = cosine_similarity(true_3gram_tensor, generated_3gram_tensor)\n",
        "\n",
        "  # # Prepare 4-gram tensors\n",
        "  generated_4gram_tensor = generate_ngram_embeddings(raw_generated_words, word_model, 4)\n",
        "  true_4gram_tensor = generate_ngram_embeddings(true_words, word_model, 4)\n",
        "\n",
        "  # Compute 4-gram Cosine Similarity\n",
        "  similarity_4gram = cosine_similarity(true_4gram_tensor, generated_4gram_tensor)\n",
        "\n",
        "  true_lyrics = true_lyrics.replace('newline', '\\n')\n",
        "\n",
        "  print(f\"Real Lyrics: {true_lyrics}\\n\")\n",
        "  return similarity_1gram, similarity_2gram, similarity_3gram, similarity_4gram"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQXc7dAT0J0s"
      },
      "source": [
        "# **Test Song 1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrvarCOH2Odu"
      },
      "outputs": [],
      "source": [
        "results_model1 = {\"1gram\": [], \"2gram\": [], \"3gram\": [], \"4gram\": []}\n",
        "results_model2 = {\"1gram\": [], \"2gram\": [], \"3gram\": [], \"4gram\": []}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "no7tu2YX0-Lc"
      },
      "source": [
        "## Word - close"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-JPh6NN5PQa",
        "outputId": "e4e44129-e2e9-423b-900e-51f6eafbceeb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Song 1: close\n",
            "\n",
            "Model 1: \n",
            "\n",
            "Generated Lyrics: close closer room though hes watching out \n",
            " because ya ho ho dead water deceiving done and those \n",
            " quit once alone for a bitch would it just air of im ho to hear your sleep hmm breakin \n",
            " hungry venus joy \n",
            " one to die melodies watching their part dead black coming waiting ends bitch \n",
            " never lie \n",
            " their saw a monkey picking hungry god to meet on life in two glimpse you hope in summit \n",
            " lie it \n",
            " its just so to smile when i seem \n",
            " thinking dead face lonely \n",
            " because it easy times for the call its a myself so my lives\n",
            "\n",
            "Real Lyrics: close your eyes give me your hand darling \n",
            " do you feel my heart beating \n",
            " do you understand \n",
            " do you feel the same \n",
            " am i only dreaming \n",
            " is this burning an eternal flame \n",
            " i believe its meant to be darling \n",
            " i watch you when you are sleeping \n",
            " you belong with me \n",
            " do you feel the same \n",
            " am i only dreaming \n",
            " or is this burning an eternal flame \n",
            " say my name sun shines through the rain \n",
            " a whole life so lonely \n",
            " and then you come and ease the pain \n",
            " i dont want to lose this feeling \n",
            "\n",
            "\n",
            "1-Gram Cosine Similarity: -0.0845\n",
            "2-Gram Cosine Similarity: 0.4494\n",
            "3-Gram Cosine Similarity: 0.4173\n",
            "4-Gram Cosine Similarity: 0.5000\n",
            "Model 2: \n",
            "\n",
            "Generated Lyrics: close \n",
            " oz \n",
            " girl i was been there of us play where its good enough \n",
            " i wont at the damage a miles i see me grieving \n",
            " in molasses real endeavor will need you \n",
            " oh oh yes put and since the moment again \n",
            " you if cherish her girls that brother \n",
            " check \n",
            " im theres to hear me outside inside well face \n",
            " grab the midnight \n",
            " i am i walk in we going into the fucking aint whoa gotta pretty make me are all so a gonna toss \n",
            " and gone he used to play the state of here from the fields stress what\n",
            "\n",
            "Real Lyrics: close your eyes give me your hand darling \n",
            " do you feel my heart beating \n",
            " do you understand \n",
            " do you feel the same \n",
            " am i only dreaming \n",
            " is this burning an eternal flame \n",
            " i believe its meant to be darling \n",
            " i watch you when you are sleeping \n",
            " you belong with me \n",
            " do you feel the same \n",
            " am i only dreaming \n",
            " or is this burning an eternal flame \n",
            " say my name sun shines through the rain \n",
            " a whole life so lonely \n",
            " and then you come and ease the pain \n",
            " i dont want to lose this feeling \n",
            "\n",
            "\n",
            "1-Gram Cosine Similarity: -0.0705\n",
            "2-Gram Cosine Similarity: 0.4246\n",
            "3-Gram Cosine Similarity: 0.5505\n",
            "4-Gram Cosine Similarity: 0.5915\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_1783929/701868571.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  melody_feature_tensor = torch.tensor(melody_feature).float().to(device)\n",
            "/tmp/ipykernel_1783929/701868571.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  melody_feature_tensor = torch.tensor(melody_feature).float().to(device)\n"
          ]
        }
      ],
      "source": [
        "# Generate lyrics for a specific song\n",
        "initial_word = 'close'\n",
        "song_index = 0\n",
        "chosen_model = [model1, model2]\n",
        "print(f\"Song {song_index + 1}: {initial_word}\\n\")\n",
        "\n",
        "for model in chosen_model:\n",
        "  generated_lyrics = generate_text(model, X_test_load[song_index], word_model, initial_word, song_index)\n",
        "  # print model\n",
        "  print(f\"Model {chosen_model.index(model) + 1}: \\n\")\n",
        "  #print generated lyrics (if word is newline make it \\n)\n",
        "  generated_lyrics_with_newline = generated_lyrics\n",
        "  generated_lyrics_with_newline = generated_lyrics_with_newline.replace('newline', '\\n')\n",
        "  print(f\"Generated Lyrics: {generated_lyrics_with_newline}\\n\")\n",
        "\n",
        "  # Evaluate lyrics and store results\n",
        "  sim_1gram, sim_2gram, sim_3gram, sim_4gram = evaluate_lyrics(\n",
        "      generated_lyrics, song_index\n",
        "  )\n",
        "\n",
        "  if model == model1:  # Model 1\n",
        "      results_model1[\"1gram\"].append(sim_1gram)\n",
        "      results_model1[\"2gram\"].append(sim_2gram)\n",
        "      results_model1[\"3gram\"].append(sim_3gram)\n",
        "      results_model1[\"4gram\"].append(sim_4gram)\n",
        "  else:  # Model 2\n",
        "      results_model2[\"1gram\"].append(sim_1gram)\n",
        "      results_model2[\"2gram\"].append(sim_2gram)\n",
        "      results_model2[\"3gram\"].append(sim_3gram)\n",
        "      results_model2[\"4gram\"].append(sim_4gram)\n",
        "\n",
        "  print(f\"1-Gram Cosine Similarity: {sim_1gram:.4f}\")\n",
        "  print(f\"2-Gram Cosine Similarity: {sim_2gram:.4f}\")\n",
        "  print(f\"3-Gram Cosine Similarity: {sim_3gram:.4f}\")\n",
        "  print(f\"4-Gram Cosine Similarity: {sim_4gram:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSn0W9sN18an"
      },
      "source": [
        "## Word - your"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXW0aJZc18ao",
        "outputId": "e4e44129-e2e9-423b-900e-51f6eafbceeb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Song 1: your\n",
            "\n",
            "Model 1: \n",
            "\n",
            "Generated Lyrics: your eyes i help their deep room words in just never fingers their up out up watching to spend the same their would show in each pity out up for us wont uh a bitch its so many catch mess out \n",
            " to smile dead box dead fill their lonely till then delight \n",
            " cut mine and least my part hell \n",
            " help me clothes nice up to wail just meet the eternally dead rise dead late on time deceiving wants \n",
            " so true love \n",
            " one dead smile up \n",
            " lonely dead shine dead watching off is it together each moon bitch me hey take you care if\n",
            "\n",
            "Real Lyrics: close your eyes give me your hand darling \n",
            " do you feel my heart beating \n",
            " do you understand \n",
            " do you feel the same \n",
            " am i only dreaming \n",
            " is this burning an eternal flame \n",
            " i believe its meant to be darling \n",
            " i watch you when you are sleeping \n",
            " you belong with me \n",
            " do you feel the same \n",
            " am i only dreaming \n",
            " or is this burning an eternal flame \n",
            " say my name sun shines through the rain \n",
            " a whole life so lonely \n",
            " and then you come and ease the pain \n",
            " i dont want to lose this feeling \n",
            "\n",
            "\n",
            "1-Gram Cosine Similarity: 0.0381\n",
            "2-Gram Cosine Similarity: 0.4360\n",
            "3-Gram Cosine Similarity: 0.4575\n",
            "4-Gram Cosine Similarity: 0.5682\n",
            "Model 2: \n",
            "\n",
            "Generated Lyrics: your sister \n",
            " still gotta the glitter you balls from these mouth was trouble homie in wine silent lot of you hide me that da ba ba daa up in least not a dream man i close weighing the lions \n",
            " my life \n",
            " yeah ive \n",
            " fuck combination \n",
            " take you \n",
            " my mind they dialed like this time im \n",
            " said shes gonna be come my see ill win coming \n",
            " my grew im let \n",
            " that cant \n",
            " cause they bop \n",
            " slim \n",
            " flailing his faster \n",
            " we it anyway he said is there out this one man to the same i aint they rang\n",
            "\n",
            "Real Lyrics: close your eyes give me your hand darling \n",
            " do you feel my heart beating \n",
            " do you understand \n",
            " do you feel the same \n",
            " am i only dreaming \n",
            " is this burning an eternal flame \n",
            " i believe its meant to be darling \n",
            " i watch you when you are sleeping \n",
            " you belong with me \n",
            " do you feel the same \n",
            " am i only dreaming \n",
            " or is this burning an eternal flame \n",
            " say my name sun shines through the rain \n",
            " a whole life so lonely \n",
            " and then you come and ease the pain \n",
            " i dont want to lose this feeling \n",
            "\n",
            "\n",
            "1-Gram Cosine Similarity: 0.5302\n",
            "2-Gram Cosine Similarity: 0.2685\n",
            "3-Gram Cosine Similarity: 0.2581\n",
            "4-Gram Cosine Similarity: 0.3118\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_1783929/701868571.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  melody_feature_tensor = torch.tensor(melody_feature).float().to(device)\n",
            "/tmp/ipykernel_1783929/701868571.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  melody_feature_tensor = torch.tensor(melody_feature).float().to(device)\n"
          ]
        }
      ],
      "source": [
        "# Generate lyrics for a specific song\n",
        "initial_word = 'your'\n",
        "song_index = 0\n",
        "chosen_model = [model1, model2]\n",
        "print(f\"Song {song_index + 1}: {initial_word}\\n\")\n",
        "\n",
        "for model in chosen_model:\n",
        "  generated_lyrics = generate_text(model, X_test_load[song_index], word_model, initial_word, song_index)\n",
        "  # print model\n",
        "  print(f\"Model {chosen_model.index(model) + 1}: \\n\")\n",
        "  generated_lyrics_with_newline = generated_lyrics\n",
        "  generated_lyrics_with_newline = generated_lyrics_with_newline.replace('newline', '\\n')\n",
        "  print(f\"Generated Lyrics: {generated_lyrics_with_newline}\\n\")\n",
        "    # Evaluate lyrics and store results\n",
        "  sim_1gram, sim_2gram, sim_3gram, sim_4gram = evaluate_lyrics(\n",
        "      generated_lyrics, song_index\n",
        "  )\n",
        "\n",
        "  # Append results to the corresponding lists\n",
        "  if model == model1:  # Model 1\n",
        "      results_model1[\"1gram\"].append(sim_1gram)\n",
        "      results_model1[\"2gram\"].append(sim_2gram)\n",
        "      results_model1[\"3gram\"].append(sim_3gram)\n",
        "      results_model1[\"4gram\"].append(sim_4gram)\n",
        "  else:  # Model 2\n",
        "      results_model2[\"1gram\"].append(sim_1gram)\n",
        "      results_model2[\"2gram\"].append(sim_2gram)\n",
        "      results_model2[\"3gram\"].append(sim_3gram)\n",
        "      results_model2[\"4gram\"].append(sim_4gram)\n",
        "\n",
        "  print(f\"1-Gram Cosine Similarity: {sim_1gram:.4f}\")\n",
        "  print(f\"2-Gram Cosine Similarity: {sim_2gram:.4f}\")\n",
        "  print(f\"3-Gram Cosine Similarity: {sim_3gram:.4f}\")\n",
        "  print(f\"4-Gram Cosine Similarity: {sim_4gram:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2bG4DYh2Atm"
      },
      "source": [
        "## Word - eyes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onBfqaMa2Atn",
        "outputId": "e4e44129-e2e9-423b-900e-51f6eafbceeb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Song 1: eyes\n",
            "\n",
            "Model 1: \n",
            "\n",
            "Generated Lyrics: eyes \n",
            " so their black things can fly on \n",
            " i saw facing \n",
            " though you of my italian la la la la so i saw her arms everyday id brought yours god on and sleep dead of their just saw me of me \n",
            " soon it in god call dry living your mind no glimpse its never swear what im thinkin remember their dead getting heart greet about down \n",
            " because their shining room together picking thinkin out dead \n",
            " its could show in time my \n",
            " somebody what unkindly ho la la la la la do it easy up without you sleep and leave \n",
            " so many\n",
            "\n",
            "Real Lyrics: close your eyes give me your hand darling \n",
            " do you feel my heart beating \n",
            " do you understand \n",
            " do you feel the same \n",
            " am i only dreaming \n",
            " is this burning an eternal flame \n",
            " i believe its meant to be darling \n",
            " i watch you when you are sleeping \n",
            " you belong with me \n",
            " do you feel the same \n",
            " am i only dreaming \n",
            " or is this burning an eternal flame \n",
            " say my name sun shines through the rain \n",
            " a whole life so lonely \n",
            " and then you come and ease the pain \n",
            " i dont want to lose this feeling \n",
            "\n",
            "\n",
            "1-Gram Cosine Similarity: -0.1086\n",
            "2-Gram Cosine Similarity: 0.3219\n",
            "3-Gram Cosine Similarity: 0.4189\n",
            "4-Gram Cosine Similarity: 0.5381\n",
            "Model 2: \n",
            "\n",
            "Generated Lyrics: eyes without you did she got him play thats but flex da do it right out up in confusion sex then tha floss dark and ask me that right on soul brother \n",
            " in bali \n",
            " id make notice im meet \n",
            " ever read at em the papers \n",
            " with the bitch honey teacher the brother \n",
            " oh oh my legs bag an fan \n",
            " i were full real girlfriend \n",
            " coucher as honey maybe it three shoes probably all right crash there to mony will love he confronted ten as time the pops \n",
            " well \n",
            " oh the crowd all now baby and i really want it bop\n",
            "\n",
            "Real Lyrics: close your eyes give me your hand darling \n",
            " do you feel my heart beating \n",
            " do you understand \n",
            " do you feel the same \n",
            " am i only dreaming \n",
            " is this burning an eternal flame \n",
            " i believe its meant to be darling \n",
            " i watch you when you are sleeping \n",
            " you belong with me \n",
            " do you feel the same \n",
            " am i only dreaming \n",
            " or is this burning an eternal flame \n",
            " say my name sun shines through the rain \n",
            " a whole life so lonely \n",
            " and then you come and ease the pain \n",
            " i dont want to lose this feeling \n",
            "\n",
            "\n",
            "1-Gram Cosine Similarity: 0.3186\n",
            "2-Gram Cosine Similarity: 0.2883\n",
            "3-Gram Cosine Similarity: 0.5262\n",
            "4-Gram Cosine Similarity: 0.6432\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_1783929/701868571.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  melody_feature_tensor = torch.tensor(melody_feature).float().to(device)\n",
            "/tmp/ipykernel_1783929/701868571.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  melody_feature_tensor = torch.tensor(melody_feature).float().to(device)\n"
          ]
        }
      ],
      "source": [
        "# Generate lyrics for a specific song\n",
        "initial_word = 'eyes'\n",
        "song_index = 0\n",
        "chosen_model = [model1,model2]\n",
        "print(f\"Song {song_index + 1}: {initial_word}\\n\")\n",
        "\n",
        "for model in chosen_model:\n",
        "  generated_lyrics = generate_text(model, X_test_load[song_index], word_model, initial_word, song_index)\n",
        "  # print model\n",
        "  print(f\"Model {chosen_model.index(model) + 1}: \\n\")\n",
        "  generated_lyrics_with_newline = generated_lyrics\n",
        "  generated_lyrics_with_newline = generated_lyrics_with_newline.replace('newline', '\\n')\n",
        "  print(f\"Generated Lyrics: {generated_lyrics_with_newline}\\n\")\n",
        "    # Evaluate lyrics and store results\n",
        "  sim_1gram, sim_2gram, sim_3gram, sim_4gram = evaluate_lyrics(\n",
        "      generated_lyrics, song_index\n",
        "  )\n",
        "\n",
        "  # Append results to the corresponding lists\n",
        "  if idx == 0:  # Model 1\n",
        "      results_model1[\"1gram\"].append(sim_1gram)\n",
        "      results_model1[\"2gram\"].append(sim_2gram)\n",
        "      results_model1[\"3gram\"].append(sim_3gram)\n",
        "      results_model1[\"4gram\"].append(sim_4gram)\n",
        "  else:  # Model 2\n",
        "      results_model2[\"1gram\"].append(sim_1gram)\n",
        "      results_model2[\"2gram\"].append(sim_2gram)\n",
        "      results_model2[\"3gram\"].append(sim_3gram)\n",
        "      results_model2[\"4gram\"].append(sim_4gram)\n",
        "\n",
        "\n",
        "  print(f\"1-Gram Cosine Similarity: {sim_1gram:.4f}\")\n",
        "  print(f\"2-Gram Cosine Similarity: {sim_2gram:.4f}\")\n",
        "  print(f\"3-Gram Cosine Similarity: {sim_3gram:.4f}\")\n",
        "  print(f\"4-Gram Cosine Similarity: {sim_4gram:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nvOcOj32O3H"
      },
      "source": [
        "# **Test Song 2**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcCKMNxO2O3I"
      },
      "source": [
        "## Word - if"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_wcYPuv2O3I",
        "outputId": "e4e44129-e2e9-423b-900e-51f6eafbceeb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Song 2: if\n",
            "\n",
            "Model 1: \n",
            "\n",
            "Generated Lyrics: if a friend and ill be the time \n",
            " i incomprehensible \n",
            " pain dead anyway one time late make lonely room wrong ever when i saw each feeling so mess in a lot dead my car \n",
            " stab tight bitch oh ho says eyes of my head far time \n",
            " its where far dead smile \n",
            " this together for were enough closer day which sleep and lonely \n",
            " its racing die why glimpse \n",
            " cause love miss south of attitude room by the glimpse deceiving \n",
            " late she it easy bitch with them noise summit nc it late would love room in black never steps out just just watching wrapped closer depths by a bottle which bells \n",
            " living with their waterloo \n",
            " and their lonely cause my wants take by \n",
            " so easy ones brought full truth \n",
            " bitch to know what id never pity a times brought dead in least see when theres late \n",
            " their feeling my arms dead dead bitch no dead together full lonely dead cup around picking to make us pride cry in their beautiful steps upside \n",
            " getting both summit and fly room \n",
            " perfect twilight perfect wrong \n",
            " and the depths words id no than summer in a just call me ten naturally to live deceiving \n",
            " and lonely high this depths begin down for the wild well now it id grandmothers up is coming full far in their beautiful \n",
            " she wants no im\n",
            "\n",
            "Real Lyrics: if you search for tenderness \n",
            " it hard to find \n",
            " you can have the love you need to live \n",
            " but if you look for truthfulness \n",
            " you might just as well be blind \n",
            " it always seems to be so hard to give \n",
            " honesty is such a lonely word \n",
            " everyone is so untrue \n",
            " honesty is hardly ever heard \n",
            " and mostly what i need from you \n",
            " i can always find someone \n",
            " to say they sympathize \n",
            " if i wear my heart out on my sleeve \n",
            " but i dont want some pretty face \n",
            " to tell me pretty lies \n",
            " all i want is someone to believe \n",
            " honesty is such a lonely word \n",
            " everyone is so untrue \n",
            " honesty is hardly ever heard \n",
            " and mostly what i need from you \n",
            " i can find a lover \n",
            " i can find a friend \n",
            " i can have security until the bitter end \n",
            " anyone can comfort me \n",
            " with promises again \n",
            " i know i know \n",
            " when im deep inside of me \n",
            " dont be too concerned \n",
            " i wont ask for nothin while im gone \n",
            " but when i want sincerity \n",
            " tell me where else can i turn \n",
            " cause the one i depend upon \n",
            " honesty is such a lonely word \n",
            " everyone is so untrue \n",
            " honesty is hardly ever heard \n",
            " and mostly what i need from you \n",
            "\n",
            "\n",
            "1-Gram Cosine Similarity: 0.4580\n",
            "2-Gram Cosine Similarity: 0.2634\n",
            "3-Gram Cosine Similarity: 0.2893\n",
            "4-Gram Cosine Similarity: 0.3342\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_1783929/701868571.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  melody_feature_tensor = torch.tensor(melody_feature).float().to(device)\n",
            "/tmp/ipykernel_1783929/701868571.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  melody_feature_tensor = torch.tensor(melody_feature).float().to(device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model 2: \n",
            "\n",
            "Generated Lyrics: if you always seem to hear me so magic anybody baby brother \n",
            " my unbelievable the fire like they some a revolver up in years huh it \n",
            " guns \n",
            " shes my way about \n",
            " let your heart i put my heart \n",
            " my mom baby you ambition \n",
            " on up \n",
            " call me yeah \n",
            " and i saw the music so is on here and magic around your name is going real bitches i dine and eye say for in passing drown thats out of the devil \n",
            " heaven or they really want me on your out of springtime so dre wore heaven wont got imitating \n",
            " run \n",
            " with you here \n",
            " come too weed ooo \n",
            " is so much huh is i swear im here in mine \n",
            " cant want to me slowly \n",
            " im im type that midnight or secret brother so special dick daa your eyes back like you my dick and bringin drip straight i kiss in the recipe was for a fashion out yeah nigga \n",
            " photograph so full years meet your onion \n",
            " concrete my life is never party \n",
            " if i deserve i swore \n",
            " i was \n",
            " under the party \n",
            " his two \n",
            " and hi ba daa and always your lips \n",
            " bad at bones \n",
            " yeah yeah i always want it is mammals hes stand of outer \n",
            " its like what die mm \n",
            " what was all right in your magic\n",
            "\n",
            "Real Lyrics: if you search for tenderness \n",
            " it hard to find \n",
            " you can have the love you need to live \n",
            " but if you look for truthfulness \n",
            " you might just as well be blind \n",
            " it always seems to be so hard to give \n",
            " honesty is such a lonely word \n",
            " everyone is so untrue \n",
            " honesty is hardly ever heard \n",
            " and mostly what i need from you \n",
            " i can always find someone \n",
            " to say they sympathize \n",
            " if i wear my heart out on my sleeve \n",
            " but i dont want some pretty face \n",
            " to tell me pretty lies \n",
            " all i want is someone to believe \n",
            " honesty is such a lonely word \n",
            " everyone is so untrue \n",
            " honesty is hardly ever heard \n",
            " and mostly what i need from you \n",
            " i can find a lover \n",
            " i can find a friend \n",
            " i can have security until the bitter end \n",
            " anyone can comfort me \n",
            " with promises again \n",
            " i know i know \n",
            " when im deep inside of me \n",
            " dont be too concerned \n",
            " i wont ask for nothin while im gone \n",
            " but when i want sincerity \n",
            " tell me where else can i turn \n",
            " cause the one i depend upon \n",
            " honesty is such a lonely word \n",
            " everyone is so untrue \n",
            " honesty is hardly ever heard \n",
            " and mostly what i need from you \n",
            "\n",
            "\n",
            "1-Gram Cosine Similarity: 0.1680\n",
            "2-Gram Cosine Similarity: 0.6237\n",
            "3-Gram Cosine Similarity: 0.4979\n",
            "4-Gram Cosine Similarity: 0.5530\n"
          ]
        }
      ],
      "source": [
        "# Generate lyrics for a specific song\n",
        "initial_word = 'if'\n",
        "song_index = 1\n",
        "chosen_model = [model1, model2]\n",
        "print(f\"Song {song_index + 1}: {initial_word}\\n\")\n",
        "\n",
        "for model in chosen_model:\n",
        "  generated_lyrics = generate_text(model, X_test_load[song_index], word_model, initial_word, song_index)\n",
        "  # print model\n",
        "  print(f\"Model {chosen_model.index(model) + 1}: \\n\")\n",
        "  generated_lyrics_with_newline = generated_lyrics\n",
        "  generated_lyrics_with_newline = generated_lyrics_with_newline.replace('newline', '\\n')\n",
        "  print(f\"Generated Lyrics: {generated_lyrics_with_newline}\\n\")\n",
        "    # Evaluate lyrics and store results\n",
        "  sim_1gram, sim_2gram, sim_3gram, sim_4gram = evaluate_lyrics(\n",
        "      generated_lyrics, song_index\n",
        "  )\n",
        "\n",
        "  # Append results to the corresponding lists\n",
        "  if model == model1:  # Model 1\n",
        "      results_model1[\"1gram\"].append(sim_1gram)\n",
        "      results_model1[\"2gram\"].append(sim_2gram)\n",
        "      results_model1[\"3gram\"].append(sim_3gram)\n",
        "      results_model1[\"4gram\"].append(sim_4gram)\n",
        "  else:  # Model 2\n",
        "      results_model2[\"1gram\"].append(sim_1gram)\n",
        "      results_model2[\"2gram\"].append(sim_2gram)\n",
        "      results_model2[\"3gram\"].append(sim_3gram)\n",
        "      results_model2[\"4gram\"].append(sim_4gram)\n",
        "\n",
        "  print(f\"1-Gram Cosine Similarity: {sim_1gram:.4f}\")\n",
        "  print(f\"2-Gram Cosine Similarity: {sim_2gram:.4f}\")\n",
        "  print(f\"3-Gram Cosine Similarity: {sim_3gram:.4f}\")\n",
        "  print(f\"4-Gram Cosine Similarity: {sim_4gram:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBgPbISl2O3I"
      },
      "source": [
        "## Word - you"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "7QNuPXJ82O3J",
        "outputId": "ced49016-3922-4364-f46c-ca4fbe3a7bf2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Song 2: you\n",
            "\n",
            "Model 1: \n",
            "\n",
            "Generated Lyrics: you would is forever with me help you \n",
            " though their coming stoned ya not comes you let me late delight \n",
            " we live through together dead hell door enough late stoned where the black than just really when sleep their singing of lonely dead dead air \n",
            " never both big both times full big day comes said would feel for some eyes comes in those new regret \n",
            " brought glass and i saw me would get some arms of their life \n",
            " bitch bad part and the pity is watching my air of vain living where pity were it easy enough \n",
            " its \n",
            " \n",
            " surely dead yours doing in you getting it \n",
            " dearly shady always steps my glimpse shining dead of foolish god to sleep feel down where we think and could fly quit my heart dead dead arms our adams saw their car \n",
            " yeah would never a ten decisions so door fly nobody saw me for i saw a hole coming and lonely piano a friend which as bedouin lonely is coming love forget my their eyes thinking tomorrows needs i dont go for words and gray never ever reason for me where their part a bottle pills room mend to relate naturally in your knees to part late had \n",
            " in their eyes \n",
            " watching both a bottle \n",
            " never take \n",
            " getting easy it mess late is real of deceiving dead plays \n",
            " ring dead dead\n",
            "\n",
            "Real Lyrics: if you search for tenderness \n",
            " it hard to find \n",
            " you can have the love you need to live \n",
            " but if you look for truthfulness \n",
            " you might just as well be blind \n",
            " it always seems to be so hard to give \n",
            " honesty is such a lonely word \n",
            " everyone is so untrue \n",
            " honesty is hardly ever heard \n",
            " and mostly what i need from you \n",
            " i can always find someone \n",
            " to say they sympathize \n",
            " if i wear my heart out on my sleeve \n",
            " but i dont want some pretty face \n",
            " to tell me pretty lies \n",
            " all i want is someone to believe \n",
            " honesty is such a lonely word \n",
            " everyone is so untrue \n",
            " honesty is hardly ever heard \n",
            " and mostly what i need from you \n",
            " i can find a lover \n",
            " i can find a friend \n",
            " i can have security until the bitter end \n",
            " anyone can comfort me \n",
            " with promises again \n",
            " i know i know \n",
            " when im deep inside of me \n",
            " dont be too concerned \n",
            " i wont ask for nothin while im gone \n",
            " but when i want sincerity \n",
            " tell me where else can i turn \n",
            " cause the one i depend upon \n",
            " honesty is such a lonely word \n",
            " everyone is so untrue \n",
            " honesty is hardly ever heard \n",
            " and mostly what i need from you \n",
            "\n",
            "\n",
            "1-Gram Cosine Similarity: -0.0141\n",
            "2-Gram Cosine Similarity: 0.3409\n",
            "3-Gram Cosine Similarity: 0.3320\n",
            "4-Gram Cosine Similarity: 0.2952\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_1783929/701868571.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  melody_feature_tensor = torch.tensor(melody_feature).float().to(device)\n",
            "/tmp/ipykernel_1783929/701868571.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  melody_feature_tensor = torch.tensor(melody_feature).float().to(device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model 2: \n",
            "\n",
            "Generated Lyrics: you in a beautiful life \n",
            " dont kill blue full of a row of gold of you can start this earl \n",
            " was a nuts \n",
            " when no other on my eyes \n",
            " two eat eye that was all the vibe \n",
            " you are he calls the right through jerry bout wont you all im what \n",
            " kick close an big by your ass high with tha vegas \n",
            " and i dont stand out of twilight \n",
            " when i dont even stick into the place is all words \n",
            " you should i apologize talk was the tribal be in them \n",
            " got it off in tokyo like the workin baby \n",
            " siskel broke control \n",
            " with me cause they know cant get it off your name \n",
            " if lets find sparkling shady \n",
            " i could that i ask me live in vietnam know im da ba retired \n",
            " beat in a yea \n",
            " my cant wear back into its all i goodbye \n",
            " hes \n",
            " now she even tits she ever let you crawl hmm am you must make it was going up aw da daa excuse and people all out slim brother \n",
            " come into \n",
            " they snatch his soul you \n",
            " you on lines where you too swallow \n",
            " hes or he is you got it let \n",
            " they drop into the tidings \n",
            " but if i can swing all the bentley claus central and buried sidewalks by of the fire\n",
            "\n",
            "Real Lyrics: if you search for tenderness \n",
            " it hard to find \n",
            " you can have the love you need to live \n",
            " but if you look for truthfulness \n",
            " you might just as well be blind \n",
            " it always seems to be so hard to give \n",
            " honesty is such a lonely word \n",
            " everyone is so untrue \n",
            " honesty is hardly ever heard \n",
            " and mostly what i need from you \n",
            " i can always find someone \n",
            " to say they sympathize \n",
            " if i wear my heart out on my sleeve \n",
            " but i dont want some pretty face \n",
            " to tell me pretty lies \n",
            " all i want is someone to believe \n",
            " honesty is such a lonely word \n",
            " everyone is so untrue \n",
            " honesty is hardly ever heard \n",
            " and mostly what i need from you \n",
            " i can find a lover \n",
            " i can find a friend \n",
            " i can have security until the bitter end \n",
            " anyone can comfort me \n",
            " with promises again \n",
            " i know i know \n",
            " when im deep inside of me \n",
            " dont be too concerned \n",
            " i wont ask for nothin while im gone \n",
            " but when i want sincerity \n",
            " tell me where else can i turn \n",
            " cause the one i depend upon \n",
            " honesty is such a lonely word \n",
            " everyone is so untrue \n",
            " honesty is hardly ever heard \n",
            " and mostly what i need from you \n",
            "\n",
            "\n",
            "1-Gram Cosine Similarity: -0.0714\n",
            "2-Gram Cosine Similarity: 0.1992\n",
            "3-Gram Cosine Similarity: 0.2889\n",
            "4-Gram Cosine Similarity: 0.2448\n"
          ]
        }
      ],
      "source": [
        "# Generate lyrics for a specific song\n",
        "initial_word = 'you'\n",
        "song_index = 1\n",
        "chosen_model = [model1, model2]\n",
        "print(f\"Song {song_index + 1}: {initial_word}\\n\")\n",
        "\n",
        "for model in chosen_model:\n",
        "  generated_lyrics = generate_text(model, X_test_load[song_index], word_model, initial_word, song_index)\n",
        "  # print model\n",
        "  print(f\"Model {chosen_model.index(model) + 1}: \\n\")\n",
        "  generated_lyrics_with_newline = generated_lyrics\n",
        "  generated_lyrics_with_newline = generated_lyrics_with_newline.replace('newline', '\\n')\n",
        "  print(f\"Generated Lyrics: {generated_lyrics_with_newline}\\n\")\n",
        "    # Evaluate lyrics and store results\n",
        "  sim_1gram, sim_2gram, sim_3gram, sim_4gram = evaluate_lyrics(\n",
        "      generated_lyrics, song_index\n",
        "  )\n",
        "\n",
        "  # Append results to the corresponding lists\n",
        "  if model == model1:  # Model 1\n",
        "      results_model1[\"1gram\"].append(sim_1gram)\n",
        "      results_model1[\"2gram\"].append(sim_2gram)\n",
        "      results_model1[\"3gram\"].append(sim_3gram)\n",
        "      results_model1[\"4gram\"].append(sim_4gram)\n",
        "  else:  # Model 2\n",
        "      results_model2[\"1gram\"].append(sim_1gram)\n",
        "      results_model2[\"2gram\"].append(sim_2gram)\n",
        "      results_model2[\"3gram\"].append(sim_3gram)\n",
        "      results_model2[\"4gram\"].append(sim_4gram)\n",
        "\n",
        "  print(f\"1-Gram Cosine Similarity: {sim_1gram:.4f}\")\n",
        "  print(f\"2-Gram Cosine Similarity: {sim_2gram:.4f}\")\n",
        "  print(f\"3-Gram Cosine Similarity: {sim_3gram:.4f}\")\n",
        "  print(f\"4-Gram Cosine Similarity: {sim_4gram:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wzz52Rln2O3J"
      },
      "source": [
        "## Word - search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAstqfZj2O3J",
        "outputId": "e4e44129-e2e9-423b-900e-51f6eafbceeb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Song 2: search\n",
            "\n",
            "Model 1: \n",
            "\n",
            "Generated Lyrics: search watching their sweet pride baby \n",
            " said care dead \n",
            " with she ever misled go watching it \n",
            " i said would never easy right \n",
            " words \n",
            " attitude of their beautiful weather and hold the moon with myself bitch no glimpse \n",
            " cry bad \n",
            " because your door a hole of their pride is coming back to her door down \n",
            " because asking \n",
            " get me fall dead understand dead which monkey \n",
            " to when they say \n",
            " because \n",
            " an strong dead her shine god had id deceiving room remain the dearly and you wake \n",
            " lonely dead dead to reach watching \n",
            " playing your part for me away late \n",
            " bitch im ho in a bottle pride \n",
            " bitch im catch you both late dont sleep \n",
            " of a getting ten big cry tight shes black emotion enough closer far cry to mess \n",
            " theres perfect light naturally it now baby wrapped door together eye thinkin and i want their it \n",
            " because their two time \n",
            " everybody down now live picking up in their still deep bitch he ever forget dead show which sake of my arms up so big god it would take little lives forget \n",
            " just must fly up of up of wrapped in a times room down \n",
            " and thinking picking dead to myself dont mess in in the hot uh ho coming \n",
            " it on this crowd down late had to forget your sexy\n",
            "\n",
            "Real Lyrics: if you search for tenderness \n",
            " it hard to find \n",
            " you can have the love you need to live \n",
            " but if you look for truthfulness \n",
            " you might just as well be blind \n",
            " it always seems to be so hard to give \n",
            " honesty is such a lonely word \n",
            " everyone is so untrue \n",
            " honesty is hardly ever heard \n",
            " and mostly what i need from you \n",
            " i can always find someone \n",
            " to say they sympathize \n",
            " if i wear my heart out on my sleeve \n",
            " but i dont want some pretty face \n",
            " to tell me pretty lies \n",
            " all i want is someone to believe \n",
            " honesty is such a lonely word \n",
            " everyone is so untrue \n",
            " honesty is hardly ever heard \n",
            " and mostly what i need from you \n",
            " i can find a lover \n",
            " i can find a friend \n",
            " i can have security until the bitter end \n",
            " anyone can comfort me \n",
            " with promises again \n",
            " i know i know \n",
            " when im deep inside of me \n",
            " dont be too concerned \n",
            " i wont ask for nothin while im gone \n",
            " but when i want sincerity \n",
            " tell me where else can i turn \n",
            " cause the one i depend upon \n",
            " honesty is such a lonely word \n",
            " everyone is so untrue \n",
            " honesty is hardly ever heard \n",
            " and mostly what i need from you \n",
            "\n",
            "\n",
            "1-Gram Cosine Similarity: 0.4008\n",
            "2-Gram Cosine Similarity: 0.6524\n",
            "3-Gram Cosine Similarity: 0.4832\n",
            "4-Gram Cosine Similarity: 0.5388\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_1783929/701868571.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  melody_feature_tensor = torch.tensor(melody_feature).float().to(device)\n",
            "/tmp/ipykernel_1783929/701868571.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  melody_feature_tensor = torch.tensor(melody_feature).float().to(device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model 2: \n",
            "\n",
            "Generated Lyrics: search mad all surprise cause baby for the chalet hoop you \n",
            " \n",
            " hes mountains \n",
            " and four bridges a genie out of play to explain your mind of skin mating dial some never been inside \n",
            " but you else outside here \n",
            " there to touch on \n",
            " thats cause up past not right in baby when the jam \n",
            " \n",
            " they stick that nigga up \n",
            " be fast \n",
            " perfect hot \n",
            " cause you monstrous of vietnam sleep \n",
            " you mean your name was too hard to the motives \n",
            " but the big smokin here like as im chauncey if give made put my problems ooh of his \n",
            " slim but mine me and play a thousand of allentown slim bush game at her pants \n",
            " born to bag everytime with somebody i earth \n",
            " in anywhere fuckin up bag asleep oh \n",
            " im rainbow hip nigga \n",
            " you wanna excuse back you that wont so time of day please \n",
            " kiss smokin break you can never slip full time \n",
            " and some people up my heart \n",
            " slim \n",
            " so another new somebody stay it endless hi im i drumbeat known there \n",
            " for him in her on fan da ba daa a bitch oh hes the good or fields the potion sighs come or it easy a once at the intergalactic shady \n",
            " anyways thats you want someone else \n",
            " i dont work young open \n",
            " and donde need a\n",
            "\n",
            "Real Lyrics: if you search for tenderness \n",
            " it hard to find \n",
            " you can have the love you need to live \n",
            " but if you look for truthfulness \n",
            " you might just as well be blind \n",
            " it always seems to be so hard to give \n",
            " honesty is such a lonely word \n",
            " everyone is so untrue \n",
            " honesty is hardly ever heard \n",
            " and mostly what i need from you \n",
            " i can always find someone \n",
            " to say they sympathize \n",
            " if i wear my heart out on my sleeve \n",
            " but i dont want some pretty face \n",
            " to tell me pretty lies \n",
            " all i want is someone to believe \n",
            " honesty is such a lonely word \n",
            " everyone is so untrue \n",
            " honesty is hardly ever heard \n",
            " and mostly what i need from you \n",
            " i can find a lover \n",
            " i can find a friend \n",
            " i can have security until the bitter end \n",
            " anyone can comfort me \n",
            " with promises again \n",
            " i know i know \n",
            " when im deep inside of me \n",
            " dont be too concerned \n",
            " i wont ask for nothin while im gone \n",
            " but when i want sincerity \n",
            " tell me where else can i turn \n",
            " cause the one i depend upon \n",
            " honesty is such a lonely word \n",
            " everyone is so untrue \n",
            " honesty is hardly ever heard \n",
            " and mostly what i need from you \n",
            "\n",
            "\n",
            "1-Gram Cosine Similarity: -0.0168\n",
            "2-Gram Cosine Similarity: 0.2938\n",
            "3-Gram Cosine Similarity: 0.2927\n",
            "4-Gram Cosine Similarity: 0.5131\n"
          ]
        }
      ],
      "source": [
        "# Generate lyrics for a specific song\n",
        "initial_word = 'search'\n",
        "song_index = 1\n",
        "chosen_model = [model1, model2]\n",
        "print(f\"Song {song_index + 1}: {initial_word}\\n\")\n",
        "\n",
        "for model in chosen_model:\n",
        "  generated_lyrics = generate_text(model, X_test_load[song_index], word_model, initial_word, song_index)\n",
        "  # print model\n",
        "  print(f\"Model {chosen_model.index(model) + 1}: \\n\")\n",
        "  generated_lyrics_with_newline = generated_lyrics\n",
        "  generated_lyrics_with_newline = generated_lyrics_with_newline.replace('newline', '\\n')\n",
        "  print(f\"Generated Lyrics: {generated_lyrics_with_newline}\\n\")\n",
        "    # Evaluate lyrics and store results\n",
        "  sim_1gram, sim_2gram, sim_3gram, sim_4gram = evaluate_lyrics(\n",
        "      generated_lyrics, song_index\n",
        "  )\n",
        "\n",
        "  # Append results to the corresponding lists\n",
        "  if model == model1:  # Model 1\n",
        "      results_model1[\"1gram\"].append(sim_1gram)\n",
        "      results_model1[\"2gram\"].append(sim_2gram)\n",
        "      results_model1[\"3gram\"].append(sim_3gram)\n",
        "      results_model1[\"4gram\"].append(sim_4gram)\n",
        "  else:  # Model 2\n",
        "      results_model2[\"1gram\"].append(sim_1gram)\n",
        "      results_model2[\"2gram\"].append(sim_2gram)\n",
        "      results_model2[\"3gram\"].append(sim_3gram)\n",
        "      results_model2[\"4gram\"].append(sim_4gram)\n",
        "\n",
        "  print(f\"1-Gram Cosine Similarity: {sim_1gram:.4f}\")\n",
        "  print(f\"2-Gram Cosine Similarity: {sim_2gram:.4f}\")\n",
        "  print(f\"3-Gram Cosine Similarity: {sim_3gram:.4f}\")\n",
        "  print(f\"4-Gram Cosine Similarity: {sim_4gram:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LySbk_S2eEA"
      },
      "source": [
        "# **Test Song 3**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dqtA7Sy2eEB"
      },
      "source": [
        "## Word - dear"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjDVYxnF2eEB",
        "outputId": "e4e44129-e2e9-423b-900e-51f6eafbceeb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Song 3: dear\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_1783929/701868571.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  melody_feature_tensor = torch.tensor(melody_feature).float().to(device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model 1: \n",
            "\n",
            "Generated Lyrics: dear seem to stay sorrow who dead dream so good face their lonely im black of their nigga bitch me bitch dead car \n",
            " sleep is a soft of around their sleep line \n",
            " but we down want to say just you smile huh and fly from my blues down \n",
            " you \n",
            " them eyes \n",
            " to take a naturally a bottle dead room so thinkin of delight dont deceiving ooh dead gotta fly their door id had for you needs their ring \n",
            " bitch \n",
            " \n",
            " and i saw a late but i saw just just thinkin deceiving \n",
            " honey im their saw a wild deceiving dead in my heart their pride box than black boys make some ringing \n",
            " just which die weed back picking soon out \n",
            " never la la du da da da some dead glass the hole dead and were it so facing up for dead some two night for people watching up your throw for a hole one late is one fernando \n",
            " would try again late is their two coming their eyes which part high deceiving on sorrow my what to say about im a room to nobody fits without him would never for summit to relate to hold for me ends bitch dead without their finger for a cash moon \n",
            " though their attitude dead for my name \n",
            " attitude black strange letter \n",
            " he had to make myself no day watching some you by that must myself cry up full father just thinking with \n",
            " me so \n",
            " \n",
            " fly watching closer so melodies \n",
            " oh with for the arms delight dead room wrapped that bedouin deceiving so baby and facing which said live for the depths of a four words watching on out late \n",
            " remember closer bad miss by of air is real wail and thinking bitch he said her dreams bring a place baby \n",
            " just saw us door bitch by time wrapped down and their house \n",
            " on the their big night and your would give\n",
            "\n",
            "Real Lyrics: dear i fear were facing a problem \n",
            " you love me no longer i know \n",
            " and maybe there is nothing \n",
            " that i can do to make you do \n",
            " mama tells me i bother \n",
            " that i ought to stick to another man \n",
            " a man that surely deserves me \n",
            " but i think you do \n",
            " so i cry i pray and i beg \n",
            " love me love me \n",
            " say that you love me \n",
            " fool me fool me \n",
            " go on and fool me \n",
            " love me love me \n",
            " pretend that you love me \n",
            " leave me leave me \n",
            " just say that you need me \n",
            " love me love me \n",
            " say that you love me \n",
            " leave me leave me \n",
            " just say that you need me \n",
            " i cant care bout anything but you \n",
            " lately i have desperately pondered \n",
            " spent my nights awake and i wonder \n",
            " what i could have done in another way \n",
            " to make you stay \n",
            " reason will not lead to solution \n",
            " i will end up lost in confusion \n",
            " i dont care if you really care \n",
            " as long as you dont go \n",
            " so i cry i pray and i beg \n",
            " love me love me \n",
            " say that you love me \n",
            " fool me fool me \n",
            " go on and fool me \n",
            " love me love me \n",
            " pretend that you love me \n",
            " leave me leave me \n",
            " just say that you need me \n",
            " so i cry and i pray for you to \n",
            " love me love me \n",
            " say that you love me \n",
            " leave me leave me \n",
            " just say that you need me \n",
            " i cant care bout anything but you \n",
            " anything but you \n",
            " love me love me say that you love me \n",
            " fool me fool me go on and fool me \n",
            " love me love me i know that you need me \n",
            " i cant care bout anything but you \n",
            "\n",
            "\n",
            "1-Gram Cosine Similarity: 0.1975\n",
            "2-Gram Cosine Similarity: 0.3017\n",
            "3-Gram Cosine Similarity: 0.4692\n",
            "4-Gram Cosine Similarity: 0.5135\n",
            "Model 2: \n",
            "\n",
            "Generated Lyrics: dear and suck to take them babe \n",
            " he feel just they say id start more more more \n",
            " you on your new world \n",
            " anyways make on and im if there you feel blow miles who collects me now me go no tears \n",
            " you cry baby beat turning true \n",
            " you say he really could stop \n",
            " instead get master but all all away \n",
            " from daylight stick like keeps to fly ride \n",
            " tribal realized that from myself not you better late \n",
            " i like me up \n",
            " fa like walkin \n",
            " to belong that lies i aint you know how some also time i spin our heart \n",
            " jingle sorry and going on everything you \n",
            " boy \n",
            " well still understand me on war thing and tomorrow \n",
            " but you dont be down \n",
            " take a change dancing \n",
            " as we feel somebody but you had im \n",
            " i comes out again \n",
            " do you do love out of school above \n",
            " then the day passages i know i have you \n",
            " only it to do \n",
            " with my arms stealin make your eyes \n",
            " im oh he was i believe word to guide \n",
            " coucher \n",
            " like you give her feel your life \n",
            " o da da saw the der jeans \n",
            " in the way of man \n",
            " the trees \n",
            " aint more day may know \n",
            " yeah ow together \n",
            " think \n",
            " just have a tonic \n",
            " la la la la la la la la la la do \n",
            " lets a happy like all those bar quick train sail such a candy girl that they say you do \n",
            " blow again \n",
            " how they got away \n",
            " he said for my whole clothes distance \n",
            " now still liked \n",
            " toss \n",
            " dawn that man has only ever black pretty times we hide truth that special in this great far as understands be walk em apart be to anyone \n",
            " you \n",
            " i did \n",
            " and they have your dough cupid \n",
            " the history\n",
            "\n",
            "Real Lyrics: dear i fear were facing a problem \n",
            " you love me no longer i know \n",
            " and maybe there is nothing \n",
            " that i can do to make you do \n",
            " mama tells me i bother \n",
            " that i ought to stick to another man \n",
            " a man that surely deserves me \n",
            " but i think you do \n",
            " so i cry i pray and i beg \n",
            " love me love me \n",
            " say that you love me \n",
            " fool me fool me \n",
            " go on and fool me \n",
            " love me love me \n",
            " pretend that you love me \n",
            " leave me leave me \n",
            " just say that you need me \n",
            " love me love me \n",
            " say that you love me \n",
            " leave me leave me \n",
            " just say that you need me \n",
            " i cant care bout anything but you \n",
            " lately i have desperately pondered \n",
            " spent my nights awake and i wonder \n",
            " what i could have done in another way \n",
            " to make you stay \n",
            " reason will not lead to solution \n",
            " i will end up lost in confusion \n",
            " i dont care if you really care \n",
            " as long as you dont go \n",
            " so i cry i pray and i beg \n",
            " love me love me \n",
            " say that you love me \n",
            " fool me fool me \n",
            " go on and fool me \n",
            " love me love me \n",
            " pretend that you love me \n",
            " leave me leave me \n",
            " just say that you need me \n",
            " so i cry and i pray for you to \n",
            " love me love me \n",
            " say that you love me \n",
            " leave me leave me \n",
            " just say that you need me \n",
            " i cant care bout anything but you \n",
            " anything but you \n",
            " love me love me say that you love me \n",
            " fool me fool me go on and fool me \n",
            " love me love me i know that you need me \n",
            " i cant care bout anything but you \n",
            "\n",
            "\n",
            "1-Gram Cosine Similarity: -0.0335\n",
            "2-Gram Cosine Similarity: 0.0477\n",
            "3-Gram Cosine Similarity: 0.1558\n",
            "4-Gram Cosine Similarity: 0.1592\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_1783929/701868571.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  melody_feature_tensor = torch.tensor(melody_feature).float().to(device)\n"
          ]
        }
      ],
      "source": [
        "# Generate lyrics for a specific song\n",
        "initial_word = 'dear'\n",
        "song_index = 2\n",
        "chosen_model = [model1, model2]\n",
        "print(f\"Song {song_index + 1}: {initial_word}\\n\")\n",
        "\n",
        "for model in chosen_model:\n",
        "  generated_lyrics = generate_text(model, X_test_load[song_index], word_model, initial_word, song_index)\n",
        "  # print model\n",
        "  print(f\"Model {chosen_model.index(model) + 1}: \\n\")\n",
        "  generated_lyrics_with_newline = generated_lyrics\n",
        "  generated_lyrics_with_newline = generated_lyrics_with_newline.replace('newline', '\\n')\n",
        "  print(f\"Generated Lyrics: {generated_lyrics_with_newline}\\n\")\n",
        "    # Evaluate lyrics and store results\n",
        "  sim_1gram, sim_2gram, sim_3gram, sim_4gram = evaluate_lyrics(\n",
        "      generated_lyrics, song_index\n",
        "  )\n",
        "\n",
        "  # Append results to the corresponding lists\n",
        "  if model == model1:  # Model 1\n",
        "      results_model1[\"1gram\"].append(sim_1gram)\n",
        "      results_model1[\"2gram\"].append(sim_2gram)\n",
        "      results_model1[\"3gram\"].append(sim_3gram)\n",
        "      results_model1[\"4gram\"].append(sim_4gram)\n",
        "  else:  # Model 2\n",
        "      results_model2[\"1gram\"].append(sim_1gram)\n",
        "      results_model2[\"2gram\"].append(sim_2gram)\n",
        "      results_model2[\"3gram\"].append(sim_3gram)\n",
        "      results_model2[\"4gram\"].append(sim_4gram)\n",
        "\n",
        "\n",
        "  print(f\"1-Gram Cosine Similarity: {sim_1gram:.4f}\")\n",
        "  print(f\"2-Gram Cosine Similarity: {sim_2gram:.4f}\")\n",
        "  print(f\"3-Gram Cosine Similarity: {sim_3gram:.4f}\")\n",
        "  print(f\"4-Gram Cosine Similarity: {sim_4gram:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrsy2cfJ2eEB"
      },
      "source": [
        "## Word - i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "4kQioJA32eEC",
        "outputId": "ced49016-3922-4364-f46c-ca4fbe3a7bf2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Song 3: i\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_1783929/701868571.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  melody_feature_tensor = torch.tensor(melody_feature).float().to(device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model 1: \n",
            "\n",
            "Generated Lyrics: i hes hell dead of guy were deceiving which wont so late grandmothers line high lovers whats so dark \n",
            " i baby im na im ho da da melodies their lonely need a fingers deceiving \n",
            " quit their could never slit \n",
            " they saw the attitude dead brother dead enough late stoned free to go by me alone and gotta feel they stab dead dead cry \n",
            " but im really a hole of your fingers alone forget you said sleep \n",
            " oh oh ho ho here around of into every noise when my stab full room open watching it its getting moments door away \n",
            " so gone and it easy free of their fingers workin mess your bell my part dead is mine \n",
            " and incomprehensible dead dead had remember all that came out by door \n",
            " oh \n",
            " that of a place to ever one late to fly em da da \n",
            " still racing on \n",
            " part door \n",
            " it new beautiful no emotion incomprehensible deceiving i wrong and i part my would show me are no ringing is \n",
            " quit which sleep in a bottle dead door late is dead line of looking their lonely dead way \n",
            " and thinking attracted black room ill be deceiving my part \n",
            " hey some day line of view is which live with their side open now would the bottle \n",
            " for you \n",
            " so it down of when youd is my way im ho so to stop up \n",
            " pay dead by of which beautiful of me too lonely dead so your part is loved thinkin photograph \n",
            " leavin so warm about your summer time \n",
            " were deceiving \n",
            " deceiving dead black dead had to lie \n",
            " would \n",
            " and my scene that day bitch you meet dead true as late to me has no enough hard bitch me both of their which easy in their slit without you meet hi im just da in one black bitch \n",
            " fly room full reason black old getting a hole in their\n",
            "\n",
            "Real Lyrics: dear i fear were facing a problem \n",
            " you love me no longer i know \n",
            " and maybe there is nothing \n",
            " that i can do to make you do \n",
            " mama tells me i bother \n",
            " that i ought to stick to another man \n",
            " a man that surely deserves me \n",
            " but i think you do \n",
            " so i cry i pray and i beg \n",
            " love me love me \n",
            " say that you love me \n",
            " fool me fool me \n",
            " go on and fool me \n",
            " love me love me \n",
            " pretend that you love me \n",
            " leave me leave me \n",
            " just say that you need me \n",
            " love me love me \n",
            " say that you love me \n",
            " leave me leave me \n",
            " just say that you need me \n",
            " i cant care bout anything but you \n",
            " lately i have desperately pondered \n",
            " spent my nights awake and i wonder \n",
            " what i could have done in another way \n",
            " to make you stay \n",
            " reason will not lead to solution \n",
            " i will end up lost in confusion \n",
            " i dont care if you really care \n",
            " as long as you dont go \n",
            " so i cry i pray and i beg \n",
            " love me love me \n",
            " say that you love me \n",
            " fool me fool me \n",
            " go on and fool me \n",
            " love me love me \n",
            " pretend that you love me \n",
            " leave me leave me \n",
            " just say that you need me \n",
            " so i cry and i pray for you to \n",
            " love me love me \n",
            " say that you love me \n",
            " leave me leave me \n",
            " just say that you need me \n",
            " i cant care bout anything but you \n",
            " anything but you \n",
            " love me love me say that you love me \n",
            " fool me fool me go on and fool me \n",
            " love me love me i know that you need me \n",
            " i cant care bout anything but you \n",
            "\n",
            "\n",
            "1-Gram Cosine Similarity: -0.0678\n",
            "2-Gram Cosine Similarity: 0.1653\n",
            "3-Gram Cosine Similarity: 0.3418\n",
            "4-Gram Cosine Similarity: 0.3978\n",
            "Model 2: \n",
            "\n",
            "Generated Lyrics: i pass \n",
            " make every forever \n",
            " need a new world \n",
            " morning to wait the getting secrets in the rain everyday its just anybody woo to common rich man goes on the sunday money \n",
            " ooh just near \n",
            " maybe it too long to surely all \n",
            " eighth every mary comes empty cool i see \n",
            " should love is not a pap still \n",
            " the way was cry im jackie \n",
            " if now disguise sing they be the shining on apart bite it wrong enough to you belong \n",
            " la la and make me christmas cold time there must even get along \n",
            " the blow of vain changed \n",
            " say it be my quiet soul \n",
            " blue plus star of heaven laughs \n",
            " i speak i hope of to eternal sign your living around a for something \n",
            " never ever de la la la la could take eyesight lane \n",
            " lido \n",
            " i stumble knee deep told us know the casbah and now it \n",
            " chorus lewis \n",
            " one whenever i hear me home you \n",
            " listen that loves me \n",
            " let me \n",
            " oh my friend fernando so there \n",
            " where i just just me on top again \n",
            " now you lie \n",
            " suit pressure \n",
            " wanna give \n",
            " another pain \n",
            " boys theres everybody in emotional blue is goin was over the only knew i want to party \n",
            " repeat ill knew \n",
            " human sinned \n",
            " save to grow before you could scream your mind \n",
            " i cant \n",
            " theres \n",
            " the shes \n",
            " take way up in what \n",
            " and tomorrows know why we moan he lookin \n",
            " think ive time i dont get tired because the ocean to that \n",
            " believe me hey \n",
            " yes oh cuerpo more \n",
            " the end on your seven and rosy too when she wakes the stars \n",
            " comes of bein chorus without i found it like deep its my pain le la la la la la la la could to bother where now come \n",
            " yeah worse days\n",
            "\n",
            "Real Lyrics: dear i fear were facing a problem \n",
            " you love me no longer i know \n",
            " and maybe there is nothing \n",
            " that i can do to make you do \n",
            " mama tells me i bother \n",
            " that i ought to stick to another man \n",
            " a man that surely deserves me \n",
            " but i think you do \n",
            " so i cry i pray and i beg \n",
            " love me love me \n",
            " say that you love me \n",
            " fool me fool me \n",
            " go on and fool me \n",
            " love me love me \n",
            " pretend that you love me \n",
            " leave me leave me \n",
            " just say that you need me \n",
            " love me love me \n",
            " say that you love me \n",
            " leave me leave me \n",
            " just say that you need me \n",
            " i cant care bout anything but you \n",
            " lately i have desperately pondered \n",
            " spent my nights awake and i wonder \n",
            " what i could have done in another way \n",
            " to make you stay \n",
            " reason will not lead to solution \n",
            " i will end up lost in confusion \n",
            " i dont care if you really care \n",
            " as long as you dont go \n",
            " so i cry i pray and i beg \n",
            " love me love me \n",
            " say that you love me \n",
            " fool me fool me \n",
            " go on and fool me \n",
            " love me love me \n",
            " pretend that you love me \n",
            " leave me leave me \n",
            " just say that you need me \n",
            " so i cry and i pray for you to \n",
            " love me love me \n",
            " say that you love me \n",
            " leave me leave me \n",
            " just say that you need me \n",
            " i cant care bout anything but you \n",
            " anything but you \n",
            " love me love me say that you love me \n",
            " fool me fool me go on and fool me \n",
            " love me love me i know that you need me \n",
            " i cant care bout anything but you \n",
            "\n",
            "\n",
            "1-Gram Cosine Similarity: -0.0879\n",
            "2-Gram Cosine Similarity: 0.2804\n",
            "3-Gram Cosine Similarity: 0.3969\n",
            "4-Gram Cosine Similarity: 0.4250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_1783929/701868571.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  melody_feature_tensor = torch.tensor(melody_feature).float().to(device)\n"
          ]
        }
      ],
      "source": [
        "# Generate lyrics for a specific song\n",
        "initial_word = 'i'\n",
        "song_index = 2\n",
        "chosen_model = [model1, model2]\n",
        "print(f\"Song {song_index + 1}: {initial_word}\\n\")\n",
        "\n",
        "for model in chosen_model:\n",
        "  generated_lyrics = generate_text(model, X_test_load[song_index], word_model, initial_word, song_index)\n",
        "  # print model\n",
        "  print(f\"Model {chosen_model.index(model) + 1}: \\n\")\n",
        "  generated_lyrics_with_newline = generated_lyrics\n",
        "  generated_lyrics_with_newline = generated_lyrics_with_newline.replace('newline', '\\n')\n",
        "  print(f\"Generated Lyrics: {generated_lyrics_with_newline}\\n\")\n",
        "    # Evaluate lyrics and store results\n",
        "  sim_1gram, sim_2gram, sim_3gram, sim_4gram = evaluate_lyrics(\n",
        "      generated_lyrics, song_index\n",
        "  )\n",
        "\n",
        "  # Append results to the corresponding lists\n",
        "  if model == model1:  # Model 1\n",
        "      results_model1[\"1gram\"].append(sim_1gram)\n",
        "      results_model1[\"2gram\"].append(sim_2gram)\n",
        "      results_model1[\"3gram\"].append(sim_3gram)\n",
        "      results_model1[\"4gram\"].append(sim_4gram)\n",
        "  else:  # Model 2\n",
        "      results_model2[\"1gram\"].append(sim_1gram)\n",
        "      results_model2[\"2gram\"].append(sim_2gram)\n",
        "      results_model2[\"3gram\"].append(sim_3gram)\n",
        "      results_model2[\"4gram\"].append(sim_4gram)\n",
        "\n",
        "  print(f\"1-Gram Cosine Similarity: {sim_1gram:.4f}\")\n",
        "  print(f\"2-Gram Cosine Similarity: {sim_2gram:.4f}\")\n",
        "  print(f\"3-Gram Cosine Similarity: {sim_3gram:.4f}\")\n",
        "  print(f\"4-Gram Cosine Similarity: {sim_4gram:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0ltRzmU2eEC"
      },
      "source": [
        "## Word - fear"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KGQJqcT2eEC",
        "outputId": "e4e44129-e2e9-423b-900e-51f6eafbceeb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Song 3: fear\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_1783929/701868571.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  melody_feature_tensor = torch.tensor(melody_feature).float().to(device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model 1: \n",
            "\n",
            "Generated Lyrics: fear \n",
            " just fly turn dead \n",
            " and take back dead and late is dead \n",
            " because their lonely steps of their pride hungry ten of mine \n",
            " oh ill see \n",
            " cause incomprehensible places by the mend \n",
            " id said the getting their best \n",
            " both she wants god into every which door i call up door i rest and what need us live enough big would so honey to take me so easy bad bitch \n",
            " ah living room \n",
            " for the monkey and moon room thinking me throw full dead uh \n",
            " te to go tight door by alright baby smile black coming room both to go remain me \n",
            " im coming up knows in my hope \n",
            " gimme pity baby \n",
            " so i saw id a four day of tellin yeah bell do it easy bitch racing my sleep \n",
            " so hell \n",
            " hes ten place closer cruel dead their open go \n",
            " when ill go \n",
            " perfect lot of my mind \n",
            " i had in delight lonely god true im coming \n",
            " breakin \n",
            " both lonely hungry dead deep incomprehensible day where try open back away \n",
            " we kissed one as into it easy matters comes \n",
            " and live em in time trying \n",
            " baby dead keep black day cause to would understand in love it bring the depths \n",
            " the moon my room to forget dead til oh dead with me room right lane fernando da da da da da da da da da da da da la la la la la la la la da da da is a glimpse both one little depths bitch dead home \n",
            " stab shit which glimpse of my heart place high dead \n",
            " we call my big only depths one duke words for \n",
            " one black deceiving me just one dance apart im down of me know we and til \n",
            " keeps in their screwing you forgotten \n",
            " while now about \n",
            " and remember miss you true \n",
            " one remember god eternally and lets go reach\n",
            "\n",
            "Real Lyrics: dear i fear were facing a problem \n",
            " you love me no longer i know \n",
            " and maybe there is nothing \n",
            " that i can do to make you do \n",
            " mama tells me i bother \n",
            " that i ought to stick to another man \n",
            " a man that surely deserves me \n",
            " but i think you do \n",
            " so i cry i pray and i beg \n",
            " love me love me \n",
            " say that you love me \n",
            " fool me fool me \n",
            " go on and fool me \n",
            " love me love me \n",
            " pretend that you love me \n",
            " leave me leave me \n",
            " just say that you need me \n",
            " love me love me \n",
            " say that you love me \n",
            " leave me leave me \n",
            " just say that you need me \n",
            " i cant care bout anything but you \n",
            " lately i have desperately pondered \n",
            " spent my nights awake and i wonder \n",
            " what i could have done in another way \n",
            " to make you stay \n",
            " reason will not lead to solution \n",
            " i will end up lost in confusion \n",
            " i dont care if you really care \n",
            " as long as you dont go \n",
            " so i cry i pray and i beg \n",
            " love me love me \n",
            " say that you love me \n",
            " fool me fool me \n",
            " go on and fool me \n",
            " love me love me \n",
            " pretend that you love me \n",
            " leave me leave me \n",
            " just say that you need me \n",
            " so i cry and i pray for you to \n",
            " love me love me \n",
            " say that you love me \n",
            " leave me leave me \n",
            " just say that you need me \n",
            " i cant care bout anything but you \n",
            " anything but you \n",
            " love me love me say that you love me \n",
            " fool me fool me go on and fool me \n",
            " love me love me i know that you need me \n",
            " i cant care bout anything but you \n",
            "\n",
            "\n",
            "1-Gram Cosine Similarity: 0.0464\n",
            "2-Gram Cosine Similarity: 0.3972\n",
            "3-Gram Cosine Similarity: 0.4260\n",
            "4-Gram Cosine Similarity: 0.4885\n",
            "Model 2: \n",
            "\n",
            "Generated Lyrics: fear twice names \n",
            " ooh they suffered as less else no games \n",
            " but your face \n",
            " you were blind do i never meet \n",
            " time about a fancy \n",
            " i love is \n",
            " well we saw where \n",
            " leave the place for my thang \n",
            " \n",
            " but so caught it must fool you bought so i love for tune people girl she said of the winner \n",
            " youd looking so easy for time \n",
            " had \n",
            " oh amadeus freak \n",
            " i see you learn gonna give each men on every time to take on and now as the eye \n",
            " ive up to not glory he set you say \n",
            " your cares in a crazy \n",
            " play so faithful like my freedom dreadlock \n",
            " girl \n",
            " before \n",
            " we can feel well if you got to the flow wild or waterloo \n",
            " i promise in a holly \n",
            " listen \n",
            " we let you got today turning music of the end said \n",
            " im a hometown you broke me now it well i see what its round the radio \n",
            " make satisfaction so i get walk into its and i need permission on the dark so why \n",
            " caught me \n",
            " need \n",
            " \n",
            " but got it from time \n",
            " except a boys broke other question it ive get confessed see \n",
            " black with the try \n",
            " so hit me helped let you smile always knew \n",
            " starry da tires after time shrimp in my eyes \n",
            " just i understand \n",
            " filled me know \n",
            " wont the copa \n",
            " sock they laundry \n",
            " its christmas run and raped ill come on ringin crooked \n",
            " takin lost anybody yeah \n",
            " \n",
            " fame \n",
            " we feel in the stars on a new really to georgia \n",
            " as its too drag there is it too much let control my name are it away south of heaven inside your heart \n",
            " ill never meet one \n",
            " es goin \n",
            " will have your heart that im so alright \n",
            " cause what should give my\n",
            "\n",
            "Real Lyrics: dear i fear were facing a problem \n",
            " you love me no longer i know \n",
            " and maybe there is nothing \n",
            " that i can do to make you do \n",
            " mama tells me i bother \n",
            " that i ought to stick to another man \n",
            " a man that surely deserves me \n",
            " but i think you do \n",
            " so i cry i pray and i beg \n",
            " love me love me \n",
            " say that you love me \n",
            " fool me fool me \n",
            " go on and fool me \n",
            " love me love me \n",
            " pretend that you love me \n",
            " leave me leave me \n",
            " just say that you need me \n",
            " love me love me \n",
            " say that you love me \n",
            " leave me leave me \n",
            " just say that you need me \n",
            " i cant care bout anything but you \n",
            " lately i have desperately pondered \n",
            " spent my nights awake and i wonder \n",
            " what i could have done in another way \n",
            " to make you stay \n",
            " reason will not lead to solution \n",
            " i will end up lost in confusion \n",
            " i dont care if you really care \n",
            " as long as you dont go \n",
            " so i cry i pray and i beg \n",
            " love me love me \n",
            " say that you love me \n",
            " fool me fool me \n",
            " go on and fool me \n",
            " love me love me \n",
            " pretend that you love me \n",
            " leave me leave me \n",
            " just say that you need me \n",
            " so i cry and i pray for you to \n",
            " love me love me \n",
            " say that you love me \n",
            " leave me leave me \n",
            " just say that you need me \n",
            " i cant care bout anything but you \n",
            " anything but you \n",
            " love me love me say that you love me \n",
            " fool me fool me go on and fool me \n",
            " love me love me i know that you need me \n",
            " i cant care bout anything but you \n",
            "\n",
            "\n",
            "1-Gram Cosine Similarity: 0.1416\n",
            "2-Gram Cosine Similarity: 0.5670\n",
            "3-Gram Cosine Similarity: 0.4870\n",
            "4-Gram Cosine Similarity: 0.6412\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_1783929/701868571.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  melody_feature_tensor = torch.tensor(melody_feature).float().to(device)\n"
          ]
        }
      ],
      "source": [
        "# Generate lyrics for a specific song\n",
        "initial_word = 'fear'\n",
        "song_index = 2\n",
        "chosen_model = [model1, model2]\n",
        "print(f\"Song {song_index + 1}: {initial_word}\\n\")\n",
        "\n",
        "for model in chosen_model:\n",
        "  generated_lyrics = generate_text(model, X_test_load[song_index], word_model, initial_word, song_index)\n",
        "  # print model\n",
        "  print(f\"Model {chosen_model.index(model) + 1}: \\n\")\n",
        "  generated_lyrics_with_newline = generated_lyrics\n",
        "  generated_lyrics_with_newline = generated_lyrics_with_newline.replace('newline', '\\n')\n",
        "  print(f\"Generated Lyrics: {generated_lyrics_with_newline}\\n\")\n",
        "    # Evaluate lyrics and store results\n",
        "  sim_1gram, sim_2gram, sim_3gram, sim_4gram = evaluate_lyrics(\n",
        "      generated_lyrics, song_index\n",
        "  )\n",
        "\n",
        "  # Append results to the corresponding lists\n",
        "  if model == model1:  # Model 1\n",
        "      results_model1[\"1gram\"].append(sim_1gram)\n",
        "      results_model1[\"2gram\"].append(sim_2gram)\n",
        "      results_model1[\"3gram\"].append(sim_3gram)\n",
        "      results_model1[\"4gram\"].append(sim_4gram)\n",
        "  else:  # Model 2\n",
        "      results_model2[\"1gram\"].append(sim_1gram)\n",
        "      results_model2[\"2gram\"].append(sim_2gram)\n",
        "      results_model2[\"3gram\"].append(sim_3gram)\n",
        "      results_model2[\"4gram\"].append(sim_4gram)\n",
        "\n",
        "\n",
        "  print(f\"1-Gram Cosine Similarity: {sim_1gram:.4f}\")\n",
        "  print(f\"2-Gram Cosine Similarity: {sim_2gram:.4f}\")\n",
        "  print(f\"3-Gram Cosine Similarity: {sim_3gram:.4f}\")\n",
        "  print(f\"4-Gram Cosine Similarity: {sim_4gram:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1N8UYYR5244G"
      },
      "source": [
        "# **Test Song 4**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wbTuF2q244H"
      },
      "source": [
        "## Word - hiya"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBDTQuDY244H",
        "outputId": "e4e44129-e2e9-423b-900e-51f6eafbceeb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Song 4: hiya\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_1783929/701868571.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  melody_feature_tensor = torch.tensor(melody_feature).float().to(device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model 1: \n",
            "\n",
            "Generated Lyrics: hiya we sleep would the saw someone and were down lovers stoned em and their saw that it now that hell room dead sleep \n",
            " the day to live deceiving those loved take it down pain for me would fly ends brought enough easy \n",
            " oh face my bell never smile the rain room of the at hell show goodbye to take it incomprehensible face by room show looks live mad is enough many times deep dead of room room down in dry sleep \n",
            " let me their and gray she says your door ho late it sleep smile you were free low and gimme sleep \n",
            " he see \n",
            " i could marry \n",
            " watching go \n",
            " ah a black big god breaks their care as big glimpse for my knees me \n",
            " someone gotta mess in their arms up to no questions ho na na screwing out black \n",
            " uh ho \n",
            " of its getting thinkin room bitch like i saw the lonely we would it could marry now \n",
            " mess wrong \n",
            " room and out the door late all their lonely in their lonely room enough could just melodies \n",
            " and a glimpse ya stapled and gone some face in time bitch whats car \n",
            " late to be deceiving around the heart and moon \n",
            " both for big room glass \n",
            " its glimpse would never fly help that dead bitch would fly bitch you had the depths in \n",
            " la la la la is dead good big enough lonely dead a glimpse i swear that ill \n",
            " room right to know me dead done \n",
            " late \n",
            " pay about no slit seem to sleep in me when up thinkin lonely to fly glass that theres money part late \n",
            " show me watching the attitude for pity da da da da da da da da da da \n",
            " lots \n",
            " ah dead of me sleep take him live alone with me door \n",
            " and eee broken room leave fly watching \n",
            " their saw me cause it \n",
            " it could go make your mind to my sky good eyes \n",
            " lay over this is melodies \n",
            " by rise of their waiting bitch \n",
            " just says out dead so late dont live which sleep if black world in love baby \n",
            " incomprehensible to fly on melodies \n",
            " forget god \n",
            " because my dream their honey god depths \n",
            " living trying \n",
            " bring you were gray could say no fun car \n",
            " when their lonely melodies cause we sleep one bitch just late get by to brought their melodies full fingers \n",
            " matter id in the flow id and they i saw it \n",
            " now he\n",
            "\n",
            "Real Lyrics: hiya barbie \n",
            " hi ken \n",
            " do you want to go for a ride \n",
            " sure ken \n",
            " jump in \n",
            " im a barbie girl in a barbie world \n",
            " life in plastic its fantastic \n",
            " you can brush my hair undress me everywhere \n",
            " imagination life is your creation \n",
            " come on barbie lets go party \n",
            " im a barbie girl in a barbie world \n",
            " life in plastic its fantastic \n",
            " you can brush my hair undress me everywhere \n",
            " imagination life is your creation \n",
            " im a blond bimbo girl in a fantasy world \n",
            " dress me up make it tight im your dolly \n",
            " my doll rocknroll feel the glamor in pink \n",
            " kiss me here touch me there hanky \n",
            " you can touch \n",
            " you can play \n",
            " if you say im always yours \n",
            " im a barbie girl in a barbie world \n",
            " life in plastic its fantastic \n",
            " you can brush my hair undress me everywhere \n",
            " imagination life is your creation \n",
            " come on barbie lets go party ah ah ah yeah \n",
            " come on barbie lets go party oh oh \n",
            " come on barbie lets go party ah ah ah yeah \n",
            " come on barbie lets go party oh oh \n",
            " make me walk make me talk do whatever you please \n",
            " i can act like a star i can beg on my knees \n",
            " come jump in bimbo friend let us do it again \n",
            " hit the town fool around lets go party \n",
            " you can touch \n",
            " you can play \n",
            " if you say im always yours \n",
            " you can touch \n",
            " you can play \n",
            " if you say im always yours \n",
            " come on barbie lets go party ah ah ah yeah \n",
            " come on barbie lets go party oh oh \n",
            " come on barbie lets go party ah ah ah yeah \n",
            " come on barbie lets go party oh oh \n",
            " im a barbie girl in a barbie world \n",
            " life in plastic its fantastic \n",
            " you can brush my hair undress me everywhere \n",
            " imagination life is your creation \n",
            " im a barbie girl in a barbie world \n",
            " life in plastic its fantastic \n",
            " you can brush my hair undress me everywhere \n",
            " imagination life is your creation \n",
            " come on barbie lets go party ah ah ah yeah \n",
            " come on barbie lets go party oh oh \n",
            " come on barbie lets go party ah ah ah yeah \n",
            " come on barbie lets go party oh oh \n",
            " oh im having so much fun \n",
            " well barbie we are just getting started \n",
            " oh i love you ken \n",
            "\n",
            "\n",
            "1-Gram Cosine Similarity: -0.1182\n",
            "2-Gram Cosine Similarity: 0.3091\n",
            "3-Gram Cosine Similarity: 0.3312\n",
            "4-Gram Cosine Similarity: 0.3064\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_1783929/701868571.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  melody_feature_tensor = torch.tensor(melody_feature).float().to(device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model 2: \n",
            "\n",
            "Generated Lyrics: hiya trunk and it is to let you hes \n",
            " imaginary let those beat me off with you really think i had not free or sad baby ever are the drapes just whoa that would it with me or go down while your got one got them \n",
            " baby without you everything its so time right on yourself repeat \n",
            " come someone else we say the oldies she too much i chaka and dust you should never wrong \n",
            " let a fries cuz im got me down for a body \n",
            " seduce i told the you got a dimension i cant give me goodbye sick you want it is gettin whoa gonna take a babies say for me why \n",
            " she caught it right on my song \n",
            " open anymore oh \n",
            " beware \n",
            " survives \n",
            " run here must grow out on some no piece \n",
            " cause they said impossible for \n",
            " let this right again some my confirmation got me \n",
            " stay street to them in london weary yeah that smokin i was and tell me honey love honey is some kind your my heart kiss my heartaches whos \n",
            " in here is it just want me felt \n",
            " done i get police \n",
            " just call you leave my heavenly would i sing \n",
            " with it with you do her apartment here \n",
            " da dee \n",
            " i rush your mom knows the rest in the guy \n",
            " yes the fool whats \n",
            " you felt with a bottle train to leave my tengo a fantasy \n",
            " i give off in my big legend \n",
            " chorus friend is not found him in some \n",
            " \n",
            " inland here im \n",
            " that frown \n",
            " to ever dre \n",
            " and when then did say i stand out think you \n",
            " by to get \n",
            " and it aint the call \n",
            " you dont party \n",
            " but you cant the midnight you should be a man is of the faithful \n",
            " all the mood \n",
            " got rolled wrote in my loneliness of the the real much of the other wenn \n",
            " he flava your \n",
            " light in my star \n",
            " then kind of my heart \n",
            " love a mirage i \n",
            " next shit and honey \n",
            " is the bridge \n",
            " im not imitating in life \n",
            " here is just a glad make my babies outside the sea is oh aint sorry \n",
            " i die \n",
            " sittin upon you smile \n",
            " going so try \n",
            " no \n",
            " thats wanna yeah stop \n",
            " i wanted like along \n",
            " got us effect \n",
            " tickle \n",
            " comin wonder that is mine \n",
            " and he fold shes \n",
            " when that break you got it and\n",
            "\n",
            "Real Lyrics: hiya barbie \n",
            " hi ken \n",
            " do you want to go for a ride \n",
            " sure ken \n",
            " jump in \n",
            " im a barbie girl in a barbie world \n",
            " life in plastic its fantastic \n",
            " you can brush my hair undress me everywhere \n",
            " imagination life is your creation \n",
            " come on barbie lets go party \n",
            " im a barbie girl in a barbie world \n",
            " life in plastic its fantastic \n",
            " you can brush my hair undress me everywhere \n",
            " imagination life is your creation \n",
            " im a blond bimbo girl in a fantasy world \n",
            " dress me up make it tight im your dolly \n",
            " my doll rocknroll feel the glamor in pink \n",
            " kiss me here touch me there hanky \n",
            " you can touch \n",
            " you can play \n",
            " if you say im always yours \n",
            " im a barbie girl in a barbie world \n",
            " life in plastic its fantastic \n",
            " you can brush my hair undress me everywhere \n",
            " imagination life is your creation \n",
            " come on barbie lets go party ah ah ah yeah \n",
            " come on barbie lets go party oh oh \n",
            " come on barbie lets go party ah ah ah yeah \n",
            " come on barbie lets go party oh oh \n",
            " make me walk make me talk do whatever you please \n",
            " i can act like a star i can beg on my knees \n",
            " come jump in bimbo friend let us do it again \n",
            " hit the town fool around lets go party \n",
            " you can touch \n",
            " you can play \n",
            " if you say im always yours \n",
            " you can touch \n",
            " you can play \n",
            " if you say im always yours \n",
            " come on barbie lets go party ah ah ah yeah \n",
            " come on barbie lets go party oh oh \n",
            " come on barbie lets go party ah ah ah yeah \n",
            " come on barbie lets go party oh oh \n",
            " im a barbie girl in a barbie world \n",
            " life in plastic its fantastic \n",
            " you can brush my hair undress me everywhere \n",
            " imagination life is your creation \n",
            " im a barbie girl in a barbie world \n",
            " life in plastic its fantastic \n",
            " you can brush my hair undress me everywhere \n",
            " imagination life is your creation \n",
            " come on barbie lets go party ah ah ah yeah \n",
            " come on barbie lets go party oh oh \n",
            " come on barbie lets go party ah ah ah yeah \n",
            " come on barbie lets go party oh oh \n",
            " oh im having so much fun \n",
            " well barbie we are just getting started \n",
            " oh i love you ken \n",
            "\n",
            "\n",
            "1-Gram Cosine Similarity: -0.0765\n",
            "2-Gram Cosine Similarity: 0.2685\n",
            "3-Gram Cosine Similarity: 0.4220\n",
            "4-Gram Cosine Similarity: 0.7391\n"
          ]
        }
      ],
      "source": [
        "# Generate lyrics for a specific song\n",
        "initial_word = 'hiya'\n",
        "song_index = 3\n",
        "chosen_model = [model1, model2]\n",
        "print(f\"Song {song_index + 1}: {initial_word}\\n\")\n",
        "\n",
        "for model in chosen_model:\n",
        "  generated_lyrics = generate_text(model, X_test_load[song_index], word_model, initial_word, song_index)\n",
        "  # print model\n",
        "  print(f\"Model {chosen_model.index(model) + 1}: \\n\")\n",
        "  generated_lyrics_with_newline = generated_lyrics\n",
        "  generated_lyrics_with_newline = generated_lyrics_with_newline.replace('newline', '\\n')\n",
        "  print(f\"Generated Lyrics: {generated_lyrics_with_newline}\\n\")\n",
        "    # Evaluate lyrics and store results\n",
        "  sim_1gram, sim_2gram, sim_3gram, sim_4gram = evaluate_lyrics(\n",
        "      generated_lyrics, song_index\n",
        "  )\n",
        "\n",
        "  # Append results to the corresponding lists\n",
        "  if model == model1:  # Model 1\n",
        "      results_model1[\"1gram\"].append(sim_1gram)\n",
        "      results_model1[\"2gram\"].append(sim_2gram)\n",
        "      results_model1[\"3gram\"].append(sim_3gram)\n",
        "      results_model1[\"4gram\"].append(sim_4gram)\n",
        "  else:  # Model 2\n",
        "      results_model2[\"1gram\"].append(sim_1gram)\n",
        "      results_model2[\"2gram\"].append(sim_2gram)\n",
        "      results_model2[\"3gram\"].append(sim_3gram)\n",
        "      results_model2[\"4gram\"].append(sim_4gram)\n",
        "\n",
        "  print(f\"1-Gram Cosine Similarity: {sim_1gram:.4f}\")\n",
        "  print(f\"2-Gram Cosine Similarity: {sim_2gram:.4f}\")\n",
        "  print(f\"3-Gram Cosine Similarity: {sim_3gram:.4f}\")\n",
        "  print(f\"4-Gram Cosine Similarity: {sim_4gram:.4f}\")\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8eHHHBx244H"
      },
      "source": [
        "## Word - barbie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "YaMzVXuy244I",
        "outputId": "ced49016-3922-4364-f46c-ca4fbe3a7bf2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Song 4: barbie\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_1783929/701868571.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  melody_feature_tensor = torch.tensor(melody_feature).float().to(device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model 1: \n",
            "\n",
            "Generated Lyrics: barbie \n",
            " that wants my eyes deceiving door up which door glass dead \n",
            " never said your mind near the eye with a hole day \n",
            " which door \n",
            " never lie im a getting pity show up \n",
            " room and your love out in lovers up watching no depths woman in the depths and their eyes for youd because bad open together bitch you both closer for it leave some late late is forever both for im ho slit bitch the monkey the late \n",
            " stop away \n",
            " deceiving of deceiving dead turning high getting into the bottle of these thinking \n",
            " beautiful american \n",
            " she said \n",
            " is coming her great which wild which door room dead deceiving watching ya coming out \n",
            " i would never done you live bitch like you hell dead smile \n",
            " singin picking which bottle for him were had know why can i incomprehensible \n",
            " id me were \n",
            " and your mind but i \n",
            " wrapped dead hungry im a hole oh with black late to reach myself meet sing i see they must said ya i said \n",
            " just woman \n",
            " to myself room away home \n",
            " fly down in vain im not like myself mend for their life show in their fingers and i a easy groove around full easy cry ready down \n",
            " friends dead on a just downtown \n",
            " both they must never just because you sleep closer just sleep wild just says id would never see that im ho of their noise some so wrong ya a lonely me would i had always more for ten should way \n",
            " and bad day \n",
            " see me cut mine your \n",
            " i know and easy bitch \n",
            " oh lonely closer and keep \n",
            " o it live lost part of and their deep dead \n",
            " chorus would never had that part of their dust velvet of the eyes of the true eye with their feeling unkindly their life \n",
            " and stab free \n",
            " say like this bitch \n",
            " watching god \n",
            " photograph so closer simon says you sleep dead in hell wrapped dead hole and stab hoo throw their attitude of their said it seems so lonely you never both me home wrapped which till time full bitch no pity room down little never your heart my just seem a black day is the skies their eyes and bitch you sleep about crowd glass breakin im my eyes hes enough dead live with like me cut their lonely by late \n",
            " mmm ho \n",
            " theres place \n",
            " both the shine dead which would marry myself one time black door dead \n",
            " feel me wake with a\n",
            "\n",
            "Real Lyrics: hiya barbie \n",
            " hi ken \n",
            " do you want to go for a ride \n",
            " sure ken \n",
            " jump in \n",
            " im a barbie girl in a barbie world \n",
            " life in plastic its fantastic \n",
            " you can brush my hair undress me everywhere \n",
            " imagination life is your creation \n",
            " come on barbie lets go party \n",
            " im a barbie girl in a barbie world \n",
            " life in plastic its fantastic \n",
            " you can brush my hair undress me everywhere \n",
            " imagination life is your creation \n",
            " im a blond bimbo girl in a fantasy world \n",
            " dress me up make it tight im your dolly \n",
            " my doll rocknroll feel the glamor in pink \n",
            " kiss me here touch me there hanky \n",
            " you can touch \n",
            " you can play \n",
            " if you say im always yours \n",
            " im a barbie girl in a barbie world \n",
            " life in plastic its fantastic \n",
            " you can brush my hair undress me everywhere \n",
            " imagination life is your creation \n",
            " come on barbie lets go party ah ah ah yeah \n",
            " come on barbie lets go party oh oh \n",
            " come on barbie lets go party ah ah ah yeah \n",
            " come on barbie lets go party oh oh \n",
            " make me walk make me talk do whatever you please \n",
            " i can act like a star i can beg on my knees \n",
            " come jump in bimbo friend let us do it again \n",
            " hit the town fool around lets go party \n",
            " you can touch \n",
            " you can play \n",
            " if you say im always yours \n",
            " you can touch \n",
            " you can play \n",
            " if you say im always yours \n",
            " come on barbie lets go party ah ah ah yeah \n",
            " come on barbie lets go party oh oh \n",
            " come on barbie lets go party ah ah ah yeah \n",
            " come on barbie lets go party oh oh \n",
            " im a barbie girl in a barbie world \n",
            " life in plastic its fantastic \n",
            " you can brush my hair undress me everywhere \n",
            " imagination life is your creation \n",
            " im a barbie girl in a barbie world \n",
            " life in plastic its fantastic \n",
            " you can brush my hair undress me everywhere \n",
            " imagination life is your creation \n",
            " come on barbie lets go party ah ah ah yeah \n",
            " come on barbie lets go party oh oh \n",
            " come on barbie lets go party ah ah ah yeah \n",
            " come on barbie lets go party oh oh \n",
            " oh im having so much fun \n",
            " well barbie we are just getting started \n",
            " oh i love you ken \n",
            "\n",
            "\n",
            "1-Gram Cosine Similarity: -0.0168\n",
            "2-Gram Cosine Similarity: 0.2163\n",
            "3-Gram Cosine Similarity: 0.2084\n",
            "4-Gram Cosine Similarity: 0.5124\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_1783929/701868571.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  melody_feature_tensor = torch.tensor(melody_feature).float().to(device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model 2: \n",
            "\n",
            "Generated Lyrics: barbie cause he did is real rock like through the light of the poison \n",
            " ive know \n",
            " boy i bit \n",
            " when i fabulous call it ill almost brought you goes on things for a chance did make a things on up for all the city of fact you want it out of the name is faith \n",
            " listen is when i seem to shoot lets check too right again up the beware \n",
            " we swore it up runnin when \n",
            " baby impossible him if you gonna live them everything and he all about the hundred heaven \n",
            " and forwards a brains if i heard that there is the whole word from angles too \n",
            " and im wondering \n",
            " ocean yeah and looking to the bone in the funk \n",
            " yes here \n",
            " im pills \n",
            " he had a hands \n",
            " intergalactic like a puppy that they play we just lie \n",
            " ill stop \n",
            " got somebody can let her tryin you need it in cheeks \n",
            " got tha gimme shit uh yeah a showgirl ill sleep back at promise \n",
            " im a girl \n",
            " abacab to kiss another race at his wedding your way back of old excuse \n",
            " so much \n",
            " why the game alone \n",
            " ah life \n",
            " da da da ba daa of a experiment \n",
            " like me that you knew how keep lately do us babys they things yea they never mean ill slit \n",
            " are gonna ever to some right honeys khan \n",
            " where i wont just live christmas snuff \n",
            " wont you live the bad days \n",
            " you believe you you a damn they aint gon should go back back to have it or all sleeping of night brother im you too much for is under from tha smokin check your body think it to the walk a million not stars in wine mind \n",
            " goodbye back a life \n",
            " beat having funny always now baby sherry i never be here baby hey light \n",
            " and popped not way to fall high in a world just when you fucking yeah \n",
            " stand back from bud \n",
            " take it dear i tryin and it is huh know i run ever said of my number \n",
            " from her lips in a sabotage \n",
            " did that they may dance \n",
            " and i know its hard to keep control the soul on come down \n",
            " check from the midnight yo never leave you maintain your head should download \n",
            " he was pleasure when you alone we cant and look \n",
            " vincent laughter hide me yeah my attention in the again im cupid \n",
            " some always human gathered that lover yeah\n",
            "\n",
            "Real Lyrics: hiya barbie \n",
            " hi ken \n",
            " do you want to go for a ride \n",
            " sure ken \n",
            " jump in \n",
            " im a barbie girl in a barbie world \n",
            " life in plastic its fantastic \n",
            " you can brush my hair undress me everywhere \n",
            " imagination life is your creation \n",
            " come on barbie lets go party \n",
            " im a barbie girl in a barbie world \n",
            " life in plastic its fantastic \n",
            " you can brush my hair undress me everywhere \n",
            " imagination life is your creation \n",
            " im a blond bimbo girl in a fantasy world \n",
            " dress me up make it tight im your dolly \n",
            " my doll rocknroll feel the glamor in pink \n",
            " kiss me here touch me there hanky \n",
            " you can touch \n",
            " you can play \n",
            " if you say im always yours \n",
            " im a barbie girl in a barbie world \n",
            " life in plastic its fantastic \n",
            " you can brush my hair undress me everywhere \n",
            " imagination life is your creation \n",
            " come on barbie lets go party ah ah ah yeah \n",
            " come on barbie lets go party oh oh \n",
            " come on barbie lets go party ah ah ah yeah \n",
            " come on barbie lets go party oh oh \n",
            " make me walk make me talk do whatever you please \n",
            " i can act like a star i can beg on my knees \n",
            " come jump in bimbo friend let us do it again \n",
            " hit the town fool around lets go party \n",
            " you can touch \n",
            " you can play \n",
            " if you say im always yours \n",
            " you can touch \n",
            " you can play \n",
            " if you say im always yours \n",
            " come on barbie lets go party ah ah ah yeah \n",
            " come on barbie lets go party oh oh \n",
            " come on barbie lets go party ah ah ah yeah \n",
            " come on barbie lets go party oh oh \n",
            " im a barbie girl in a barbie world \n",
            " life in plastic its fantastic \n",
            " you can brush my hair undress me everywhere \n",
            " imagination life is your creation \n",
            " im a barbie girl in a barbie world \n",
            " life in plastic its fantastic \n",
            " you can brush my hair undress me everywhere \n",
            " imagination life is your creation \n",
            " come on barbie lets go party ah ah ah yeah \n",
            " come on barbie lets go party oh oh \n",
            " come on barbie lets go party ah ah ah yeah \n",
            " come on barbie lets go party oh oh \n",
            " oh im having so much fun \n",
            " well barbie we are just getting started \n",
            " oh i love you ken \n",
            "\n",
            "\n",
            "1-Gram Cosine Similarity: 0.4601\n",
            "2-Gram Cosine Similarity: 0.5093\n",
            "3-Gram Cosine Similarity: 0.3738\n",
            "4-Gram Cosine Similarity: 0.3413\n"
          ]
        }
      ],
      "source": [
        "# Generate lyrics for a specific song\n",
        "initial_word = 'barbie'\n",
        "song_index = 3\n",
        "chosen_model = [model1, model2]\n",
        "print(f\"Song {song_index + 1}: {initial_word}\\n\")\n",
        "\n",
        "for model in chosen_model:\n",
        "  generated_lyrics = generate_text(model, X_test_load[song_index], word_model, initial_word, song_index)\n",
        "  # print model\n",
        "  print(f\"Model {chosen_model.index(model) + 1}: \\n\")\n",
        "  generated_lyrics_with_newline = generated_lyrics\n",
        "  generated_lyrics_with_newline = generated_lyrics_with_newline.replace('newline', '\\n')\n",
        "  print(f\"Generated Lyrics: {generated_lyrics_with_newline}\\n\")\n",
        "     # Evaluate lyrics and store results\n",
        "  sim_1gram, sim_2gram, sim_3gram, sim_4gram = evaluate_lyrics(\n",
        "      generated_lyrics, song_index\n",
        "  )\n",
        "\n",
        "  # Append results to the corresponding lists\n",
        "  if model == model1:  # Model 1\n",
        "      results_model1[\"1gram\"].append(sim_1gram)\n",
        "      results_model1[\"2gram\"].append(sim_2gram)\n",
        "      results_model1[\"3gram\"].append(sim_3gram)\n",
        "      results_model1[\"4gram\"].append(sim_4gram)\n",
        "  else:  # Model 2\n",
        "      results_model2[\"1gram\"].append(sim_1gram)\n",
        "      results_model2[\"2gram\"].append(sim_2gram)\n",
        "      results_model2[\"3gram\"].append(sim_3gram)\n",
        "      results_model2[\"4gram\"].append(sim_4gram)\n",
        "\n",
        "  print(f\"1-Gram Cosine Similarity: {sim_1gram:.4f}\")\n",
        "  print(f\"2-Gram Cosine Similarity: {sim_2gram:.4f}\")\n",
        "  print(f\"3-Gram Cosine Similarity: {sim_3gram:.4f}\")\n",
        "  print(f\"4-Gram Cosine Similarity: {sim_4gram:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n444QekY244I"
      },
      "source": [
        "## Word - hi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leQU9K3x244I",
        "outputId": "e4e44129-e2e9-423b-900e-51f6eafbceeb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Song 4: hi\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_1783929/701868571.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  melody_feature_tensor = torch.tensor(melody_feature).float().to(device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model 1: \n",
            "\n",
            "Generated Lyrics: hi in god \n",
            " no hungry move into my finger watching me room down late like it in their side i fly giddy letter so it slowly \n",
            " half bitch no hole and green of your my view \n",
            " no one take me meet friends up me \n",
            " never hole \n",
            " and while now will bring getting wild go show me like my saw it show i all tomorrows \n",
            " the reason \n",
            " that god \n",
            " i just why saw someone won on the crowd room \n",
            " take their saw my rise dead in that hell \n",
            " cause at full one dead dead in my that ever knew to some black which home baby eyes for me so noise dead god \n",
            " down in their getting to sing without beat bitch im coming dont \n",
            " oh and singing dead would up with their when i one been the saw it in world for the a friend \n",
            " lookin forget \n",
            " bitch and before i sleep \n",
            " closer room smile rain day desire to shine down and god into the poison \n",
            " bring their best down and just said it is lonely dead crowd in a depths room \n",
            " so watching their stab out in the depths in vain \n",
            " with ten door through my big sent car to draw up her name \n",
            " with watching incomprehensible it pity were six vain \n",
            " and in times shes full lane too closer die take me \n",
            " singin so late when them done mess us needs a bottle that is real in my eyes is coming their attitude \n",
            " get their pity watching \n",
            " fly bitch \n",
            " i sleep lean heart watching dead saw their heart \n",
            " he cried guitar \n",
            " seem to show me lover lover shine car late of their eyes into the car mend my fly lots \n",
            " with a noise cry \n",
            " gimme stab make up \n",
            " bitch in their lonely turning known i for my by dead just knew \n",
            " just out is a bottle \n",
            " both \n",
            " closer \n",
            " down which ah it \n",
            " \n",
            " if tomorrows with their right glass door the life of in line of their name \n",
            " closer guitar in your get by in me \n",
            " black singing dead a hole \n",
            " love is two depths watching me dead time everyday part one \n",
            " from their saw a room love would never hope go and thinking i wont am pity would life is coming up and \n",
            " and god both for each reason and feeling the lovers da da da da da da da da \n",
            " my glimpse \n",
            " i be glad both time ho na is\n",
            "\n",
            "Real Lyrics: hiya barbie \n",
            " hi ken \n",
            " do you want to go for a ride \n",
            " sure ken \n",
            " jump in \n",
            " im a barbie girl in a barbie world \n",
            " life in plastic its fantastic \n",
            " you can brush my hair undress me everywhere \n",
            " imagination life is your creation \n",
            " come on barbie lets go party \n",
            " im a barbie girl in a barbie world \n",
            " life in plastic its fantastic \n",
            " you can brush my hair undress me everywhere \n",
            " imagination life is your creation \n",
            " im a blond bimbo girl in a fantasy world \n",
            " dress me up make it tight im your dolly \n",
            " my doll rocknroll feel the glamor in pink \n",
            " kiss me here touch me there hanky \n",
            " you can touch \n",
            " you can play \n",
            " if you say im always yours \n",
            " im a barbie girl in a barbie world \n",
            " life in plastic its fantastic \n",
            " you can brush my hair undress me everywhere \n",
            " imagination life is your creation \n",
            " come on barbie lets go party ah ah ah yeah \n",
            " come on barbie lets go party oh oh \n",
            " come on barbie lets go party ah ah ah yeah \n",
            " come on barbie lets go party oh oh \n",
            " make me walk make me talk do whatever you please \n",
            " i can act like a star i can beg on my knees \n",
            " come jump in bimbo friend let us do it again \n",
            " hit the town fool around lets go party \n",
            " you can touch \n",
            " you can play \n",
            " if you say im always yours \n",
            " you can touch \n",
            " you can play \n",
            " if you say im always yours \n",
            " come on barbie lets go party ah ah ah yeah \n",
            " come on barbie lets go party oh oh \n",
            " come on barbie lets go party ah ah ah yeah \n",
            " come on barbie lets go party oh oh \n",
            " im a barbie girl in a barbie world \n",
            " life in plastic its fantastic \n",
            " you can brush my hair undress me everywhere \n",
            " imagination life is your creation \n",
            " im a barbie girl in a barbie world \n",
            " life in plastic its fantastic \n",
            " you can brush my hair undress me everywhere \n",
            " imagination life is your creation \n",
            " come on barbie lets go party ah ah ah yeah \n",
            " come on barbie lets go party oh oh \n",
            " come on barbie lets go party ah ah ah yeah \n",
            " come on barbie lets go party oh oh \n",
            " oh im having so much fun \n",
            " well barbie we are just getting started \n",
            " oh i love you ken \n",
            "\n",
            "\n",
            "1-Gram Cosine Similarity: 0.0029\n",
            "2-Gram Cosine Similarity: 0.1009\n",
            "3-Gram Cosine Similarity: 0.1542\n",
            "4-Gram Cosine Similarity: 0.2237\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_1783929/701868571.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  melody_feature_tensor = torch.tensor(melody_feature).float().to(device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model 2: \n",
            "\n",
            "Generated Lyrics: hi gonna you walk around was a heartache \n",
            " to be what it home back \n",
            " and get laughs \n",
            " everybody fair \n",
            " words could they say you got you to make loving make love me \n",
            " romance that you must make you \n",
            " candle chic \n",
            " to party \n",
            " barry is so cold of his kiss that defense monday let all hell \n",
            " and beat him outside effect too strong dream can be out alright \n",
            " in year aint \n",
            " if i really wanna talk \n",
            " ring \n",
            " forgive what but i am the skies \n",
            " please is it side \n",
            " i cant yo yes i dont look at the point \n",
            " sing and interesting to tumble \n",
            " had to keep ye oh \n",
            " whats place your jive listen of egyptian tide \n",
            " like tell my block \n",
            " right here his body \n",
            " gon \n",
            " but you to have long enough on a raised in her shady escape over my first time after a natural \n",
            " at rest will be another place to yeah \n",
            " if i have your eyes \n",
            " talk id flava ammo believe \n",
            " lie \n",
            " anyway i my mind \n",
            " off of my babys all the spin he was is id see the day not a place \n",
            " bop \n",
            " im a beats and sexy dont come on it be for a warm the funk baby could he wants hang it gotta ever myrrh er daa here mary just near come on the promise up my head \n",
            " there wont son and you about me outside in a river my heart \n",
            " no on you where their pretty i see my dick should not a gangstas abacab but i see to me \n",
            " oh baby i could lose around your backstreets so really want it easy a knows me a beautiful eyes listen it mingled is not to draw burns \n",
            " i just ever want be there is too right now must say \n",
            " put all all the hardest time he build lets to suck in you \n",
            " amadeus old else hed suit earth from the night bitch when i should make you have been from mommy \n",
            " not when rye that is like this more just been shelter slow \n",
            " make him is the drive to he was right on now \n",
            " why i have \n",
            " to touch what back \n",
            " thats in course of your adams \n",
            " the blade in my mind in play to blackstreet ronnie too tastes \n",
            " off some day \n",
            " dance your eyes that jesus no i would i gotta just recording station \n",
            " like a body \n",
            " it think that of shades\n",
            "\n",
            "Real Lyrics: hiya barbie \n",
            " hi ken \n",
            " do you want to go for a ride \n",
            " sure ken \n",
            " jump in \n",
            " im a barbie girl in a barbie world \n",
            " life in plastic its fantastic \n",
            " you can brush my hair undress me everywhere \n",
            " imagination life is your creation \n",
            " come on barbie lets go party \n",
            " im a barbie girl in a barbie world \n",
            " life in plastic its fantastic \n",
            " you can brush my hair undress me everywhere \n",
            " imagination life is your creation \n",
            " im a blond bimbo girl in a fantasy world \n",
            " dress me up make it tight im your dolly \n",
            " my doll rocknroll feel the glamor in pink \n",
            " kiss me here touch me there hanky \n",
            " you can touch \n",
            " you can play \n",
            " if you say im always yours \n",
            " im a barbie girl in a barbie world \n",
            " life in plastic its fantastic \n",
            " you can brush my hair undress me everywhere \n",
            " imagination life is your creation \n",
            " come on barbie lets go party ah ah ah yeah \n",
            " come on barbie lets go party oh oh \n",
            " come on barbie lets go party ah ah ah yeah \n",
            " come on barbie lets go party oh oh \n",
            " make me walk make me talk do whatever you please \n",
            " i can act like a star i can beg on my knees \n",
            " come jump in bimbo friend let us do it again \n",
            " hit the town fool around lets go party \n",
            " you can touch \n",
            " you can play \n",
            " if you say im always yours \n",
            " you can touch \n",
            " you can play \n",
            " if you say im always yours \n",
            " come on barbie lets go party ah ah ah yeah \n",
            " come on barbie lets go party oh oh \n",
            " come on barbie lets go party ah ah ah yeah \n",
            " come on barbie lets go party oh oh \n",
            " im a barbie girl in a barbie world \n",
            " life in plastic its fantastic \n",
            " you can brush my hair undress me everywhere \n",
            " imagination life is your creation \n",
            " im a barbie girl in a barbie world \n",
            " life in plastic its fantastic \n",
            " you can brush my hair undress me everywhere \n",
            " imagination life is your creation \n",
            " come on barbie lets go party ah ah ah yeah \n",
            " come on barbie lets go party oh oh \n",
            " come on barbie lets go party ah ah ah yeah \n",
            " come on barbie lets go party oh oh \n",
            " oh im having so much fun \n",
            " well barbie we are just getting started \n",
            " oh i love you ken \n",
            "\n",
            "\n",
            "1-Gram Cosine Similarity: 0.0980\n",
            "2-Gram Cosine Similarity: 0.1209\n",
            "3-Gram Cosine Similarity: 0.2381\n",
            "4-Gram Cosine Similarity: 0.3000\n"
          ]
        }
      ],
      "source": [
        "# Generate lyrics for a specific song\n",
        "initial_word = 'hi'\n",
        "song_index = 3\n",
        "chosen_model = [model1, model2]\n",
        "print(f\"Song {song_index + 1}: {initial_word}\\n\")\n",
        "\n",
        "for model in chosen_model:\n",
        "  generated_lyrics = generate_text(model, X_test_load[song_index], word_model, initial_word, song_index)\n",
        "  # print model\n",
        "  print(f\"Model {chosen_model.index(model) + 1}: \\n\")\n",
        "  generated_lyrics_with_newline = generated_lyrics\n",
        "  generated_lyrics_with_newline = generated_lyrics_with_newline.replace('newline', '\\n')\n",
        "  print(f\"Generated Lyrics: {generated_lyrics_with_newline}\\n\")\n",
        "    # Evaluate lyrics and store results\n",
        "  sim_1gram, sim_2gram, sim_3gram, sim_4gram = evaluate_lyrics(\n",
        "      generated_lyrics, song_index\n",
        "  )\n",
        "\n",
        "  # Append results to the corresponding lists\n",
        "  if model == model1:  # Model 1\n",
        "      results_model1[\"1gram\"].append(sim_1gram)\n",
        "      results_model1[\"2gram\"].append(sim_2gram)\n",
        "      results_model1[\"3gram\"].append(sim_3gram)\n",
        "      results_model1[\"4gram\"].append(sim_4gram)\n",
        "  else:  # Model 2\n",
        "      results_model2[\"1gram\"].append(sim_1gram)\n",
        "      results_model2[\"2gram\"].append(sim_2gram)\n",
        "      results_model2[\"3gram\"].append(sim_3gram)\n",
        "      results_model2[\"4gram\"].append(sim_4gram)\n",
        "\n",
        "  print(f\"1-Gram Cosine Similarity: {sim_1gram:.4f}\")\n",
        "  print(f\"2-Gram Cosine Similarity: {sim_2gram:.4f}\")\n",
        "  print(f\"3-Gram Cosine Similarity: {sim_3gram:.4f}\")\n",
        "  print(f\"4-Gram Cosine Similarity: {sim_4gram:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8RoyYIX3Hxj"
      },
      "source": [
        "# **Test Song 5**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Tdx4gxT3Hxk"
      },
      "source": [
        "## Word - all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQQhCg1F3Hxk",
        "outputId": "e4e44129-e2e9-423b-900e-51f6eafbceeb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Song 5: all\n",
            "\n",
            "Model 1: \n",
            "\n",
            "Generated Lyrics: all dead wail \n",
            " because their room \n",
            " their two one hell see we would take me \n",
            " theres move into their door naturally its incomprehensible their yo marry us we must \n",
            " cause gimme the street through my reason for now oh am i knew go just a hole wants me sleep \n",
            " up \n",
            " both to live this never down closer by wrong \n",
            " sleep things id closer glass \n",
            " so bedouin no reason rock out dead \n",
            " ready wont stab get it easy shelter at my sleep at a white its not \n",
            " oh oh oh oh hey in which two lonely dead black bitch and their mind through than words \n",
            " had so free \n",
            " honey god when forget my dead twist \n",
            " and baby right \n",
            " god once it easy dead say want \n",
            " ah ho lives your reason the facing their door show for a pity ya coming into the black it easy words and remember as late of \n",
            " we are yours guitar to try to that would up dead forgotten \n",
            " so to marry \n",
            " fly their gotta understand in a bottle \n",
            " id never least christ \n",
            " my place into god mend\n",
            "\n",
            "Real Lyrics: all the small things \n",
            " true care truth brings \n",
            " ill take one lift \n",
            " your ride best trip \n",
            " always i know \n",
            " be at my show \n",
            " watching waiting \n",
            " say it aint so i will not go \n",
            " turn the lights off carry me home \n",
            " na na na na \n",
            " na na na na na na na na na na na \n",
            " late night come home \n",
            " work sucks i know \n",
            " she left me roses by the stairs \n",
            " surprises let me know she cares \n",
            " say it aint so i will not go \n",
            " turn the lights off carry me home \n",
            " na na na na \n",
            " na na na na na na na na na na na \n",
            " say it aint so i will not go \n",
            " turn the lights off carry me home \n",
            " keep your head still ill be your thrill \n",
            " the night will go on my little windmill \n",
            " say it aint so i will not go \n",
            " turn the lights off carry me home \n",
            " keep your head still ill be your thrill \n",
            " the night will go on \n",
            " the night will go on \n",
            " my little windmill \n",
            "\n",
            "\n",
            "1-Gram Cosine Similarity: 0.3528\n",
            "2-Gram Cosine Similarity: 0.2997\n",
            "3-Gram Cosine Similarity: 0.2168\n",
            "4-Gram Cosine Similarity: 0.2867\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_1783929/701868571.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  melody_feature_tensor = torch.tensor(melody_feature).float().to(device)\n",
            "/tmp/ipykernel_1783929/701868571.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  melody_feature_tensor = torch.tensor(melody_feature).float().to(device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model 2: \n",
            "\n",
            "Generated Lyrics: all the peace else be filled away \n",
            " searching \n",
            " and would love you too much one question with one just apart take it \n",
            " model when up \n",
            " let me high like it roll \n",
            " leave with down from tomorrows \n",
            " i said \n",
            " and you try again \n",
            " i die hope neither than you \n",
            " feel it all the started walk eyes from it \n",
            " and is on my faith comes and visit the whole secret were around you were feeling time in which im goodbye by box baby \n",
            " baby matter it \n",
            " when stiff live everything down and angles now than all it with you with you are no dreams \n",
            " so when shes more i need most scandals \n",
            " upside the have a do all in every way for back \n",
            " cause that we last day when they gotta be new life \n",
            " and remember that him on my whole morning together peace side be love \n",
            " \n",
            " but it \n",
            " come out \n",
            " well live my package not one day \n",
            " and ill wear me in the border is not only one lizards with a floor \n",
            " baby has to say \n",
            " by touch by\n",
            "\n",
            "Real Lyrics: all the small things \n",
            " true care truth brings \n",
            " ill take one lift \n",
            " your ride best trip \n",
            " always i know \n",
            " be at my show \n",
            " watching waiting \n",
            " say it aint so i will not go \n",
            " turn the lights off carry me home \n",
            " na na na na \n",
            " na na na na na na na na na na na \n",
            " late night come home \n",
            " work sucks i know \n",
            " she left me roses by the stairs \n",
            " surprises let me know she cares \n",
            " say it aint so i will not go \n",
            " turn the lights off carry me home \n",
            " na na na na \n",
            " na na na na na na na na na na na \n",
            " say it aint so i will not go \n",
            " turn the lights off carry me home \n",
            " keep your head still ill be your thrill \n",
            " the night will go on my little windmill \n",
            " say it aint so i will not go \n",
            " turn the lights off carry me home \n",
            " keep your head still ill be your thrill \n",
            " the night will go on \n",
            " the night will go on \n",
            " my little windmill \n",
            "\n",
            "\n",
            "1-Gram Cosine Similarity: -0.0748\n",
            "2-Gram Cosine Similarity: 0.1181\n",
            "3-Gram Cosine Similarity: 0.0376\n",
            "4-Gram Cosine Similarity: 0.1078\n"
          ]
        }
      ],
      "source": [
        "# Generate lyrics for a specific song\n",
        "initial_word = 'all'\n",
        "song_index = 4\n",
        "chosen_model = [model1, model2]\n",
        "print(f\"Song {song_index + 1}: {initial_word}\\n\")\n",
        "\n",
        "for model in chosen_model:\n",
        "  generated_lyrics = generate_text(model, X_test_load[song_index], word_model, initial_word, song_index)\n",
        "  # print model\n",
        "  print(f\"Model {chosen_model.index(model) + 1}: \\n\")\n",
        "  generated_lyrics_with_newline = generated_lyrics\n",
        "  generated_lyrics_with_newline = generated_lyrics_with_newline.replace('newline', '\\n')\n",
        "  print(f\"Generated Lyrics: {generated_lyrics_with_newline}\\n\")\n",
        "     # Evaluate lyrics and store results\n",
        "  sim_1gram, sim_2gram, sim_3gram, sim_4gram = evaluate_lyrics(\n",
        "      generated_lyrics, song_index\n",
        "  )\n",
        "\n",
        "  # Append results to the corresponding lists\n",
        "  if model == model1:  # Model 1\n",
        "      results_model1[\"1gram\"].append(sim_1gram)\n",
        "      results_model1[\"2gram\"].append(sim_2gram)\n",
        "      results_model1[\"3gram\"].append(sim_3gram)\n",
        "      results_model1[\"4gram\"].append(sim_4gram)\n",
        "  else:  # Model 2\n",
        "      results_model2[\"1gram\"].append(sim_1gram)\n",
        "      results_model2[\"2gram\"].append(sim_2gram)\n",
        "      results_model2[\"3gram\"].append(sim_3gram)\n",
        "      results_model2[\"4gram\"].append(sim_4gram)\n",
        "\n",
        "\n",
        "  print(f\"1-Gram Cosine Similarity: {sim_1gram:.4f}\")\n",
        "  print(f\"2-Gram Cosine Similarity: {sim_2gram:.4f}\")\n",
        "  print(f\"3-Gram Cosine Similarity: {sim_3gram:.4f}\")\n",
        "  print(f\"4-Gram Cosine Similarity: {sim_4gram:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qrvs9BqV3Hxk"
      },
      "source": [
        "## Word - the"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "ii4bXfRM3Hxk",
        "outputId": "ced49016-3922-4364-f46c-ca4fbe3a7bf2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Song 5: the\n",
            "\n",
            "Model 1: \n",
            "\n",
            "Generated Lyrics: the everything id know love \n",
            " and thinking me lonely dead lonely crowd upside me \n",
            " full to me one saw my black which stab and had gimme so easy wrapped dead gotta marry in hell em \n",
            " turning down til it up black up me room would \n",
            " both my its your arms of my arms watching it down of which hungry youd watching \n",
            " im so live in many times just \n",
            " sleep mess \n",
            " gimme the depths \n",
            " with me for so it down of place and now thinkin mend nowhere could be getting their two of the attitude upside my have no that big pain dead \n",
            " photograph for servant and their lonely down our pity \n",
            " id \n",
            " cause fly near \n",
            " venus a friend get up watching dead more live their big as bedouin a car what would relate together take so done help both of mind \n",
            " catch dry which shes to take her moon da had a wild her would still would give peace part \n",
            " closer far by of now god brought \n",
            " shoe strong ringing attitude perfect yours i swear is coming i dont by black im in \n",
            " i take\n",
            "\n",
            "Real Lyrics: all the small things \n",
            " true care truth brings \n",
            " ill take one lift \n",
            " your ride best trip \n",
            " always i know \n",
            " be at my show \n",
            " watching waiting \n",
            " say it aint so i will not go \n",
            " turn the lights off carry me home \n",
            " na na na na \n",
            " na na na na na na na na na na na \n",
            " late night come home \n",
            " work sucks i know \n",
            " she left me roses by the stairs \n",
            " surprises let me know she cares \n",
            " say it aint so i will not go \n",
            " turn the lights off carry me home \n",
            " na na na na \n",
            " na na na na na na na na na na na \n",
            " say it aint so i will not go \n",
            " turn the lights off carry me home \n",
            " keep your head still ill be your thrill \n",
            " the night will go on my little windmill \n",
            " say it aint so i will not go \n",
            " turn the lights off carry me home \n",
            " keep your head still ill be your thrill \n",
            " the night will go on \n",
            " the night will go on \n",
            " my little windmill \n",
            "\n",
            "\n",
            "1-Gram Cosine Similarity: 0.0325\n",
            "2-Gram Cosine Similarity: 0.4258\n",
            "3-Gram Cosine Similarity: 0.4333\n",
            "4-Gram Cosine Similarity: 0.4332\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_1783929/701868571.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  melody_feature_tensor = torch.tensor(melody_feature).float().to(device)\n",
            "/tmp/ipykernel_1783929/701868571.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  melody_feature_tensor = torch.tensor(melody_feature).float().to(device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model 2: \n",
            "\n",
            "Generated Lyrics: the boardwalk such out \n",
            " so rain has not close to be opened sense to be on tie just time i dont buy it \n",
            " da la la la la be a posters \n",
            " when only love is silken rock your and ad \n",
            " cause i do like to shoot into the same lonely \n",
            " you do you and such a reason \n",
            " still know you tried \n",
            " but it it aint i took ten light \n",
            " plan \n",
            " aint aint were at treat you must be never time alone again \n",
            " true weighing easy or you may change for mo di ya \n",
            " and hope one girl im baby up from a song thats no give are \n",
            " do you were serious good to pay me such that i cant let that i wants to bite your reflection my secrets guitar \n",
            " alleluia and fill a get there to love again im decision to lots queen making you \n",
            " ill break rooms \n",
            " save it for you teach me the dark city of these make me \n",
            " da the one day cause where me for two away \n",
            " to make me you work i love \n",
            " oh or and telling\n",
            "\n",
            "Real Lyrics: all the small things \n",
            " true care truth brings \n",
            " ill take one lift \n",
            " your ride best trip \n",
            " always i know \n",
            " be at my show \n",
            " watching waiting \n",
            " say it aint so i will not go \n",
            " turn the lights off carry me home \n",
            " na na na na \n",
            " na na na na na na na na na na na \n",
            " late night come home \n",
            " work sucks i know \n",
            " she left me roses by the stairs \n",
            " surprises let me know she cares \n",
            " say it aint so i will not go \n",
            " turn the lights off carry me home \n",
            " na na na na \n",
            " na na na na na na na na na na na \n",
            " say it aint so i will not go \n",
            " turn the lights off carry me home \n",
            " keep your head still ill be your thrill \n",
            " the night will go on my little windmill \n",
            " say it aint so i will not go \n",
            " turn the lights off carry me home \n",
            " keep your head still ill be your thrill \n",
            " the night will go on \n",
            " the night will go on \n",
            " my little windmill \n",
            "\n",
            "\n",
            "1-Gram Cosine Similarity: 0.3984\n",
            "2-Gram Cosine Similarity: 0.2667\n",
            "3-Gram Cosine Similarity: 0.2238\n",
            "4-Gram Cosine Similarity: 0.2918\n"
          ]
        }
      ],
      "source": [
        "# Generate lyrics for a specific song\n",
        "initial_word = 'the'\n",
        "song_index = 4\n",
        "chosen_model = [model1, model2]\n",
        "print(f\"Song {song_index + 1}: {initial_word}\\n\")\n",
        "\n",
        "for model in chosen_model:\n",
        "  generated_lyrics = generate_text(model, X_test_load[song_index], word_model, initial_word, song_index)\n",
        "  # print model\n",
        "  print(f\"Model {chosen_model.index(model) + 1}: \\n\")\n",
        "  generated_lyrics_with_newline = generated_lyrics\n",
        "  generated_lyrics_with_newline = generated_lyrics_with_newline.replace('newline', '\\n')\n",
        "  print(f\"Generated Lyrics: {generated_lyrics_with_newline}\\n\")\n",
        "     # Evaluate lyrics and store results\n",
        "  sim_1gram, sim_2gram, sim_3gram, sim_4gram = evaluate_lyrics(\n",
        "      generated_lyrics, song_index\n",
        "  )\n",
        "\n",
        "  # Append results to the corresponding lists\n",
        "  if model == model1:  # Model 1\n",
        "      results_model1[\"1gram\"].append(sim_1gram)\n",
        "      results_model1[\"2gram\"].append(sim_2gram)\n",
        "      results_model1[\"3gram\"].append(sim_3gram)\n",
        "      results_model1[\"4gram\"].append(sim_4gram)\n",
        "  else:  # Model 2\n",
        "      results_model2[\"1gram\"].append(sim_1gram)\n",
        "      results_model2[\"2gram\"].append(sim_2gram)\n",
        "      results_model2[\"3gram\"].append(sim_3gram)\n",
        "      results_model2[\"4gram\"].append(sim_4gram)\n",
        "\n",
        "  print(f\"1-Gram Cosine Similarity: {sim_1gram:.4f}\")\n",
        "  print(f\"2-Gram Cosine Similarity: {sim_2gram:.4f}\")\n",
        "  print(f\"3-Gram Cosine Similarity: {sim_3gram:.4f}\")\n",
        "  print(f\"4-Gram Cosine Similarity: {sim_4gram:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8D_ceH63Hxl"
      },
      "source": [
        "## Word - small"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5UqJ0v-3Hxl",
        "outputId": "e4e44129-e2e9-423b-900e-51f6eafbceeb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Song 5: small\n",
            "\n",
            "Model 1: \n",
            "\n",
            "Generated Lyrics: small bitch of anywhere \n",
            " because many enough depths and he bitch about in god on baby \n",
            " ah never said about and facing her dreams incomprehensible try out their nigga we embarrassment my care that you sleep near \n",
            " lonely for underground deceiving my depths their for my pride in the glimpse brought door back must take ya coming \n",
            " maybe for big free black eye \n",
            " all their words who easy \n",
            " lets myself i remember into attitude no hole \n",
            " im coming full arms feeling id a car \n",
            " i want you to take \n",
            " he never knew \n",
            " photograph as sweet because their saw me through their part of their life late to a place worth \n",
            " take it fly die sleep baby lean door \n",
            " getting brought room attitude day in \n",
            " one \n",
            " throw eternally brother \n",
            " uh she wants your arms lonely of hell smile late melodies my part dead of their mind and lonely \n",
            " make another rain \n",
            " let me \n",
            " goodbye im lost their reason tonight had \n",
            " fly down for i swear god \n",
            " id pity \n",
            " more that sleep lonely lonely dead \n",
            " we meet closer high \n",
            " id\n",
            "\n",
            "Real Lyrics: all the small things \n",
            " true care truth brings \n",
            " ill take one lift \n",
            " your ride best trip \n",
            " always i know \n",
            " be at my show \n",
            " watching waiting \n",
            " say it aint so i will not go \n",
            " turn the lights off carry me home \n",
            " na na na na \n",
            " na na na na na na na na na na na \n",
            " late night come home \n",
            " work sucks i know \n",
            " she left me roses by the stairs \n",
            " surprises let me know she cares \n",
            " say it aint so i will not go \n",
            " turn the lights off carry me home \n",
            " na na na na \n",
            " na na na na na na na na na na na \n",
            " say it aint so i will not go \n",
            " turn the lights off carry me home \n",
            " keep your head still ill be your thrill \n",
            " the night will go on my little windmill \n",
            " say it aint so i will not go \n",
            " turn the lights off carry me home \n",
            " keep your head still ill be your thrill \n",
            " the night will go on \n",
            " the night will go on \n",
            " my little windmill \n",
            "\n",
            "\n",
            "1-Gram Cosine Similarity: 0.3936\n",
            "2-Gram Cosine Similarity: 0.1214\n",
            "3-Gram Cosine Similarity: 0.1896\n",
            "4-Gram Cosine Similarity: 0.2883\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_1783929/701868571.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  melody_feature_tensor = torch.tensor(melody_feature).float().to(device)\n",
            "/tmp/ipykernel_1783929/701868571.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  melody_feature_tensor = torch.tensor(melody_feature).float().to(device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model 2: \n",
            "\n",
            "Generated Lyrics: small these before as never need you can build you can think \n",
            " there the crowd steel shine knows better listen me let thither in line \n",
            " and the light \n",
            " and i stay through \n",
            " you were \n",
            " a time \n",
            " you seeing sings \n",
            " i gotta say without each days put me do any world \n",
            " that we should thoughts \n",
            " help me out where looks can people dont you find for you mean that by she was sorry gotta turn to mess \n",
            " keeping view fills \n",
            " now \n",
            " ill have so yes oh oh \n",
            " i wonder \n",
            " and wondering shes take up and fight nights and they sign today \n",
            " and i be \n",
            " lets try you need is the past die and comin and your fuckin romance sails for the street be your father \n",
            " freedom into keeping free \n",
            " i bought you gettin to me from \n",
            " were in a step your clothes \n",
            " cant secrets must taking \n",
            " up how to you feel any time mmm \n",
            " lonely \n",
            " seasons anyway we wish run like me with being \n",
            " care \n",
            " i know \n",
            " they need been too in the words in life\n",
            "\n",
            "Real Lyrics: all the small things \n",
            " true care truth brings \n",
            " ill take one lift \n",
            " your ride best trip \n",
            " always i know \n",
            " be at my show \n",
            " watching waiting \n",
            " say it aint so i will not go \n",
            " turn the lights off carry me home \n",
            " na na na na \n",
            " na na na na na na na na na na na \n",
            " late night come home \n",
            " work sucks i know \n",
            " she left me roses by the stairs \n",
            " surprises let me know she cares \n",
            " say it aint so i will not go \n",
            " turn the lights off carry me home \n",
            " na na na na \n",
            " na na na na na na na na na na na \n",
            " say it aint so i will not go \n",
            " turn the lights off carry me home \n",
            " keep your head still ill be your thrill \n",
            " the night will go on my little windmill \n",
            " say it aint so i will not go \n",
            " turn the lights off carry me home \n",
            " keep your head still ill be your thrill \n",
            " the night will go on \n",
            " the night will go on \n",
            " my little windmill \n",
            "\n",
            "\n",
            "1-Gram Cosine Similarity: -0.0819\n",
            "2-Gram Cosine Similarity: 0.1914\n",
            "3-Gram Cosine Similarity: 0.2666\n",
            "4-Gram Cosine Similarity: 0.3790\n"
          ]
        }
      ],
      "source": [
        "# Generate lyrics for a specific song\n",
        "initial_word = 'small'\n",
        "song_index = 4\n",
        "chosen_model = [model1, model2]\n",
        "print(f\"Song {song_index + 1}: {initial_word}\\n\")\n",
        "\n",
        "for model in chosen_model:\n",
        "  generated_lyrics = generate_text(model, X_test_load[song_index], word_model, initial_word, song_index)\n",
        "  # print model\n",
        "  print(f\"Model {chosen_model.index(model) + 1}: \\n\")\n",
        "  generated_lyrics_with_newline = generated_lyrics\n",
        "  generated_lyrics_with_newline = generated_lyrics_with_newline.replace('newline', '\\n')\n",
        "  print(f\"Generated Lyrics: {generated_lyrics_with_newline}\\n\")\n",
        "     # Evaluate lyrics and store results\n",
        "  sim_1gram, sim_2gram, sim_3gram, sim_4gram = evaluate_lyrics(\n",
        "      generated_lyrics, song_index\n",
        "  )\n",
        "\n",
        "  # Append results to the corresponding lists\n",
        "  if model == model1:  # Model 1\n",
        "      results_model1[\"1gram\"].append(sim_1gram)\n",
        "      results_model1[\"2gram\"].append(sim_2gram)\n",
        "      results_model1[\"3gram\"].append(sim_3gram)\n",
        "      results_model1[\"4gram\"].append(sim_4gram)\n",
        "  else:  # Model 2\n",
        "      results_model2[\"1gram\"].append(sim_1gram)\n",
        "      results_model2[\"2gram\"].append(sim_2gram)\n",
        "      results_model2[\"3gram\"].append(sim_3gram)\n",
        "      results_model2[\"4gram\"].append(sim_4gram)\n",
        "\n",
        "\n",
        "  print(f\"1-Gram Cosine Similarity: {sim_1gram:.4f}\")\n",
        "  print(f\"2-Gram Cosine Similarity: {sim_2gram:.4f}\")\n",
        "  print(f\"3-Gram Cosine Similarity: {sim_3gram:.4f}\")\n",
        "  print(f\"4-Gram Cosine Similarity: {sim_4gram:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZD-7NBL2Od2"
      },
      "source": [
        "# **results**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0OnSwq32Od2",
        "outputId": "047b72ea-87d5-47e0-f012-bc9de993f91c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Summary of Results:\n",
            "Model 1 Mean Results: {'1gram': 0.1826923578698188, '2gram': 0.22032057583332063, '3gram': 0.277560206707567, '4gram': 0.37563665717840194}\n",
            "Model 2 Mean Results: {'1gram': 0.39602609417800394, '2gram': 0.3025585362421615, '3gram': 0.3084555741931711, '4gram': 0.3476228304207325}\n"
          ]
        }
      ],
      "source": [
        "# Calculate mean results for each model\n",
        "def calculate_mean_results(results):\n",
        "    return {key: np.mean(values) if values else 0 for key, values in results.items()}\n",
        "\n",
        "mean_results_model1 = calculate_mean_results(results_model1)\n",
        "mean_results_model2 = calculate_mean_results(results_model2)\n",
        "\n",
        "# Print summary\n",
        "print(\"Summary of Results:\")\n",
        "print(f\"Model 1 Mean Results: {mean_results_model1}\")\n",
        "print(f\"Model 2 Mean Results: {mean_results_model2}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "9M7ul7OMm_dk",
        "LnZdcbwF1eN_",
        "ZPQaQgwH1h7W",
        "y4NIRKwQLMwD",
        "eTliULIwSrE2",
        "li-XjGqh2COJ",
        "66TqZo-XSnNa",
        "6s6iZiHD2GHR",
        "Ask9pJb4KN2j",
        "gnzrSCbWLPzc",
        "CdgZYaZ1K0Eo",
        "kQXc7dAT0J0s",
        "no7tu2YX0-Lc",
        "bSn0W9sN18an",
        "r2bG4DYh2Atm",
        "_nvOcOj32O3H",
        "bcCKMNxO2O3I",
        "MBgPbISl2O3I",
        "Wzz52Rln2O3J",
        "4LySbk_S2eEA",
        "5dqtA7Sy2eEB",
        "lrsy2cfJ2eEB",
        "t0ltRzmU2eEC",
        "1N8UYYR5244G",
        "3wbTuF2q244H",
        "V8eHHHBx244H",
        "n444QekY244I",
        "C8RoyYIX3Hxj",
        "9Tdx4gxT3Hxk",
        "Qrvs9BqV3Hxk",
        "p8D_ceH63Hxl"
      ],
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "tal_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}